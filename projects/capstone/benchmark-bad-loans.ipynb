{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan data\n",
    "df = pd.read_pickle('data_cleaned.pkl')\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features from data-cleanup.ipynb\n",
    "cat_features = ['grade', 'sub_grade', 'emp_length', 'home_ownership', 'verification_status', \n",
    "                'purpose', 'addr_state', 'initial_list_status', 'application_type', 'disbursement_method']\n",
    "\n",
    "for y in cat_features:\n",
    "    # print(y + \" has \" + str(len(df[y].unique())) + \" unique values\")\n",
    "    df = df.join(pd.get_dummies(df[y], prefix=y))\n",
    "    df.drop(y, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 830685\n",
      "Total number of good loans: 659424\n",
      "Total number of bad loans: 171261\n",
      "Percentage of bad loans: 20.616840318532297\n"
     ]
    }
   ],
   "source": [
    "# Total number of records\n",
    "n_records = len(df.index)\n",
    "\n",
    "# Number of records where loan status is 'Fully Paid'\n",
    "n_fully_paid = len(df[df.loan_status == 'Fully Paid'].index)\n",
    "\n",
    "# Number of records where loan status is 'Charged Off\n",
    "n_charged_off = len(df[df.loan_status == 'Charged Off'].index)\n",
    "\n",
    "# Percentage of loan default\n",
    "loan_default = 100 * float(n_charged_off) / n_records\n",
    "\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Total number of good loans: {}\".format(n_fully_paid))\n",
    "print(\"Total number of bad loans: {}\".format(n_charged_off))\n",
    "print(\"Percentage of bad loans: {}\".format(loan_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in features and target label\n",
    "loan_status_raw = df['loan_status']\n",
    "features = df.drop('loan_status', axis=1)\n",
    "\n",
    "# Encode the loan_status_raw to numerical values\n",
    "# Fully Paid = 1\n",
    "# Charged Off = 0\n",
    "loan_status = loan_status_raw.apply(lambda x: int(x == 'Fully Paid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 664548 samples.\n",
      "Testing set has 166137 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the features and loan_status data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "    start = time() # Get start time\n",
    "    learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set,\n",
    "    #       then get predictions on the first 300 training samples\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "       \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples\n",
    "    results['acc_train'] = accuracy_score(y_train[:300], learner.predict(X_train[:300]))\n",
    "        \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test, learner.predict(X_test))\n",
    "    \n",
    "    # TODO: Compute F-score on the the first 300 training samples\n",
    "    results['f_train'] = fbeta_score(y_train[:300], learner.predict(X_train[:300]), beta=0.5)\n",
    "        \n",
    "    # TODO: Compute F-score on the test set\n",
    "    results['f_test'] = fbeta_score(y_test, learner.predict(X_test), beta=0.5)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB trained on 664548 samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_time': 2.950104236602783,\n",
       " 'pred_time': 0.6878616809844971,\n",
       " 'acc_train': 0.45,\n",
       " 'acc_test': 0.3935727742766512,\n",
       " 'f_train': 0.6629834254143647,\n",
       " 'f_test': 0.6091418829195067}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
