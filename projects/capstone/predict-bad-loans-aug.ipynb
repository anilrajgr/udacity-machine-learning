{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',1000)\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan data\n",
    "df = pd.read_pickle('data_cleaned.pkl')\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features from data-cleanup.ipynb\n",
    "cat_features = ['grade', 'sub_grade', 'emp_length', 'home_ownership', 'verification_status', \n",
    "                'purpose', 'addr_state', 'initial_list_status', 'application_type', 'disbursement_method']\n",
    "\n",
    "for y in cat_features:\n",
    "    # print(y + \" has \" + str(len(df[y].unique())) + \" unique values\")\n",
    "    df = df.join(pd.get_dummies(df[y], prefix=y))\n",
    "    df.drop(y, axis=1, inplace=True)\n",
    "\n",
    "# Remove int_rate also\n",
    "df.drop('int_rate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the loan_status to numerical values\n",
    "# Fully Paid = 1\n",
    "# Charged Off = 0\n",
    "df['loan_status'] = df['loan_status'].apply(lambda x: int(x == 'Fully Paid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>disbursement_method_Cash</th>\n",
       "      <th>disbursement_method_DirectPay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>8.306850e+05</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "      <td>830685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14325.615727</td>\n",
       "      <td>14312.102722</td>\n",
       "      <td>14279.615080</td>\n",
       "      <td>41.796970</td>\n",
       "      <td>436.406142</td>\n",
       "      <td>7.529807e+04</td>\n",
       "      <td>0.793832</td>\n",
       "      <td>518.830457</td>\n",
       "      <td>17.395740</td>\n",
       "      <td>0.307000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022308</td>\n",
       "      <td>0.012747</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.504204</td>\n",
       "      <td>0.495796</td>\n",
       "      <td>0.994908</td>\n",
       "      <td>0.005092</td>\n",
       "      <td>0.998617</td>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8509.996557</td>\n",
       "      <td>8503.337725</td>\n",
       "      <td>8508.362095</td>\n",
       "      <td>10.272417</td>\n",
       "      <td>255.953656</td>\n",
       "      <td>6.557081e+04</td>\n",
       "      <td>0.404553</td>\n",
       "      <td>314.240924</td>\n",
       "      <td>8.984933</td>\n",
       "      <td>0.857069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147684</td>\n",
       "      <td>0.112182</td>\n",
       "      <td>0.063140</td>\n",
       "      <td>0.047317</td>\n",
       "      <td>0.499983</td>\n",
       "      <td>0.499983</td>\n",
       "      <td>0.071178</td>\n",
       "      <td>0.071178</td>\n",
       "      <td>0.037166</td>\n",
       "      <td>0.037166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>7975.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>4.520000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>377.000000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>9.000000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>823.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1714.000000</td>\n",
       "      <td>9.550000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           loan_amnt    funded_amnt  funded_amnt_inv           term  \\\n",
       "count  830685.000000  830685.000000    830685.000000  830685.000000   \n",
       "mean    14325.615727   14312.102722     14279.615080      41.796970   \n",
       "std      8509.996557    8503.337725      8508.362095      10.272417   \n",
       "min       500.000000     500.000000         0.000000      36.000000   \n",
       "25%      8000.000000    8000.000000      7975.000000      36.000000   \n",
       "50%     12000.000000   12000.000000     12000.000000      36.000000   \n",
       "75%     20000.000000   20000.000000     20000.000000      36.000000   \n",
       "max     40000.000000   40000.000000     40000.000000      60.000000   \n",
       "\n",
       "         installment    annual_inc    loan_status       zip_code  \\\n",
       "count  830685.000000  8.306850e+05  830685.000000  830685.000000   \n",
       "mean      436.406142  7.529807e+04       0.793832     518.830457   \n",
       "std       255.953656  6.557081e+04       0.404553     314.240924   \n",
       "min         4.000000  0.000000e+00       0.000000       7.000000   \n",
       "25%       251.000000  4.520000e+04       1.000000     234.000000   \n",
       "50%       377.000000  6.500000e+04       1.000000     481.000000   \n",
       "75%       576.000000  9.000000e+04       1.000000     823.000000   \n",
       "max      1714.000000  9.550000e+06       1.000000     999.000000   \n",
       "\n",
       "                 dti    delinq_2yrs              ...                \\\n",
       "count  830685.000000  830685.000000              ...                 \n",
       "mean       17.395740       0.307000              ...                 \n",
       "std         8.984933       0.857069              ...                 \n",
       "min        -1.000000       0.000000              ...                 \n",
       "25%        11.000000       0.000000              ...                 \n",
       "50%        17.000000       0.000000              ...                 \n",
       "75%        23.000000       0.000000              ...                 \n",
       "max       999.000000      39.000000              ...                 \n",
       "\n",
       "       addr_state_WA  addr_state_WI  addr_state_WV  addr_state_WY  \\\n",
       "count  830685.000000  830685.000000  830685.000000  830685.000000   \n",
       "mean        0.022308       0.012747       0.004003       0.002244   \n",
       "std         0.147684       0.112182       0.063140       0.047317   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       initial_list_status_f  initial_list_status_w  \\\n",
       "count          830685.000000          830685.000000   \n",
       "mean                0.504204               0.495796   \n",
       "std                 0.499983               0.499983   \n",
       "min                 0.000000               0.000000   \n",
       "25%                 0.000000               0.000000   \n",
       "50%                 1.000000               0.000000   \n",
       "75%                 1.000000               1.000000   \n",
       "max                 1.000000               1.000000   \n",
       "\n",
       "       application_type_Individual  application_type_Joint App  \\\n",
       "count                830685.000000               830685.000000   \n",
       "mean                      0.994908                    0.005092   \n",
       "std                       0.071178                    0.071178   \n",
       "min                       0.000000                    0.000000   \n",
       "25%                       1.000000                    0.000000   \n",
       "50%                       1.000000                    0.000000   \n",
       "75%                       1.000000                    0.000000   \n",
       "max                       1.000000                    1.000000   \n",
       "\n",
       "       disbursement_method_Cash  disbursement_method_DirectPay  \n",
       "count             830685.000000                  830685.000000  \n",
       "mean                   0.998617                       0.001383  \n",
       "std                    0.037166                       0.037166  \n",
       "min                    0.000000                       0.000000  \n",
       "25%                    1.000000                       0.000000  \n",
       "50%                    1.000000                       0.000000  \n",
       "75%                    1.000000                       0.000000  \n",
       "max                    1.000000                       1.000000  \n",
       "\n",
       "[8 rows x 221 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "# most correlated features\n",
    "corrmat = df.corr()\n",
    "# top_corr_features = corrmat.index[abs(corrmat[\"int_rate\"])>0.5]\n",
    "# plt.figure(figsize=(100,100))\n",
    "# g = sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "# sns.heatmap(df.corr(),annot=True,cmap=\"RdYlGn\")\n",
    "\n",
    "def correlation_matrix(df):\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib import cm as cm\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    cmap = cm.get_cmap('jet', 30)\n",
    "    cax = ax1.imshow(df.corr(), interpolation=\"nearest\")\n",
    "    ax1.grid(True)\n",
    "    plt.title('Feature Correlation')\n",
    "    # labels=['Sex','Length','Diam','Height','Whole','Shucked','Viscera','Shell','Rings',]\n",
    "    # ax1.set_xticklabels(labels,fontsize=6)\n",
    "    # ax1.set_yticklabels(labels,fontsize=6)\n",
    "    # Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "    fig.colorbar(cax) # , ticks=[.75,.8,.85,.90,.95,1])\n",
    "    plt.figure(figsize=(100,100))\n",
    "    plt.show()\n",
    "\n",
    "# correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt                       -0.064021\n",
       "funded_amnt                     -0.064132\n",
       "funded_amnt_inv                 -0.063865\n",
       "term                            -0.177266\n",
       "installment                     -0.046476\n",
       "annual_inc                       0.046371\n",
       "loan_status                      1.000000\n",
       "zip_code                         0.016527\n",
       "dti                             -0.120715\n",
       "delinq_2yrs                     -0.021748\n",
       "inq_last_6mths                  -0.058934\n",
       "mths_since_last_delinq          -0.005921\n",
       "mths_since_last_record          -0.023344\n",
       "open_acc                        -0.034570\n",
       "pub_rec                         -0.023285\n",
       "revol_bal                        0.013427\n",
       "revol_util                      -0.072684\n",
       "total_acc                        0.011113\n",
       "collections_12_mths_ex_med      -0.018195\n",
       "mths_since_last_major_derog     -0.025663\n",
       "acc_now_delinq                  -0.007142\n",
       "tot_coll_amt                    -0.000020\n",
       "tot_cur_bal                      0.061666\n",
       "open_acc_6m                     -0.037827\n",
       "open_act_il                     -0.022859\n",
       "open_il_12m                     -0.035859\n",
       "open_il_24m                     -0.031631\n",
       "mths_since_rcnt_il              -0.001594\n",
       "total_bal_il                    -0.015194\n",
       "il_util                         -0.031631\n",
       "                                   ...   \n",
       "addr_state_NC                   -0.003622\n",
       "addr_state_ND                   -0.002090\n",
       "addr_state_NE                   -0.006749\n",
       "addr_state_NH                    0.010618\n",
       "addr_state_NJ                   -0.004963\n",
       "addr_state_NM                   -0.003390\n",
       "addr_state_NV                   -0.008473\n",
       "addr_state_NY                   -0.015443\n",
       "addr_state_OH                   -0.008578\n",
       "addr_state_OK                   -0.009697\n",
       "addr_state_OR                    0.015144\n",
       "addr_state_PA                   -0.003946\n",
       "addr_state_RI                    0.002230\n",
       "addr_state_SC                    0.008899\n",
       "addr_state_SD                   -0.001807\n",
       "addr_state_TN                   -0.007141\n",
       "addr_state_TX                    0.002480\n",
       "addr_state_UT                    0.006129\n",
       "addr_state_VA                   -0.000809\n",
       "addr_state_VT                    0.006318\n",
       "addr_state_WA                    0.014800\n",
       "addr_state_WI                    0.009154\n",
       "addr_state_WV                    0.003936\n",
       "addr_state_WY                    0.003163\n",
       "initial_list_status_f            0.017221\n",
       "initial_list_status_w           -0.017221\n",
       "application_type_Individual     -0.003934\n",
       "application_type_Joint App       0.003934\n",
       "disbursement_method_Cash         0.024749\n",
       "disbursement_method_DirectPay   -0.024749\n",
       "Name: loan_status, Length: 221, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_corr_features = corrmat.loc[abs(corrmat['loan_status']) > 0.1]\n",
    "# plt.figure(figsize=(10,10))\n",
    "# sns.heatmap(df[top_corr_features].corr(), annot=True, cmap='RdYlGn')\n",
    "# sns.heatmap(top_corr_features.corr(), annot=True, cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Absolute Correlations\n",
      "<class 'pandas.core.series.Series'>\n",
      "disbursement_method_Cash     disbursement_method_DirectPay     1.000000\n",
      "application_type_Individual  application_type_Joint App        1.000000\n",
      "initial_list_status_f        initial_list_status_w             1.000000\n",
      "loan_amnt                    funded_amnt                       0.999263\n",
      "funded_amnt                  funded_amnt_inv                   0.998497\n",
      "loan_amnt                    funded_amnt_inv                   0.997613\n",
      "num_actv_rev_tl              num_rev_tl_bal_gt_0               0.986859\n",
      "tot_cur_bal                  tot_hi_cred_lim                   0.981071\n",
      "funded_amnt                  installment                       0.954615\n",
      "loan_amnt                    installment                       0.953506\n",
      "funded_amnt_inv              installment                       0.953042\n",
      "sec_app_open_acc             sec_app_num_rev_accts             0.923560\n",
      "il_util                      all_util                          0.900204\n",
      "open_acc                     num_sats                          0.897208\n",
      "num_bc_tl                    num_rev_accts                     0.870921\n",
      "open_rv_12m                  open_rv_24m                       0.869813\n",
      "total_bal_ex_mort            total_il_high_credit_limit        0.864920\n",
      "open_il_12m                  open_il_24m                       0.852106\n",
      "tot_cur_bal                  avg_cur_bal                       0.851719\n",
      "bc_util                      percent_bc_gt_75                  0.850330\n",
      "bc_open_to_buy               total_bc_limit                    0.842910\n",
      "num_op_rev_tl                num_sats                          0.841537\n",
      "num_actv_bc_tl               num_actv_rev_tl                   0.836741\n",
      "num_op_rev_tl                num_rev_tl_bal_gt_0               0.835273\n",
      "num_actv_bc_tl               num_bc_sats                       0.833963\n",
      "                             num_rev_tl_bal_gt_0               0.832568\n",
      "num_actv_rev_tl              num_op_rev_tl                     0.831511\n",
      "avg_cur_bal                  tot_hi_cred_lim                   0.819974\n",
      "home_ownership_MORTGAGE      home_ownership_RENT               0.813413\n",
      "num_op_rev_tl                num_rev_accts                     0.812670\n",
      "revol_bal_joint              sec_app_open_acc                  0.803739\n",
      "acc_now_delinq               num_tl_30dpd                      0.799828\n",
      "mths_since_recent_bc_dlq     mths_since_recent_revol_delinq    0.792761\n",
      "mths_since_last_record       pub_rec_bankruptcies              0.789003\n",
      "sec_app_open_acc             sec_app_open_act_il               0.788576\n",
      "revol_bal_joint              sec_app_num_rev_accts             0.780204\n",
      "revol_bal                    total_rev_hi_lim                  0.778773\n",
      "open_acc_6m                  open_rv_12m                       0.768445\n",
      "sec_app_open_acc             sec_app_revol_util                0.764508\n",
      "acc_open_past_24mths         num_tl_op_past_12m                0.758473\n",
      "num_bc_sats                  num_op_rev_tl                     0.757965\n",
      "revol_bal_joint              sec_app_revol_util                0.752302\n",
      "open_acc                     num_op_rev_tl                     0.752077\n",
      "mo_sin_old_rev_tl_op         earliest_cr_line_yr               0.743809\n",
      "open_il_24m                  il_util                           0.736145\n",
      "num_bc_sats                  num_bc_tl                         0.728773\n",
      "open_act_il                  total_bal_il                      0.728292\n",
      "sec_app_revol_util           sec_app_num_rev_accts             0.725993\n",
      "open_act_il                  il_util                           0.716773\n",
      "revol_util                   bc_util                           0.715363\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(type(get_top_abs_correlations(df, 3)))\n",
    "print(get_top_abs_correlations(df, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/vjgupta/reach-top-10-with-simple-model-on-housing-prices\n",
    "    \n",
    "# c = df.corr().abs()\n",
    "# s = c.unstack()\n",
    "# so = s.sort_values(ascending=False).drop_duplicates()\n",
    "\n",
    "# with pd.option_context('display.max_rows', 1000, 'display.max_columns', 3):\n",
    "  # print(so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = 0.79 and sigma = 0.40\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target Variable \n",
    "def check_skewness(col):\n",
    "    sns.distplot(df[col], fit=norm)\n",
    "    fig = plt.figure()\n",
    "    res = stats.probplot(df[col], plot=plt)\n",
    "    (mu, sigma) = norm.fit(df[col])\n",
    "    print('mu = {:.2f} and sigma = {:.2f}'.format(mu, sigma))\n",
    "\n",
    "check_skewness('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <td>868.224262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_IA</th>\n",
       "      <td>344.479732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec_app_chargeoff_within_12_mths</th>\n",
       "      <td>291.800358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec_app_collections_12_mths_ex_med</th>\n",
       "      <td>289.936477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec_app_open_act_il</th>\n",
       "      <td>66.269959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec_app_mths_since_last_major_derog</th>\n",
       "      <td>61.649797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec_app_inq_last_6mths</th>\n",
       "      <td>59.804717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <td>57.101681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_bal_joint</th>\n",
       "      <td>51.782773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose_educational</th>\n",
       "      <td>50.920438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <td>49.018559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec_app_mort_acc</th>\n",
       "      <td>47.834308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>44.635559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax_liens</th>\n",
       "      <td>41.839451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec_app_num_rev_accts</th>\n",
       "      <td>41.055559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_ID</th>\n",
       "      <td>38.824439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec_app_open_acc</th>\n",
       "      <td>37.355993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose_renewable_energy</th>\n",
       "      <td>36.711144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_ND</th>\n",
       "      <td>36.299375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_G5</th>\n",
       "      <td>35.679330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_ME</th>\n",
       "      <td>33.969748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sec_app_revol_util</th>\n",
       "      <td>32.146604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_G4</th>\n",
       "      <td>31.722843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_G3</th>\n",
       "      <td>27.589870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disbursement_method_DirectPay</th>\n",
       "      <td>26.832160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NE</th>\n",
       "      <td>23.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_G2</th>\n",
       "      <td>23.205980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_VT</th>\n",
       "      <td>22.914876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_30dpd</th>\n",
       "      <td>21.931103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_SD</th>\n",
       "      <td>21.914366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc</th>\n",
       "      <td>0.915511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status_Not Verified</th>\n",
       "      <td>0.830687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sats</th>\n",
       "      <td>0.768048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.766396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>0.765844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.764110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_length_10+</th>\n",
       "      <td>0.745471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <td>0.722423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <td>0.715516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status_Source Verified</th>\n",
       "      <td>0.575880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <td>0.413331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_credit_pull_d_mon</th>\n",
       "      <td>0.279970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <td>0.232774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <td>0.024699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <td>0.016818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <td>0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <td>-0.016818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue_d_mon</th>\n",
       "      <td>-0.037399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <td>-0.052698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>-0.065885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_mon</th>\n",
       "      <td>-0.128532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <td>-0.369469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc_util</th>\n",
       "      <td>-0.406719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue_d_yr</th>\n",
       "      <td>-0.751754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_yr</th>\n",
       "      <td>-1.048155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>-1.452624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_credit_pull_d_yr</th>\n",
       "      <td>-1.837823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <td>-2.641405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_type_Individual</th>\n",
       "      <td>-13.906277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disbursement_method_Cash</th>\n",
       "      <td>-26.832160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Skew\n",
       "tot_coll_amt                         868.224262\n",
       "addr_state_IA                        344.479732\n",
       "sec_app_chargeoff_within_12_mths     291.800358\n",
       "sec_app_collections_12_mths_ex_med   289.936477\n",
       "sec_app_open_act_il                   66.269959\n",
       "sec_app_mths_since_last_major_derog   61.649797\n",
       "sec_app_inq_last_6mths                59.804717\n",
       "total_rev_hi_lim                      57.101681\n",
       "revol_bal_joint                       51.782773\n",
       "purpose_educational                   50.920438\n",
       "num_tl_120dpd_2m                      49.018559\n",
       "sec_app_mort_acc                      47.834308\n",
       "annual_inc                            44.635559\n",
       "tax_liens                             41.839451\n",
       "sec_app_num_rev_accts                 41.055559\n",
       "addr_state_ID                         38.824439\n",
       "sec_app_open_acc                      37.355993\n",
       "purpose_renewable_energy              36.711144\n",
       "addr_state_ND                         36.299375\n",
       "sub_grade_G5                          35.679330\n",
       "addr_state_ME                         33.969748\n",
       "sec_app_revol_util                    32.146604\n",
       "sub_grade_G4                          31.722843\n",
       "sub_grade_G3                          27.589870\n",
       "disbursement_method_DirectPay         26.832160\n",
       "addr_state_NE                         23.790000\n",
       "sub_grade_G2                          23.205980\n",
       "addr_state_VT                         22.914876\n",
       "num_tl_30dpd                          21.931103\n",
       "addr_state_SD                         21.914366\n",
       "...                                         ...\n",
       "total_acc                              0.915511\n",
       "verification_status_Not Verified       0.830687\n",
       "num_sats                               0.768048\n",
       "funded_amnt                            0.766396\n",
       "funded_amnt_inv                        0.765844\n",
       "loan_amnt                              0.764110\n",
       "emp_length_10+                         0.745471\n",
       "verification_status_Verified           0.722423\n",
       "mo_sin_old_rev_tl_op                   0.715516\n",
       "verification_status_Source Verified    0.575880\n",
       "home_ownership_RENT                    0.413331\n",
       "last_credit_pull_d_mon                 0.279970\n",
       "percent_bc_gt_75                       0.232774\n",
       "zip_code                               0.024699\n",
       "initial_list_status_w                  0.016818\n",
       "home_ownership_MORTGAGE                0.002588\n",
       "initial_list_status_f                 -0.016818\n",
       "issue_d_mon                           -0.037399\n",
       "mo_sin_old_il_acct                    -0.052698\n",
       "revol_util                            -0.065885\n",
       "earliest_cr_line_mon                  -0.128532\n",
       "purpose_debt_consolidation            -0.369469\n",
       "bc_util                               -0.406719\n",
       "issue_d_yr                            -0.751754\n",
       "earliest_cr_line_yr                   -1.048155\n",
       "loan_status                           -1.452624\n",
       "last_credit_pull_d_yr                 -1.837823\n",
       "pct_tl_nvr_dlq                        -2.641405\n",
       "application_type_Individual          -13.906277\n",
       "disbursement_method_Cash             -26.832160\n",
       "\n",
       "[221 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highly skewed features\n",
    "\n",
    "skewed_features = df.apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew': skewed_features})\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 221 skewed features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print('There are {} skewed features to Box Cox transform'.format(skewness.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    df[feat] = boxcox1p(df[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830685, 221)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>disbursement_method_Cash</th>\n",
       "      <th>disbursement_method_DirectPay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>341007</th>\n",
       "      <td>18.270678</td>\n",
       "      <td>18.270678</td>\n",
       "      <td>18.270678</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.315257</td>\n",
       "      <td>24.628632</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.892039</td>\n",
       "      <td>3.701973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439960</th>\n",
       "      <td>18.491718</td>\n",
       "      <td>18.491718</td>\n",
       "      <td>18.491718</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.315257</td>\n",
       "      <td>30.446771</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>8.002449</td>\n",
       "      <td>2.750250</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158396</th>\n",
       "      <td>21.812732</td>\n",
       "      <td>21.812732</td>\n",
       "      <td>21.812732</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.463745</td>\n",
       "      <td>31.617040</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.047664</td>\n",
       "      <td>2.885846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543282</th>\n",
       "      <td>24.628632</td>\n",
       "      <td>24.628632</td>\n",
       "      <td>24.628632</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.136082</td>\n",
       "      <td>30.506041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.380946</td>\n",
       "      <td>4.003419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660761</th>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.830886</td>\n",
       "      <td>28.395339</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.184716</td>\n",
       "      <td>3.618223</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692733</th>\n",
       "      <td>23.206076</td>\n",
       "      <td>23.206076</td>\n",
       "      <td>23.206076</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.101459</td>\n",
       "      <td>31.813889</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.514262</td>\n",
       "      <td>3.340760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705925</th>\n",
       "      <td>12.125370</td>\n",
       "      <td>12.125370</td>\n",
       "      <td>12.125370</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>4.745132</td>\n",
       "      <td>23.383907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.984426</td>\n",
       "      <td>3.618223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170841</th>\n",
       "      <td>19.000645</td>\n",
       "      <td>19.000645</td>\n",
       "      <td>19.000645</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.970600</td>\n",
       "      <td>29.239480</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.999087</td>\n",
       "      <td>3.701973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83614</th>\n",
       "      <td>24.581490</td>\n",
       "      <td>24.581490</td>\n",
       "      <td>24.581490</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.292803</td>\n",
       "      <td>28.557548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.800080</td>\n",
       "      <td>3.438110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681686</th>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.322492</td>\n",
       "      <td>29.588763</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.916131</td>\n",
       "      <td>3.701973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266461</th>\n",
       "      <td>23.692253</td>\n",
       "      <td>23.692253</td>\n",
       "      <td>23.692253</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.634887</td>\n",
       "      <td>28.869811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.473163</td>\n",
       "      <td>4.380946</td>\n",
       "      <td>1.540963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475384</th>\n",
       "      <td>18.213642</td>\n",
       "      <td>18.213642</td>\n",
       "      <td>18.213642</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.335517</td>\n",
       "      <td>25.686058</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.541318</td>\n",
       "      <td>3.530419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202670</th>\n",
       "      <td>25.357236</td>\n",
       "      <td>25.357236</td>\n",
       "      <td>25.353802</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>12.153411</td>\n",
       "      <td>33.561213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.685747</td>\n",
       "      <td>3.530419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800690</th>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.018228</td>\n",
       "      <td>30.535477</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.800080</td>\n",
       "      <td>3.858807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755508</th>\n",
       "      <td>22.602295</td>\n",
       "      <td>22.602295</td>\n",
       "      <td>22.602295</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.072965</td>\n",
       "      <td>28.869811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.736626</td>\n",
       "      <td>4.137711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447806</th>\n",
       "      <td>24.628632</td>\n",
       "      <td>24.628632</td>\n",
       "      <td>24.628632</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.116894</td>\n",
       "      <td>29.451339</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.993231</td>\n",
       "      <td>3.932510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338675</th>\n",
       "      <td>20.802161</td>\n",
       "      <td>20.802161</td>\n",
       "      <td>20.802161</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.040245</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.732788</td>\n",
       "      <td>3.237728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808829</th>\n",
       "      <td>17.253669</td>\n",
       "      <td>17.253669</td>\n",
       "      <td>17.253669</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>7.483296</td>\n",
       "      <td>33.928699</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.826617</td>\n",
       "      <td>2.750250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368210</th>\n",
       "      <td>17.070370</td>\n",
       "      <td>17.070370</td>\n",
       "      <td>17.070370</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>7.836797</td>\n",
       "      <td>32.889081</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.210715</td>\n",
       "      <td>2.602594</td>\n",
       "      <td>1.540963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>19.000645</td>\n",
       "      <td>19.000645</td>\n",
       "      <td>19.000645</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.763534</td>\n",
       "      <td>26.008617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.881111</td>\n",
       "      <td>4.071754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390676</th>\n",
       "      <td>17.663696</td>\n",
       "      <td>17.663696</td>\n",
       "      <td>17.663696</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.025268</td>\n",
       "      <td>22.513737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.860283</td>\n",
       "      <td>4.380946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646251</th>\n",
       "      <td>18.702272</td>\n",
       "      <td>18.702272</td>\n",
       "      <td>18.702272</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.365619</td>\n",
       "      <td>28.869811</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.899104</td>\n",
       "      <td>3.530419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741684</th>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>9.405519</td>\n",
       "      <td>28.057555</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>12.082859</td>\n",
       "      <td>2.602594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265450</th>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>12.700940</td>\n",
       "      <td>31.362625</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>12.048452</td>\n",
       "      <td>3.011340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425691</th>\n",
       "      <td>23.123972</td>\n",
       "      <td>23.123972</td>\n",
       "      <td>23.123972</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.050764</td>\n",
       "      <td>29.239480</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>5.942124</td>\n",
       "      <td>3.128239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755320</th>\n",
       "      <td>15.517294</td>\n",
       "      <td>15.517294</td>\n",
       "      <td>15.517294</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>6.694191</td>\n",
       "      <td>29.239480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.033700</td>\n",
       "      <td>4.263161</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101876</th>\n",
       "      <td>17.962596</td>\n",
       "      <td>17.962596</td>\n",
       "      <td>17.962596</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.375577</td>\n",
       "      <td>23.306941</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.314735</td>\n",
       "      <td>3.128239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220711</th>\n",
       "      <td>23.154912</td>\n",
       "      <td>23.154912</td>\n",
       "      <td>23.154912</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.634887</td>\n",
       "      <td>27.569792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.654950</td>\n",
       "      <td>4.545286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80006</th>\n",
       "      <td>19.189158</td>\n",
       "      <td>19.189158</td>\n",
       "      <td>19.189158</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.041487</td>\n",
       "      <td>29.167258</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.894096</td>\n",
       "      <td>4.201461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98186</th>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.019154</td>\n",
       "      <td>30.173194</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>5.914940</td>\n",
       "      <td>4.003419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423196</th>\n",
       "      <td>20.777526</td>\n",
       "      <td>20.777526</td>\n",
       "      <td>20.777526</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.835883</td>\n",
       "      <td>32.327599</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.258334</td>\n",
       "      <td>2.259674</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152975</th>\n",
       "      <td>22.998360</td>\n",
       "      <td>22.998360</td>\n",
       "      <td>22.993060</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.101459</td>\n",
       "      <td>31.362625</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.654950</td>\n",
       "      <td>4.322948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584468</th>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.843317</td>\n",
       "      <td>30.234988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.419146</td>\n",
       "      <td>4.545286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540353</th>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.357236</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.864722</td>\n",
       "      <td>30.234988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.882959</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9251</th>\n",
       "      <td>18.753396</td>\n",
       "      <td>18.753396</td>\n",
       "      <td>18.753396</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.658271</td>\n",
       "      <td>29.919958</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.905600</td>\n",
       "      <td>3.530419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252892</th>\n",
       "      <td>20.256340</td>\n",
       "      <td>20.256340</td>\n",
       "      <td>20.256340</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.459637</td>\n",
       "      <td>29.588763</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.934084</td>\n",
       "      <td>3.011340</td>\n",
       "      <td>1.194318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266894</th>\n",
       "      <td>17.916752</td>\n",
       "      <td>17.916752</td>\n",
       "      <td>17.916752</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>7.897190</td>\n",
       "      <td>28.476974</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.996045</td>\n",
       "      <td>2.885846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641001</th>\n",
       "      <td>19.512198</td>\n",
       "      <td>19.512198</td>\n",
       "      <td>19.512198</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.103010</td>\n",
       "      <td>25.758185</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.818201</td>\n",
       "      <td>3.438110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537048</th>\n",
       "      <td>21.380786</td>\n",
       "      <td>21.380786</td>\n",
       "      <td>21.380786</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>9.258334</td>\n",
       "      <td>27.069896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.766932</td>\n",
       "      <td>4.545286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338142</th>\n",
       "      <td>20.610004</td>\n",
       "      <td>20.610004</td>\n",
       "      <td>20.610004</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.721963</td>\n",
       "      <td>28.057555</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.640795</td>\n",
       "      <td>2.440268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111081</th>\n",
       "      <td>22.320331</td>\n",
       "      <td>22.320331</td>\n",
       "      <td>22.320331</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.714795</td>\n",
       "      <td>30.923266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.766932</td>\n",
       "      <td>3.128239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144113</th>\n",
       "      <td>22.320331</td>\n",
       "      <td>22.320331</td>\n",
       "      <td>22.308239</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.661756</td>\n",
       "      <td>26.008617</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>7.566243</td>\n",
       "      <td>4.647709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142640</th>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>12.689052</td>\n",
       "      <td>36.723955</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.339779</td>\n",
       "      <td>3.530419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266727</th>\n",
       "      <td>19.370190</td>\n",
       "      <td>19.370190</td>\n",
       "      <td>19.370190</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.797736</td>\n",
       "      <td>24.628632</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.723546</td>\n",
       "      <td>4.003419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745998</th>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.477987</td>\n",
       "      <td>28.057555</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.185445</td>\n",
       "      <td>3.340760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291560</th>\n",
       "      <td>23.598505</td>\n",
       "      <td>23.598505</td>\n",
       "      <td>23.598505</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.753980</td>\n",
       "      <td>26.914539</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.148461</td>\n",
       "      <td>4.071754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294589</th>\n",
       "      <td>24.933056</td>\n",
       "      <td>24.933056</td>\n",
       "      <td>24.933056</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.219143</td>\n",
       "      <td>29.723296</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>3.701973</td>\n",
       "      <td>3.618223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751790</th>\n",
       "      <td>26.008617</td>\n",
       "      <td>26.008617</td>\n",
       "      <td>26.008617</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>12.876739</td>\n",
       "      <td>32.763482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.214828</td>\n",
       "      <td>3.618223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304575</th>\n",
       "      <td>19.436276</td>\n",
       "      <td>19.436276</td>\n",
       "      <td>19.436276</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.412341</td>\n",
       "      <td>24.628632</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.732788</td>\n",
       "      <td>4.263161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378727</th>\n",
       "      <td>18.753396</td>\n",
       "      <td>18.753396</td>\n",
       "      <td>18.753396</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.622254</td>\n",
       "      <td>27.417396</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.147932</td>\n",
       "      <td>3.011340</td>\n",
       "      <td>1.540963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709210</th>\n",
       "      <td>17.253669</td>\n",
       "      <td>17.253669</td>\n",
       "      <td>17.253669</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>7.483296</td>\n",
       "      <td>28.476974</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.462910</td>\n",
       "      <td>3.128239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823509</th>\n",
       "      <td>23.206076</td>\n",
       "      <td>23.206076</td>\n",
       "      <td>23.206076</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.444651</td>\n",
       "      <td>28.945501</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.803188</td>\n",
       "      <td>3.858807</td>\n",
       "      <td>1.540963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156102</th>\n",
       "      <td>20.939446</td>\n",
       "      <td>20.939446</td>\n",
       "      <td>20.939446</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.984891</td>\n",
       "      <td>31.465548</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.870812</td>\n",
       "      <td>3.618223</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352007</th>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.251130</td>\n",
       "      <td>25.884766</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.892039</td>\n",
       "      <td>2.885846</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220387</th>\n",
       "      <td>23.598505</td>\n",
       "      <td>23.598505</td>\n",
       "      <td>23.598505</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.607780</td>\n",
       "      <td>33.370093</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>8.036603</td>\n",
       "      <td>1.194318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7898</th>\n",
       "      <td>17.916752</td>\n",
       "      <td>17.916752</td>\n",
       "      <td>17.901363</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.025268</td>\n",
       "      <td>24.378963</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.966746</td>\n",
       "      <td>2.602594</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542413</th>\n",
       "      <td>19.670808</td>\n",
       "      <td>19.670808</td>\n",
       "      <td>19.670808</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.148276</td>\n",
       "      <td>28.228763</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>8.962610</td>\n",
       "      <td>3.858807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551670</th>\n",
       "      <td>17.916752</td>\n",
       "      <td>17.916752</td>\n",
       "      <td>17.916752</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>7.920955</td>\n",
       "      <td>29.919958</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>5.968981</td>\n",
       "      <td>2.602594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715107</th>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.265520</td>\n",
       "      <td>26.914539</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.803188</td>\n",
       "      <td>4.263161</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375400</th>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.265520</td>\n",
       "      <td>27.607297</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.258334</td>\n",
       "      <td>3.858807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830685 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_amnt  funded_amnt  funded_amnt_inv      term  installment  \\\n",
       "341007  18.270678    18.270678        18.270678  4.792130     8.315257   \n",
       "439960  18.491718    18.491718        18.491718  4.792130     8.315257   \n",
       "158396  21.812732    21.812732        21.812732  4.792130    10.463745   \n",
       "543282  24.628632    24.628632        24.628632  5.684507    11.136082   \n",
       "660761  22.782058    22.782058        22.782058  4.792130    10.830886   \n",
       "692733  23.206076    23.206076        23.206076  4.792130    11.101459   \n",
       "705925  12.125370    12.125370        12.125370  4.792130     4.745132   \n",
       "170841  19.000645    19.000645        19.000645  4.792130     8.970600   \n",
       "83614   24.581490    24.581490        24.581490  5.684507    11.292803   \n",
       "681686  21.538377    21.538377        21.538377  4.792130    10.322492   \n",
       "266461  23.692253    23.692253        23.692253  5.684507    10.634887   \n",
       "475384  18.213642    18.213642        18.213642  4.792130     8.335517   \n",
       "202670  25.357236    25.357236        25.353802  5.684507    12.153411   \n",
       "800690  22.782058    22.782058        22.782058  5.684507    10.018228   \n",
       "755508  22.602295    22.602295        22.602295  5.684507    10.072965   \n",
       "447806  24.628632    24.628632        24.628632  5.684507    11.116894   \n",
       "338675  20.802161    20.802161        20.802161  4.792130    10.040245   \n",
       "808829  17.253669    17.253669        17.253669  4.792130     7.483296   \n",
       "368210  17.070370    17.070370        17.070370  4.792130     7.836797   \n",
       "3592    19.000645    19.000645        19.000645  4.792130     8.763534   \n",
       "390676  17.663696    17.663696        17.663696  4.792130     8.025268   \n",
       "646251  18.702272    18.702272        18.702272  4.792130     8.365619   \n",
       "741684  21.538377    21.538377        21.538377  5.684507     9.405519   \n",
       "265450  25.360669    25.360669        25.360669  4.792130    12.700940   \n",
       "425691  23.123972    23.123972        23.123972  4.792130    11.050764   \n",
       "755320  15.517294    15.517294        15.517294  4.792130     6.694191   \n",
       "101876  17.962596    17.962596        17.962596  4.792130     8.375577   \n",
       "220711  23.154912    23.154912        23.154912  5.684507    10.634887   \n",
       "80006   19.189158    19.189158        19.189158  4.792130     9.041487   \n",
       "98186   22.782058    22.782058        22.782058  4.792130    11.019154   \n",
       "...           ...          ...              ...       ...          ...   \n",
       "423196  20.777526    20.777526        20.777526  4.792130     9.835883   \n",
       "152975  22.998360    22.998360        22.993060  4.792130    11.101459   \n",
       "584468  25.360669    25.360669        25.360669  5.684507    11.843317   \n",
       "540353  25.360669    25.360669        25.357236  5.684507    11.864722   \n",
       "9251    18.753396    18.753396        18.753396  4.792130     8.658271   \n",
       "252892  20.256340    20.256340        20.256340  4.792130     9.459637   \n",
       "266894  17.916752    17.916752        17.916752  4.792130     7.897190   \n",
       "641001  19.512198    19.512198        19.512198  4.792130     9.103010   \n",
       "537048  21.380786    21.380786        21.380786  5.684507     9.258334   \n",
       "338142  20.610004    20.610004        20.610004  4.792130     9.721963   \n",
       "111081  22.320331    22.320331        22.320331  4.792130    10.714795   \n",
       "144113  22.320331    22.320331        22.308239  4.792130    10.661756   \n",
       "142640  25.360669    25.360669        25.360669  4.792130    12.689052   \n",
       "266727  19.370190    19.370190        19.370190  4.792130     8.797736   \n",
       "745998  21.538377    21.538377        21.538377  4.792130    10.477987   \n",
       "291560  23.598505    23.598505        23.598505  5.684507    10.753980   \n",
       "294589  24.933056    24.933056        24.933056  5.684507    11.219143   \n",
       "751790  26.008617    26.008617        26.008617  4.792130    12.876739   \n",
       "304575  19.436276    19.436276        19.436276  4.792130     9.412341   \n",
       "378727  18.753396    18.753396        18.753396  4.792130     8.622254   \n",
       "709210  17.253669    17.253669        17.253669  4.792130     7.483296   \n",
       "823509  23.206076    23.206076        23.206076  5.684507    10.444651   \n",
       "156102  20.939446    20.939446        20.939446  4.792130     9.984891   \n",
       "352007  19.874209    19.874209        19.874209  4.792130     9.251130   \n",
       "220387  23.598505    23.598505        23.598505  5.684507    10.607780   \n",
       "7898    17.916752    17.916752        17.901363  4.792130     8.025268   \n",
       "542413  19.670808    19.670808        19.670808  4.792130     9.148276   \n",
       "551670  17.916752    17.916752        17.916752  4.792130     7.920955   \n",
       "715107  19.874209    19.874209        19.874209  4.792130     9.265520   \n",
       "375400  19.874209    19.874209        19.874209  4.792130     9.265520   \n",
       "\n",
       "        annual_inc  loan_status   zip_code       dti  delinq_2yrs  \\\n",
       "341007   24.628632     0.730463  11.892039  3.701973     0.000000   \n",
       "439960   30.446771     0.730463   8.002449  2.750250     0.730463   \n",
       "158396   31.617040     0.730463   6.047664  2.885846     0.000000   \n",
       "543282   30.506041     0.000000   4.380946  4.003419     0.000000   \n",
       "660761   28.395339     0.730463  10.184716  3.618223     0.730463   \n",
       "692733   31.813889     0.730463  11.514262  3.340760     0.000000   \n",
       "705925   23.383907     0.000000  11.984426  3.618223     0.000000   \n",
       "170841   29.239480     0.730463  11.999087  3.701973     0.000000   \n",
       "83614    28.557548     0.000000  11.800080  3.438110     0.000000   \n",
       "681686   29.588763     0.730463  11.916131  3.701973     0.000000   \n",
       "266461   28.869811     0.000000   8.473163  4.380946     1.540963   \n",
       "475384   25.686058     0.730463  11.541318  3.530419     0.000000   \n",
       "202670   33.561213     0.000000   7.685747  3.530419     0.000000   \n",
       "800690   30.535477     0.730463  11.800080  3.858807     0.000000   \n",
       "755508   28.869811     0.000000  10.736626  4.137711     0.000000   \n",
       "447806   29.451339     0.730463  11.993231  3.932510     0.000000   \n",
       "338675   25.360669     0.730463   6.732788  3.237728     0.000000   \n",
       "808829   33.928699     0.730463   6.826617  2.750250     0.000000   \n",
       "368210   32.889081     0.730463  10.210715  2.602594     1.540963   \n",
       "3592     26.008617     0.000000  10.881111  4.071754     0.000000   \n",
       "390676   22.513737     0.000000  10.860283  4.380946     0.000000   \n",
       "646251   28.869811     0.730463   6.899104  3.530419     0.000000   \n",
       "741684   28.057555     0.730463  12.082859  2.602594     0.000000   \n",
       "265450   31.362625     0.730463  12.048452  3.011340     0.000000   \n",
       "425691   29.239480     0.730463   5.942124  3.128239     0.000000   \n",
       "755320   29.239480     0.000000   9.033700  4.263161     0.730463   \n",
       "101876   23.306941     0.730463   6.314735  3.128239     0.000000   \n",
       "220711   27.569792     0.000000   6.654950  4.545286     0.000000   \n",
       "80006    29.167258     0.730463   9.894096  4.201461     0.000000   \n",
       "98186    30.173194     0.730463   5.914940  4.003419     0.000000   \n",
       "...            ...          ...        ...       ...          ...   \n",
       "423196   32.327599     0.730463   9.258334  2.259674     0.730463   \n",
       "152975   31.362625     0.730463   6.654950  4.322948     0.000000   \n",
       "584468   30.234988     0.000000   9.419146  4.545286     0.000000   \n",
       "540353   30.234988     0.000000  11.882959  4.792130     0.000000   \n",
       "9251     29.919958     0.730463   9.905600  3.530419     0.000000   \n",
       "252892   29.588763     0.730463  11.934084  3.011340     1.194318   \n",
       "266894   28.476974     0.730463   9.996045  2.885846     0.000000   \n",
       "641001   25.758185     0.730463  10.818201  3.438110     0.000000   \n",
       "537048   27.069896     0.000000  10.766932  4.545286     0.000000   \n",
       "338142   28.057555     0.730463  11.640795  2.440268     0.000000   \n",
       "111081   30.923266     0.000000  10.766932  3.128239     0.000000   \n",
       "144113   26.008617     0.730463   7.566243  4.647709     0.000000   \n",
       "142640   36.723955     0.730463  11.339779  3.530419     0.000000   \n",
       "266727   24.628632     0.730463  10.723546  4.003419     0.000000   \n",
       "745998   28.057555     0.730463   9.185445  3.340760     0.000000   \n",
       "291560   26.914539     0.730463   6.148461  4.071754     0.000000   \n",
       "294589   29.723296     0.730463   3.701973  3.618223     0.000000   \n",
       "751790   32.763482     0.000000   9.214828  3.618223     0.000000   \n",
       "304575   24.628632     0.730463   6.732788  4.263161     0.000000   \n",
       "378727   27.417396     0.730463  10.147932  3.011340     1.540963   \n",
       "709210   28.476974     0.730463  11.462910  3.128239     0.000000   \n",
       "823509   28.945501     0.730463  11.803188  3.858807     1.540963   \n",
       "156102   31.465548     0.730463  11.870812  3.618223     0.730463   \n",
       "352007   25.884766     0.000000  11.892039  2.885846     0.730463   \n",
       "220387   33.370093     0.730463   8.036603  1.194318     0.000000   \n",
       "7898     24.378963     0.730463  11.966746  2.602594     0.730463   \n",
       "542413   28.228763     0.730463   8.962610  3.858807     0.000000   \n",
       "551670   29.919958     0.730463   5.968981  2.602594     0.000000   \n",
       "715107   26.914539     0.730463  11.803188  4.263161     0.730463   \n",
       "375400   27.607297     0.730463   9.258334  3.858807     0.000000   \n",
       "\n",
       "                    ...                addr_state_WA  addr_state_WI  \\\n",
       "341007              ...                     0.000000            0.0   \n",
       "439960              ...                     0.000000            0.0   \n",
       "158396              ...                     0.000000            0.0   \n",
       "543282              ...                     0.000000            0.0   \n",
       "660761              ...                     0.000000            0.0   \n",
       "692733              ...                     0.000000            0.0   \n",
       "705925              ...                     0.000000            0.0   \n",
       "170841              ...                     0.000000            0.0   \n",
       "83614               ...                     0.000000            0.0   \n",
       "681686              ...                     0.000000            0.0   \n",
       "266461              ...                     0.000000            0.0   \n",
       "475384              ...                     0.000000            0.0   \n",
       "202670              ...                     0.000000            0.0   \n",
       "800690              ...                     0.000000            0.0   \n",
       "755508              ...                     0.000000            0.0   \n",
       "447806              ...                     0.000000            0.0   \n",
       "338675              ...                     0.000000            0.0   \n",
       "808829              ...                     0.000000            0.0   \n",
       "368210              ...                     0.000000            0.0   \n",
       "3592                ...                     0.000000            0.0   \n",
       "390676              ...                     0.000000            0.0   \n",
       "646251              ...                     0.000000            0.0   \n",
       "741684              ...                     0.730463            0.0   \n",
       "265450              ...                     0.000000            0.0   \n",
       "425691              ...                     0.000000            0.0   \n",
       "755320              ...                     0.000000            0.0   \n",
       "101876              ...                     0.000000            0.0   \n",
       "220711              ...                     0.000000            0.0   \n",
       "80006               ...                     0.000000            0.0   \n",
       "98186               ...                     0.000000            0.0   \n",
       "...                 ...                          ...            ...   \n",
       "423196              ...                     0.000000            0.0   \n",
       "152975              ...                     0.000000            0.0   \n",
       "584468              ...                     0.000000            0.0   \n",
       "540353              ...                     0.000000            0.0   \n",
       "9251                ...                     0.000000            0.0   \n",
       "252892              ...                     0.000000            0.0   \n",
       "266894              ...                     0.000000            0.0   \n",
       "641001              ...                     0.000000            0.0   \n",
       "537048              ...                     0.000000            0.0   \n",
       "338142              ...                     0.000000            0.0   \n",
       "111081              ...                     0.000000            0.0   \n",
       "144113              ...                     0.000000            0.0   \n",
       "142640              ...                     0.000000            0.0   \n",
       "266727              ...                     0.000000            0.0   \n",
       "745998              ...                     0.000000            0.0   \n",
       "291560              ...                     0.000000            0.0   \n",
       "294589              ...                     0.000000            0.0   \n",
       "751790              ...                     0.000000            0.0   \n",
       "304575              ...                     0.000000            0.0   \n",
       "378727              ...                     0.000000            0.0   \n",
       "709210              ...                     0.000000            0.0   \n",
       "823509              ...                     0.000000            0.0   \n",
       "156102              ...                     0.000000            0.0   \n",
       "352007              ...                     0.000000            0.0   \n",
       "220387              ...                     0.000000            0.0   \n",
       "7898                ...                     0.000000            0.0   \n",
       "542413              ...                     0.000000            0.0   \n",
       "551670              ...                     0.000000            0.0   \n",
       "715107              ...                     0.000000            0.0   \n",
       "375400              ...                     0.000000            0.0   \n",
       "\n",
       "        addr_state_WV  addr_state_WY  initial_list_status_f  \\\n",
       "341007            0.0            0.0               0.730463   \n",
       "439960            0.0            0.0               0.000000   \n",
       "158396            0.0            0.0               0.730463   \n",
       "543282            0.0            0.0               0.000000   \n",
       "660761            0.0            0.0               0.000000   \n",
       "692733            0.0            0.0               0.000000   \n",
       "705925            0.0            0.0               0.000000   \n",
       "170841            0.0            0.0               0.730463   \n",
       "83614             0.0            0.0               0.730463   \n",
       "681686            0.0            0.0               0.000000   \n",
       "266461            0.0            0.0               0.000000   \n",
       "475384            0.0            0.0               0.730463   \n",
       "202670            0.0            0.0               0.730463   \n",
       "800690            0.0            0.0               0.000000   \n",
       "755508            0.0            0.0               0.000000   \n",
       "447806            0.0            0.0               0.000000   \n",
       "338675            0.0            0.0               0.000000   \n",
       "808829            0.0            0.0               0.730463   \n",
       "368210            0.0            0.0               0.000000   \n",
       "3592              0.0            0.0               0.730463   \n",
       "390676            0.0            0.0               0.730463   \n",
       "646251            0.0            0.0               0.730463   \n",
       "741684            0.0            0.0               0.000000   \n",
       "265450            0.0            0.0               0.730463   \n",
       "425691            0.0            0.0               0.730463   \n",
       "755320            0.0            0.0               0.730463   \n",
       "101876            0.0            0.0               0.730463   \n",
       "220711            0.0            0.0               0.000000   \n",
       "80006             0.0            0.0               0.730463   \n",
       "98186             0.0            0.0               0.730463   \n",
       "...               ...            ...                    ...   \n",
       "423196            0.0            0.0               0.730463   \n",
       "152975            0.0            0.0               0.730463   \n",
       "584468            0.0            0.0               0.000000   \n",
       "540353            0.0            0.0               0.730463   \n",
       "9251              0.0            0.0               0.730463   \n",
       "252892            0.0            0.0               0.000000   \n",
       "266894            0.0            0.0               0.730463   \n",
       "641001            0.0            0.0               0.000000   \n",
       "537048            0.0            0.0               0.000000   \n",
       "338142            0.0            0.0               0.730463   \n",
       "111081            0.0            0.0               0.000000   \n",
       "144113            0.0            0.0               0.730463   \n",
       "142640            0.0            0.0               0.000000   \n",
       "266727            0.0            0.0               0.000000   \n",
       "745998            0.0            0.0               0.000000   \n",
       "291560            0.0            0.0               0.000000   \n",
       "294589            0.0            0.0               0.730463   \n",
       "751790            0.0            0.0               0.730463   \n",
       "304575            0.0            0.0               0.730463   \n",
       "378727            0.0            0.0               0.000000   \n",
       "709210            0.0            0.0               0.730463   \n",
       "823509            0.0            0.0               0.000000   \n",
       "156102            0.0            0.0               0.730463   \n",
       "352007            0.0            0.0               0.000000   \n",
       "220387            0.0            0.0               0.000000   \n",
       "7898              0.0            0.0               0.730463   \n",
       "542413            0.0            0.0               0.730463   \n",
       "551670            0.0            0.0               0.000000   \n",
       "715107            0.0            0.0               0.000000   \n",
       "375400            0.0            0.0               0.000000   \n",
       "\n",
       "        initial_list_status_w  application_type_Individual  \\\n",
       "341007               0.000000                     0.730463   \n",
       "439960               0.730463                     0.730463   \n",
       "158396               0.000000                     0.730463   \n",
       "543282               0.730463                     0.730463   \n",
       "660761               0.730463                     0.730463   \n",
       "692733               0.730463                     0.730463   \n",
       "705925               0.730463                     0.730463   \n",
       "170841               0.000000                     0.730463   \n",
       "83614                0.000000                     0.730463   \n",
       "681686               0.730463                     0.730463   \n",
       "266461               0.730463                     0.730463   \n",
       "475384               0.000000                     0.730463   \n",
       "202670               0.000000                     0.730463   \n",
       "800690               0.730463                     0.730463   \n",
       "755508               0.730463                     0.730463   \n",
       "447806               0.730463                     0.730463   \n",
       "338675               0.730463                     0.730463   \n",
       "808829               0.000000                     0.730463   \n",
       "368210               0.730463                     0.730463   \n",
       "3592                 0.000000                     0.730463   \n",
       "390676               0.000000                     0.730463   \n",
       "646251               0.000000                     0.730463   \n",
       "741684               0.730463                     0.730463   \n",
       "265450               0.000000                     0.730463   \n",
       "425691               0.000000                     0.730463   \n",
       "755320               0.000000                     0.730463   \n",
       "101876               0.000000                     0.730463   \n",
       "220711               0.730463                     0.730463   \n",
       "80006                0.000000                     0.730463   \n",
       "98186                0.000000                     0.730463   \n",
       "...                       ...                          ...   \n",
       "423196               0.000000                     0.730463   \n",
       "152975               0.000000                     0.730463   \n",
       "584468               0.730463                     0.730463   \n",
       "540353               0.000000                     0.730463   \n",
       "9251                 0.000000                     0.730463   \n",
       "252892               0.730463                     0.730463   \n",
       "266894               0.000000                     0.730463   \n",
       "641001               0.730463                     0.730463   \n",
       "537048               0.730463                     0.730463   \n",
       "338142               0.000000                     0.730463   \n",
       "111081               0.730463                     0.730463   \n",
       "144113               0.000000                     0.730463   \n",
       "142640               0.730463                     0.730463   \n",
       "266727               0.730463                     0.730463   \n",
       "745998               0.730463                     0.730463   \n",
       "291560               0.730463                     0.730463   \n",
       "294589               0.000000                     0.730463   \n",
       "751790               0.000000                     0.730463   \n",
       "304575               0.000000                     0.730463   \n",
       "378727               0.730463                     0.730463   \n",
       "709210               0.000000                     0.730463   \n",
       "823509               0.730463                     0.730463   \n",
       "156102               0.000000                     0.730463   \n",
       "352007               0.730463                     0.730463   \n",
       "220387               0.730463                     0.730463   \n",
       "7898                 0.000000                     0.730463   \n",
       "542413               0.000000                     0.730463   \n",
       "551670               0.730463                     0.730463   \n",
       "715107               0.730463                     0.730463   \n",
       "375400               0.730463                     0.730463   \n",
       "\n",
       "        application_type_Joint App  disbursement_method_Cash  \\\n",
       "341007                         0.0                  0.730463   \n",
       "439960                         0.0                  0.730463   \n",
       "158396                         0.0                  0.730463   \n",
       "543282                         0.0                  0.730463   \n",
       "660761                         0.0                  0.730463   \n",
       "692733                         0.0                  0.730463   \n",
       "705925                         0.0                  0.730463   \n",
       "170841                         0.0                  0.730463   \n",
       "83614                          0.0                  0.730463   \n",
       "681686                         0.0                  0.730463   \n",
       "266461                         0.0                  0.730463   \n",
       "475384                         0.0                  0.730463   \n",
       "202670                         0.0                  0.730463   \n",
       "800690                         0.0                  0.730463   \n",
       "755508                         0.0                  0.730463   \n",
       "447806                         0.0                  0.730463   \n",
       "338675                         0.0                  0.730463   \n",
       "808829                         0.0                  0.730463   \n",
       "368210                         0.0                  0.730463   \n",
       "3592                           0.0                  0.730463   \n",
       "390676                         0.0                  0.730463   \n",
       "646251                         0.0                  0.730463   \n",
       "741684                         0.0                  0.730463   \n",
       "265450                         0.0                  0.730463   \n",
       "425691                         0.0                  0.730463   \n",
       "755320                         0.0                  0.730463   \n",
       "101876                         0.0                  0.730463   \n",
       "220711                         0.0                  0.730463   \n",
       "80006                          0.0                  0.730463   \n",
       "98186                          0.0                  0.730463   \n",
       "...                            ...                       ...   \n",
       "423196                         0.0                  0.730463   \n",
       "152975                         0.0                  0.730463   \n",
       "584468                         0.0                  0.730463   \n",
       "540353                         0.0                  0.730463   \n",
       "9251                           0.0                  0.730463   \n",
       "252892                         0.0                  0.730463   \n",
       "266894                         0.0                  0.730463   \n",
       "641001                         0.0                  0.730463   \n",
       "537048                         0.0                  0.730463   \n",
       "338142                         0.0                  0.730463   \n",
       "111081                         0.0                  0.730463   \n",
       "144113                         0.0                  0.730463   \n",
       "142640                         0.0                  0.730463   \n",
       "266727                         0.0                  0.730463   \n",
       "745998                         0.0                  0.730463   \n",
       "291560                         0.0                  0.730463   \n",
       "294589                         0.0                  0.730463   \n",
       "751790                         0.0                  0.730463   \n",
       "304575                         0.0                  0.730463   \n",
       "378727                         0.0                  0.730463   \n",
       "709210                         0.0                  0.730463   \n",
       "823509                         0.0                  0.730463   \n",
       "156102                         0.0                  0.730463   \n",
       "352007                         0.0                  0.730463   \n",
       "220387                         0.0                  0.730463   \n",
       "7898                           0.0                  0.730463   \n",
       "542413                         0.0                  0.730463   \n",
       "551670                         0.0                  0.730463   \n",
       "715107                         0.0                  0.730463   \n",
       "375400                         0.0                  0.730463   \n",
       "\n",
       "        disbursement_method_DirectPay  \n",
       "341007                            0.0  \n",
       "439960                            0.0  \n",
       "158396                            0.0  \n",
       "543282                            0.0  \n",
       "660761                            0.0  \n",
       "692733                            0.0  \n",
       "705925                            0.0  \n",
       "170841                            0.0  \n",
       "83614                             0.0  \n",
       "681686                            0.0  \n",
       "266461                            0.0  \n",
       "475384                            0.0  \n",
       "202670                            0.0  \n",
       "800690                            0.0  \n",
       "755508                            0.0  \n",
       "447806                            0.0  \n",
       "338675                            0.0  \n",
       "808829                            0.0  \n",
       "368210                            0.0  \n",
       "3592                              0.0  \n",
       "390676                            0.0  \n",
       "646251                            0.0  \n",
       "741684                            0.0  \n",
       "265450                            0.0  \n",
       "425691                            0.0  \n",
       "755320                            0.0  \n",
       "101876                            0.0  \n",
       "220711                            0.0  \n",
       "80006                             0.0  \n",
       "98186                             0.0  \n",
       "...                               ...  \n",
       "423196                            0.0  \n",
       "152975                            0.0  \n",
       "584468                            0.0  \n",
       "540353                            0.0  \n",
       "9251                              0.0  \n",
       "252892                            0.0  \n",
       "266894                            0.0  \n",
       "641001                            0.0  \n",
       "537048                            0.0  \n",
       "338142                            0.0  \n",
       "111081                            0.0  \n",
       "144113                            0.0  \n",
       "142640                            0.0  \n",
       "266727                            0.0  \n",
       "745998                            0.0  \n",
       "291560                            0.0  \n",
       "294589                            0.0  \n",
       "751790                            0.0  \n",
       "304575                            0.0  \n",
       "378727                            0.0  \n",
       "709210                            0.0  \n",
       "823509                            0.0  \n",
       "156102                            0.0  \n",
       "352007                            0.0  \n",
       "220387                            0.0  \n",
       "7898                              0.0  \n",
       "542413                            0.0  \n",
       "551670                            0.0  \n",
       "715107                            0.0  \n",
       "375400                            0.0  \n",
       "\n",
       "[830685 rows x 221 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a scatter matrix for each pair of features in the data\n",
    "# pd.scatter_matrix(df, alpha = 0.3, figsize = (14,8), diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>disbursement_method_Cash</th>\n",
       "      <th>disbursement_method_DirectPay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999482</td>\n",
       "      <td>0.991030</td>\n",
       "      <td>0.391044</td>\n",
       "      <td>0.973896</td>\n",
       "      <td>0.473329</td>\n",
       "      <td>-0.067809</td>\n",
       "      <td>-0.008859</td>\n",
       "      <td>0.059263</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>-0.007850</td>\n",
       "      <td>-0.002438</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>-0.072259</td>\n",
       "      <td>0.072259</td>\n",
       "      <td>-0.039187</td>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>-0.003903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.999482</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992027</td>\n",
       "      <td>0.390090</td>\n",
       "      <td>0.974742</td>\n",
       "      <td>0.473149</td>\n",
       "      <td>-0.067918</td>\n",
       "      <td>-0.008743</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>-0.007811</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>-0.073632</td>\n",
       "      <td>0.073632</td>\n",
       "      <td>-0.039297</td>\n",
       "      <td>0.039297</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>-0.003854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>0.991030</td>\n",
       "      <td>0.992027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388473</td>\n",
       "      <td>0.966802</td>\n",
       "      <td>0.469245</td>\n",
       "      <td>-0.066945</td>\n",
       "      <td>-0.008051</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>-0.007648</td>\n",
       "      <td>-0.002108</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>-0.079273</td>\n",
       "      <td>0.079273</td>\n",
       "      <td>-0.039320</td>\n",
       "      <td>0.039320</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>-0.003639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0.391044</td>\n",
       "      <td>0.390090</td>\n",
       "      <td>0.388473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202778</td>\n",
       "      <td>0.117914</td>\n",
       "      <td>-0.177266</td>\n",
       "      <td>-0.015615</td>\n",
       "      <td>0.078886</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002266</td>\n",
       "      <td>-0.001120</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>-0.105259</td>\n",
       "      <td>0.105259</td>\n",
       "      <td>-0.022416</td>\n",
       "      <td>0.022416</td>\n",
       "      <td>-0.002836</td>\n",
       "      <td>0.002836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0.973896</td>\n",
       "      <td>0.974742</td>\n",
       "      <td>0.966802</td>\n",
       "      <td>0.202778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458902</td>\n",
       "      <td>-0.055909</td>\n",
       "      <td>-0.005181</td>\n",
       "      <td>0.061958</td>\n",
       "      <td>0.013088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>-0.008558</td>\n",
       "      <td>-0.004545</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>-0.039278</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>-0.038442</td>\n",
       "      <td>0.038442</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.001185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>0.473329</td>\n",
       "      <td>0.473149</td>\n",
       "      <td>0.469245</td>\n",
       "      <td>0.117914</td>\n",
       "      <td>0.458902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073626</td>\n",
       "      <td>-0.018684</td>\n",
       "      <td>-0.204691</td>\n",
       "      <td>0.081714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>-0.023125</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>-0.001996</td>\n",
       "      <td>-0.070210</td>\n",
       "      <td>0.070210</td>\n",
       "      <td>0.038470</td>\n",
       "      <td>-0.038470</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>-0.018666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>-0.067809</td>\n",
       "      <td>-0.067918</td>\n",
       "      <td>-0.066945</td>\n",
       "      <td>-0.177266</td>\n",
       "      <td>-0.055909</td>\n",
       "      <td>0.073626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010264</td>\n",
       "      <td>-0.116495</td>\n",
       "      <td>-0.022806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.017221</td>\n",
       "      <td>-0.017221</td>\n",
       "      <td>-0.003934</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.024749</td>\n",
       "      <td>-0.024749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <td>-0.008859</td>\n",
       "      <td>-0.008743</td>\n",
       "      <td>-0.008051</td>\n",
       "      <td>-0.015615</td>\n",
       "      <td>-0.005181</td>\n",
       "      <td>-0.018684</td>\n",
       "      <td>0.010264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>-0.027382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166768</td>\n",
       "      <td>0.037518</td>\n",
       "      <td>-0.032957</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>-0.004923</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>-0.010975</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>-0.002253</td>\n",
       "      <td>0.002253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>0.059263</td>\n",
       "      <td>0.059948</td>\n",
       "      <td>0.063721</td>\n",
       "      <td>0.078886</td>\n",
       "      <td>0.061958</td>\n",
       "      <td>-0.204691</td>\n",
       "      <td>-0.116495</td>\n",
       "      <td>0.030521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.013316</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>-0.035859</td>\n",
       "      <td>0.035859</td>\n",
       "      <td>-0.050293</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>-0.068471</td>\n",
       "      <td>0.068471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.004714</td>\n",
       "      <td>0.013088</td>\n",
       "      <td>0.081714</td>\n",
       "      <td>-0.022806</td>\n",
       "      <td>-0.027382</td>\n",
       "      <td>-0.003053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008047</td>\n",
       "      <td>-0.003831</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>-0.000627</td>\n",
       "      <td>-0.018504</td>\n",
       "      <td>0.018504</td>\n",
       "      <td>-0.002948</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <td>-0.020058</td>\n",
       "      <td>-0.020291</td>\n",
       "      <td>-0.022149</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.047620</td>\n",
       "      <td>-0.060134</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.022908</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>0.025113</td>\n",
       "      <td>-0.000835</td>\n",
       "      <td>-0.001463</td>\n",
       "      <td>0.063113</td>\n",
       "      <td>-0.063113</td>\n",
       "      <td>0.011322</td>\n",
       "      <td>-0.011322</td>\n",
       "      <td>0.003470</td>\n",
       "      <td>-0.003470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <td>-0.014025</td>\n",
       "      <td>-0.013573</td>\n",
       "      <td>-0.012371</td>\n",
       "      <td>-0.004168</td>\n",
       "      <td>-0.005307</td>\n",
       "      <td>0.066270</td>\n",
       "      <td>-0.011247</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>-0.011279</td>\n",
       "      <td>0.148953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004429</td>\n",
       "      <td>-0.002838</td>\n",
       "      <td>-0.003456</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>-0.027383</td>\n",
       "      <td>0.027383</td>\n",
       "      <td>-0.004510</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <td>-0.090465</td>\n",
       "      <td>-0.090100</td>\n",
       "      <td>-0.087629</td>\n",
       "      <td>-0.019439</td>\n",
       "      <td>-0.082119</td>\n",
       "      <td>-0.052576</td>\n",
       "      <td>-0.024920</td>\n",
       "      <td>0.018015</td>\n",
       "      <td>-0.033241</td>\n",
       "      <td>-0.036506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>0.005010</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>-0.037918</td>\n",
       "      <td>0.037918</td>\n",
       "      <td>-0.012144</td>\n",
       "      <td>0.012144</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>0.000795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc</th>\n",
       "      <td>0.211422</td>\n",
       "      <td>0.211819</td>\n",
       "      <td>0.211980</td>\n",
       "      <td>0.083120</td>\n",
       "      <td>0.203134</td>\n",
       "      <td>0.238825</td>\n",
       "      <td>-0.034241</td>\n",
       "      <td>-0.035829</td>\n",
       "      <td>0.342374</td>\n",
       "      <td>0.062467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019424</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>-0.000813</td>\n",
       "      <td>-0.005229</td>\n",
       "      <td>-0.060844</td>\n",
       "      <td>0.060844</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.022420</td>\n",
       "      <td>0.022420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec</th>\n",
       "      <td>-0.082996</td>\n",
       "      <td>-0.082608</td>\n",
       "      <td>-0.080097</td>\n",
       "      <td>-0.023186</td>\n",
       "      <td>-0.073299</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>-0.026014</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>-0.042525</td>\n",
       "      <td>-0.026153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001445</td>\n",
       "      <td>0.011162</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>-0.040112</td>\n",
       "      <td>0.040112</td>\n",
       "      <td>-0.010278</td>\n",
       "      <td>0.010278</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>0.000406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_bal</th>\n",
       "      <td>0.416462</td>\n",
       "      <td>0.416399</td>\n",
       "      <td>0.413883</td>\n",
       "      <td>0.126244</td>\n",
       "      <td>0.407350</td>\n",
       "      <td>0.370592</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>-0.020441</td>\n",
       "      <td>0.282319</td>\n",
       "      <td>-0.059145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011318</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>-0.003784</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>-0.027849</td>\n",
       "      <td>0.027849</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.014646</td>\n",
       "      <td>0.014646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>0.114303</td>\n",
       "      <td>0.114742</td>\n",
       "      <td>0.116397</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>0.134272</td>\n",
       "      <td>0.040381</td>\n",
       "      <td>-0.069792</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.250044</td>\n",
       "      <td>-0.011423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018996</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.055912</td>\n",
       "      <td>-0.055912</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>-0.009125</td>\n",
       "      <td>0.009125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc</th>\n",
       "      <td>0.233461</td>\n",
       "      <td>0.233450</td>\n",
       "      <td>0.233358</td>\n",
       "      <td>0.107992</td>\n",
       "      <td>0.213479</td>\n",
       "      <td>0.322710</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>-0.004693</td>\n",
       "      <td>0.260145</td>\n",
       "      <td>0.135472</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013174</td>\n",
       "      <td>0.016408</td>\n",
       "      <td>0.007988</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>-0.054287</td>\n",
       "      <td>0.054287</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>-0.002924</td>\n",
       "      <td>-0.014356</td>\n",
       "      <td>0.014356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <td>-0.014423</td>\n",
       "      <td>-0.014273</td>\n",
       "      <td>-0.013464</td>\n",
       "      <td>-0.004925</td>\n",
       "      <td>-0.011895</td>\n",
       "      <td>-0.003638</td>\n",
       "      <td>-0.019495</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.073898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>-0.005831</td>\n",
       "      <td>-0.003426</td>\n",
       "      <td>-0.002805</td>\n",
       "      <td>-0.021125</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>-0.001222</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <td>-0.042279</td>\n",
       "      <td>-0.041529</td>\n",
       "      <td>-0.037759</td>\n",
       "      <td>-0.014800</td>\n",
       "      <td>-0.031424</td>\n",
       "      <td>0.036006</td>\n",
       "      <td>-0.028201</td>\n",
       "      <td>0.019203</td>\n",
       "      <td>-0.015406</td>\n",
       "      <td>0.155710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006970</td>\n",
       "      <td>-0.003291</td>\n",
       "      <td>-0.007461</td>\n",
       "      <td>-0.006261</td>\n",
       "      <td>-0.058677</td>\n",
       "      <td>0.058677</td>\n",
       "      <td>-0.003886</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.005363</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>-0.007084</td>\n",
       "      <td>-0.005993</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.143115</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>-0.002619</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>-0.007641</td>\n",
       "      <td>0.007641</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <td>-0.056242</td>\n",
       "      <td>-0.055768</td>\n",
       "      <td>-0.053053</td>\n",
       "      <td>-0.024536</td>\n",
       "      <td>-0.048404</td>\n",
       "      <td>-0.024202</td>\n",
       "      <td>-0.021932</td>\n",
       "      <td>0.041351</td>\n",
       "      <td>-0.007472</td>\n",
       "      <td>0.028301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004548</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>-0.048259</td>\n",
       "      <td>0.048259</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <td>0.260331</td>\n",
       "      <td>0.264022</td>\n",
       "      <td>0.277116</td>\n",
       "      <td>0.091079</td>\n",
       "      <td>0.254192</td>\n",
       "      <td>0.351802</td>\n",
       "      <td>0.008476</td>\n",
       "      <td>0.023773</td>\n",
       "      <td>0.186714</td>\n",
       "      <td>0.097165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.007112</td>\n",
       "      <td>-0.260858</td>\n",
       "      <td>0.260858</td>\n",
       "      <td>-0.029434</td>\n",
       "      <td>0.029434</td>\n",
       "      <td>-0.010182</td>\n",
       "      <td>0.010182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc_6m</th>\n",
       "      <td>-0.007634</td>\n",
       "      <td>-0.007129</td>\n",
       "      <td>-0.004859</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.056890</td>\n",
       "      <td>-0.037138</td>\n",
       "      <td>0.007804</td>\n",
       "      <td>0.043074</td>\n",
       "      <td>0.009822</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004269</td>\n",
       "      <td>-0.000244</td>\n",
       "      <td>-0.013507</td>\n",
       "      <td>-0.003015</td>\n",
       "      <td>-0.181234</td>\n",
       "      <td>0.181234</td>\n",
       "      <td>-0.079814</td>\n",
       "      <td>0.079814</td>\n",
       "      <td>-0.050564</td>\n",
       "      <td>0.050564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_act_il</th>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>0.016191</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>0.017025</td>\n",
       "      <td>0.091403</td>\n",
       "      <td>-0.025843</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.136884</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002705</td>\n",
       "      <td>-0.000683</td>\n",
       "      <td>-0.015577</td>\n",
       "      <td>-0.001908</td>\n",
       "      <td>-0.231213</td>\n",
       "      <td>0.231213</td>\n",
       "      <td>-0.104828</td>\n",
       "      <td>0.104828</td>\n",
       "      <td>-0.082425</td>\n",
       "      <td>0.082425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_il_12m</th>\n",
       "      <td>-0.004978</td>\n",
       "      <td>-0.004508</td>\n",
       "      <td>-0.002408</td>\n",
       "      <td>0.013452</td>\n",
       "      <td>0.004933</td>\n",
       "      <td>0.081754</td>\n",
       "      <td>-0.035740</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.103037</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002164</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>-0.012711</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>-0.167113</td>\n",
       "      <td>0.167113</td>\n",
       "      <td>-0.071506</td>\n",
       "      <td>0.071506</td>\n",
       "      <td>-0.064204</td>\n",
       "      <td>0.064204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_il_24m</th>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>0.017232</td>\n",
       "      <td>0.013064</td>\n",
       "      <td>0.094332</td>\n",
       "      <td>-0.030601</td>\n",
       "      <td>0.020456</td>\n",
       "      <td>0.120012</td>\n",
       "      <td>0.003462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001343</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>-0.015018</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.212648</td>\n",
       "      <td>0.212648</td>\n",
       "      <td>-0.094283</td>\n",
       "      <td>0.094283</td>\n",
       "      <td>-0.076857</td>\n",
       "      <td>0.076857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.006808</td>\n",
       "      <td>-0.007158</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>-0.009248</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>-0.017196</td>\n",
       "      <td>0.023197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002194</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>-0.017463</td>\n",
       "      <td>-0.003023</td>\n",
       "      <td>-0.253458</td>\n",
       "      <td>0.253458</td>\n",
       "      <td>-0.116835</td>\n",
       "      <td>0.116835</td>\n",
       "      <td>-0.051046</td>\n",
       "      <td>0.051046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bal_il</th>\n",
       "      <td>0.023211</td>\n",
       "      <td>0.023890</td>\n",
       "      <td>0.026579</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>0.027480</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>-0.023870</td>\n",
       "      <td>0.012459</td>\n",
       "      <td>0.127342</td>\n",
       "      <td>0.025870</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001981</td>\n",
       "      <td>-0.001393</td>\n",
       "      <td>-0.017649</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.256680</td>\n",
       "      <td>0.256680</td>\n",
       "      <td>-0.119410</td>\n",
       "      <td>0.119410</td>\n",
       "      <td>-0.079235</td>\n",
       "      <td>0.079235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il_util</th>\n",
       "      <td>-0.002480</td>\n",
       "      <td>-0.001816</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.060990</td>\n",
       "      <td>-0.027818</td>\n",
       "      <td>0.008353</td>\n",
       "      <td>0.107211</td>\n",
       "      <td>0.020267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>-0.017607</td>\n",
       "      <td>-0.003270</td>\n",
       "      <td>-0.251436</td>\n",
       "      <td>0.251436</td>\n",
       "      <td>-0.113361</td>\n",
       "      <td>0.113361</td>\n",
       "      <td>-0.071777</td>\n",
       "      <td>0.071777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NC</th>\n",
       "      <td>-0.005887</td>\n",
       "      <td>-0.005829</td>\n",
       "      <td>-0.005587</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>-0.008434</td>\n",
       "      <td>-0.016974</td>\n",
       "      <td>-0.003622</td>\n",
       "      <td>-0.073336</td>\n",
       "      <td>0.010181</td>\n",
       "      <td>-0.002436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025678</td>\n",
       "      <td>-0.019316</td>\n",
       "      <td>-0.010776</td>\n",
       "      <td>-0.008062</td>\n",
       "      <td>-0.003295</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_ND</th>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>-0.001193</td>\n",
       "      <td>-0.002090</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>0.002449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004158</td>\n",
       "      <td>-0.003128</td>\n",
       "      <td>-0.001745</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.013843</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>-0.004794</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>-0.002508</td>\n",
       "      <td>0.002508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NE</th>\n",
       "      <td>-0.004314</td>\n",
       "      <td>-0.004259</td>\n",
       "      <td>-0.004290</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>-0.004841</td>\n",
       "      <td>-0.009079</td>\n",
       "      <td>-0.006749</td>\n",
       "      <td>0.025932</td>\n",
       "      <td>0.010647</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006338</td>\n",
       "      <td>-0.004768</td>\n",
       "      <td>-0.002660</td>\n",
       "      <td>-0.001990</td>\n",
       "      <td>-0.018000</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>-0.012745</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>-0.003078</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NH</th>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000539</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.010618</td>\n",
       "      <td>-0.165758</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010297</td>\n",
       "      <td>-0.007746</td>\n",
       "      <td>-0.004321</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>-0.000857</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>-0.000627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NJ</th>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.014641</td>\n",
       "      <td>0.014073</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>-0.004963</td>\n",
       "      <td>-0.332345</td>\n",
       "      <td>-0.028843</td>\n",
       "      <td>0.011549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029291</td>\n",
       "      <td>-0.022034</td>\n",
       "      <td>-0.012293</td>\n",
       "      <td>-0.009196</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>-0.006840</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>-0.004732</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NM</th>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.001967</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>-0.007479</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>0.070747</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011375</td>\n",
       "      <td>-0.008557</td>\n",
       "      <td>-0.004774</td>\n",
       "      <td>-0.003571</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>-0.000711</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>0.002388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NV</th>\n",
       "      <td>-0.009898</td>\n",
       "      <td>-0.009876</td>\n",
       "      <td>-0.009455</td>\n",
       "      <td>-0.007690</td>\n",
       "      <td>-0.007923</td>\n",
       "      <td>-0.014300</td>\n",
       "      <td>-0.008473</td>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>-0.008792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018702</td>\n",
       "      <td>-0.014069</td>\n",
       "      <td>-0.007849</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>-0.003763</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>-0.000970</td>\n",
       "      <td>0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NY</th>\n",
       "      <td>-0.003832</td>\n",
       "      <td>-0.003890</td>\n",
       "      <td>-0.004330</td>\n",
       "      <td>-0.008330</td>\n",
       "      <td>-0.001036</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>-0.015443</td>\n",
       "      <td>-0.399440</td>\n",
       "      <td>-0.060714</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045058</td>\n",
       "      <td>-0.033895</td>\n",
       "      <td>-0.018910</td>\n",
       "      <td>-0.014146</td>\n",
       "      <td>0.010430</td>\n",
       "      <td>-0.010430</td>\n",
       "      <td>0.009609</td>\n",
       "      <td>-0.009609</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>-0.002588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_OH</th>\n",
       "      <td>-0.014690</td>\n",
       "      <td>-0.014623</td>\n",
       "      <td>-0.014331</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>-0.017301</td>\n",
       "      <td>-0.035212</td>\n",
       "      <td>-0.008578</td>\n",
       "      <td>0.017512</td>\n",
       "      <td>0.029637</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027556</td>\n",
       "      <td>-0.020729</td>\n",
       "      <td>-0.011565</td>\n",
       "      <td>-0.008651</td>\n",
       "      <td>-0.002550</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>-0.002372</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>-0.001283</td>\n",
       "      <td>0.001283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_OK</th>\n",
       "      <td>-0.001960</td>\n",
       "      <td>-0.001920</td>\n",
       "      <td>-0.001708</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>-0.002045</td>\n",
       "      <td>-0.010182</td>\n",
       "      <td>-0.009697</td>\n",
       "      <td>0.068956</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>-0.003952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014356</td>\n",
       "      <td>-0.010799</td>\n",
       "      <td>-0.006025</td>\n",
       "      <td>-0.004507</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>-0.002897</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>-0.000934</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_OR</th>\n",
       "      <td>-0.011355</td>\n",
       "      <td>-0.011387</td>\n",
       "      <td>-0.011140</td>\n",
       "      <td>-0.004860</td>\n",
       "      <td>-0.011418</td>\n",
       "      <td>-0.022356</td>\n",
       "      <td>0.015144</td>\n",
       "      <td>0.123261</td>\n",
       "      <td>-0.004554</td>\n",
       "      <td>-0.004876</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017108</td>\n",
       "      <td>-0.012870</td>\n",
       "      <td>-0.007180</td>\n",
       "      <td>-0.005371</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>-0.001039</td>\n",
       "      <td>-0.002484</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>-0.001319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_PA</th>\n",
       "      <td>-0.008941</td>\n",
       "      <td>-0.008932</td>\n",
       "      <td>-0.008545</td>\n",
       "      <td>0.012965</td>\n",
       "      <td>-0.012418</td>\n",
       "      <td>-0.019310</td>\n",
       "      <td>-0.003946</td>\n",
       "      <td>-0.174771</td>\n",
       "      <td>0.018475</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028383</td>\n",
       "      <td>-0.021351</td>\n",
       "      <td>-0.011912</td>\n",
       "      <td>-0.008911</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>-0.000815</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>-0.000568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_RI</th>\n",
       "      <td>-0.005117</td>\n",
       "      <td>-0.005169</td>\n",
       "      <td>-0.005053</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>-0.005716</td>\n",
       "      <td>-0.004629</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>-0.167882</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009931</td>\n",
       "      <td>-0.007471</td>\n",
       "      <td>-0.004168</td>\n",
       "      <td>-0.003118</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>-0.001861</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>-0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_SC</th>\n",
       "      <td>-0.003728</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>-0.004484</td>\n",
       "      <td>-0.011890</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>-0.040314</td>\n",
       "      <td>0.013160</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016367</td>\n",
       "      <td>-0.012312</td>\n",
       "      <td>-0.006869</td>\n",
       "      <td>-0.005138</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>-0.000764</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>-0.001714</td>\n",
       "      <td>0.001714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_SD</th>\n",
       "      <td>-0.004510</td>\n",
       "      <td>-0.004487</td>\n",
       "      <td>-0.004316</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>-0.015484</td>\n",
       "      <td>-0.001807</td>\n",
       "      <td>0.018615</td>\n",
       "      <td>0.012341</td>\n",
       "      <td>-0.001753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006879</td>\n",
       "      <td>-0.005174</td>\n",
       "      <td>-0.002887</td>\n",
       "      <td>-0.002160</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.003441</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_TN</th>\n",
       "      <td>-0.003146</td>\n",
       "      <td>-0.003021</td>\n",
       "      <td>-0.002644</td>\n",
       "      <td>0.004288</td>\n",
       "      <td>-0.003449</td>\n",
       "      <td>-0.020866</td>\n",
       "      <td>-0.007141</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>0.023322</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018212</td>\n",
       "      <td>-0.013700</td>\n",
       "      <td>-0.007643</td>\n",
       "      <td>-0.005718</td>\n",
       "      <td>-0.014325</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>-0.002618</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>-0.002327</td>\n",
       "      <td>0.002327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_TX</th>\n",
       "      <td>0.026210</td>\n",
       "      <td>0.026239</td>\n",
       "      <td>0.026189</td>\n",
       "      <td>-0.005270</td>\n",
       "      <td>0.028433</td>\n",
       "      <td>0.042128</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>0.230943</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044648</td>\n",
       "      <td>-0.033587</td>\n",
       "      <td>-0.018738</td>\n",
       "      <td>-0.014017</td>\n",
       "      <td>-0.004806</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>-0.002497</td>\n",
       "      <td>0.002497</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_UT</th>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.005720</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.080240</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>-0.002597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013497</td>\n",
       "      <td>-0.010154</td>\n",
       "      <td>-0.005665</td>\n",
       "      <td>-0.004238</td>\n",
       "      <td>-0.002218</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>-0.004482</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>-0.001424</td>\n",
       "      <td>0.001424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_VA</th>\n",
       "      <td>0.012916</td>\n",
       "      <td>0.012907</td>\n",
       "      <td>0.012329</td>\n",
       "      <td>0.012053</td>\n",
       "      <td>0.010594</td>\n",
       "      <td>0.025669</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>-0.114757</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026166</td>\n",
       "      <td>-0.019684</td>\n",
       "      <td>-0.010981</td>\n",
       "      <td>-0.008215</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_VT</th>\n",
       "      <td>-0.005255</td>\n",
       "      <td>-0.005239</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>-0.001937</td>\n",
       "      <td>-0.005489</td>\n",
       "      <td>-0.010514</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>-0.088119</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006579</td>\n",
       "      <td>-0.004949</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>-0.002066</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>-0.000603</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>-0.002104</td>\n",
       "      <td>0.002104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_WA</th>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>-0.002266</td>\n",
       "      <td>0.003831</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.166768</td>\n",
       "      <td>-0.003520</td>\n",
       "      <td>-0.008047</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017164</td>\n",
       "      <td>-0.009576</td>\n",
       "      <td>-0.007163</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>-0.001493</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>-0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_WI</th>\n",
       "      <td>-0.007850</td>\n",
       "      <td>-0.007811</td>\n",
       "      <td>-0.007648</td>\n",
       "      <td>-0.001120</td>\n",
       "      <td>-0.008558</td>\n",
       "      <td>-0.023125</td>\n",
       "      <td>0.009154</td>\n",
       "      <td>0.037518</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>-0.003831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007204</td>\n",
       "      <td>-0.005389</td>\n",
       "      <td>-0.001632</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>0.000968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_WV</th>\n",
       "      <td>-0.002438</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>-0.002108</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>-0.004545</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>-0.032957</td>\n",
       "      <td>0.013316</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009576</td>\n",
       "      <td>-0.007204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>-0.004253</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_WY</th>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>-0.001996</td>\n",
       "      <td>0.003163</td>\n",
       "      <td>0.041197</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>-0.000627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007163</td>\n",
       "      <td>-0.005389</td>\n",
       "      <td>-0.003006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>-0.004471</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>-0.002342</td>\n",
       "      <td>0.002342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <td>-0.072259</td>\n",
       "      <td>-0.073632</td>\n",
       "      <td>-0.079273</td>\n",
       "      <td>-0.105259</td>\n",
       "      <td>-0.039278</td>\n",
       "      <td>-0.070210</td>\n",
       "      <td>0.017221</td>\n",
       "      <td>-0.004923</td>\n",
       "      <td>-0.035859</td>\n",
       "      <td>-0.018504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>-0.001632</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>-0.038353</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>-0.005658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <td>0.072259</td>\n",
       "      <td>0.073632</td>\n",
       "      <td>0.079273</td>\n",
       "      <td>0.105259</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>0.070210</td>\n",
       "      <td>-0.017221</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.035859</td>\n",
       "      <td>0.018504</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001493</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>-0.004253</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038353</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>-0.005658</td>\n",
       "      <td>0.005658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_type_Individual</th>\n",
       "      <td>-0.039187</td>\n",
       "      <td>-0.039297</td>\n",
       "      <td>-0.039320</td>\n",
       "      <td>-0.022416</td>\n",
       "      <td>-0.038442</td>\n",
       "      <td>0.038470</td>\n",
       "      <td>-0.003934</td>\n",
       "      <td>-0.010975</td>\n",
       "      <td>-0.050293</td>\n",
       "      <td>-0.002948</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-0.001972</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>-0.004471</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>-0.038353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <td>0.039187</td>\n",
       "      <td>0.039297</td>\n",
       "      <td>0.039320</td>\n",
       "      <td>0.022416</td>\n",
       "      <td>0.038442</td>\n",
       "      <td>-0.038470</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.050293</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>-0.004267</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>-0.038353</td>\n",
       "      <td>0.038353</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>-0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disbursement_method_Cash</th>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>-0.002836</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>0.024749</td>\n",
       "      <td>-0.002253</td>\n",
       "      <td>-0.068471</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>-0.000968</td>\n",
       "      <td>-0.000206</td>\n",
       "      <td>-0.002342</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>-0.005658</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disbursement_method_DirectPay</th>\n",
       "      <td>-0.003903</td>\n",
       "      <td>-0.003854</td>\n",
       "      <td>-0.003639</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.001185</td>\n",
       "      <td>-0.018666</td>\n",
       "      <td>-0.024749</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.068471</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001674</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>-0.005658</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "loan_amnt                       1.000000     0.999482         0.991030   \n",
       "funded_amnt                     0.999482     1.000000         0.992027   \n",
       "funded_amnt_inv                 0.991030     0.992027         1.000000   \n",
       "term                            0.391044     0.390090         0.388473   \n",
       "installment                     0.973896     0.974742         0.966802   \n",
       "annual_inc                      0.473329     0.473149         0.469245   \n",
       "loan_status                    -0.067809    -0.067918        -0.066945   \n",
       "zip_code                       -0.008859    -0.008743        -0.008051   \n",
       "dti                             0.059263     0.059948         0.063721   \n",
       "delinq_2yrs                     0.003954     0.004267         0.005081   \n",
       "inq_last_6mths                 -0.020058    -0.020291        -0.022149   \n",
       "mths_since_last_delinq         -0.014025    -0.013573        -0.012371   \n",
       "mths_since_last_record         -0.090465    -0.090100        -0.087629   \n",
       "open_acc                        0.211422     0.211819         0.211980   \n",
       "pub_rec                        -0.082996    -0.082608        -0.080097   \n",
       "revol_bal                       0.416462     0.416399         0.413883   \n",
       "revol_util                      0.114303     0.114742         0.116397   \n",
       "total_acc                       0.233461     0.233450         0.233358   \n",
       "collections_12_mths_ex_med     -0.014423    -0.014273        -0.013464   \n",
       "mths_since_last_major_derog    -0.042279    -0.041529        -0.037759   \n",
       "acc_now_delinq                  0.003111     0.003203         0.003556   \n",
       "tot_coll_amt                   -0.056242    -0.055768        -0.053053   \n",
       "tot_cur_bal                     0.260331     0.264022         0.277116   \n",
       "open_acc_6m                    -0.007634    -0.007129        -0.004859   \n",
       "open_act_il                     0.013072     0.013684         0.016191   \n",
       "open_il_12m                    -0.004978    -0.004508        -0.002408   \n",
       "open_il_24m                     0.005770     0.006349         0.008797   \n",
       "mths_since_rcnt_il              0.003356     0.004007         0.006808   \n",
       "total_bal_il                    0.023211     0.023890         0.026579   \n",
       "il_util                        -0.002480    -0.001816         0.001099   \n",
       "...                                  ...          ...              ...   \n",
       "addr_state_NC                  -0.005887    -0.005829        -0.005587   \n",
       "addr_state_ND                   0.001636     0.001674         0.001817   \n",
       "addr_state_NE                  -0.004314    -0.004259        -0.004290   \n",
       "addr_state_NH                   0.000103     0.000049         0.000014   \n",
       "addr_state_NJ                   0.014825     0.014641         0.014073   \n",
       "addr_state_NM                  -0.000163    -0.000173        -0.000309   \n",
       "addr_state_NV                  -0.009898    -0.009876        -0.009455   \n",
       "addr_state_NY                  -0.003832    -0.003890        -0.004330   \n",
       "addr_state_OH                  -0.014690    -0.014623        -0.014331   \n",
       "addr_state_OK                  -0.001960    -0.001920        -0.001708   \n",
       "addr_state_OR                  -0.011355    -0.011387        -0.011140   \n",
       "addr_state_PA                  -0.008941    -0.008932        -0.008545   \n",
       "addr_state_RI                  -0.005117    -0.005169        -0.005053   \n",
       "addr_state_SC                  -0.003728    -0.003729        -0.003746   \n",
       "addr_state_SD                  -0.004510    -0.004487        -0.004316   \n",
       "addr_state_TN                  -0.003146    -0.003021        -0.002644   \n",
       "addr_state_TX                   0.026210     0.026239         0.026189   \n",
       "addr_state_UT                   0.000912     0.000931         0.000853   \n",
       "addr_state_VA                   0.012916     0.012907         0.012329   \n",
       "addr_state_VT                  -0.005255    -0.005239        -0.005155   \n",
       "addr_state_WA                   0.002824     0.002905         0.002837   \n",
       "addr_state_WI                  -0.007850    -0.007811        -0.007648   \n",
       "addr_state_WV                  -0.002438    -0.002389        -0.002108   \n",
       "addr_state_WY                   0.003678     0.003698         0.003833   \n",
       "initial_list_status_f          -0.072259    -0.073632        -0.079273   \n",
       "initial_list_status_w           0.072259     0.073632         0.079273   \n",
       "application_type_Individual    -0.039187    -0.039297        -0.039320   \n",
       "application_type_Joint App      0.039187     0.039297         0.039320   \n",
       "disbursement_method_Cash        0.003903     0.003854         0.003639   \n",
       "disbursement_method_DirectPay  -0.003903    -0.003854        -0.003639   \n",
       "\n",
       "                                   term  installment  annual_inc  loan_status  \\\n",
       "loan_amnt                      0.391044     0.973896    0.473329    -0.067809   \n",
       "funded_amnt                    0.390090     0.974742    0.473149    -0.067918   \n",
       "funded_amnt_inv                0.388473     0.966802    0.469245    -0.066945   \n",
       "term                           1.000000     0.202778    0.117914    -0.177266   \n",
       "installment                    0.202778     1.000000    0.458902    -0.055909   \n",
       "annual_inc                     0.117914     0.458902    1.000000     0.073626   \n",
       "loan_status                   -0.177266    -0.055909    0.073626     1.000000   \n",
       "zip_code                      -0.015615    -0.005181   -0.018684     0.010264   \n",
       "dti                            0.078886     0.061958   -0.204691    -0.116495   \n",
       "delinq_2yrs                   -0.004714     0.013088    0.081714    -0.022806   \n",
       "inq_last_6mths                 0.018716     0.000607    0.047620    -0.060134   \n",
       "mths_since_last_delinq        -0.004168    -0.005307    0.066270    -0.011247   \n",
       "mths_since_last_record        -0.019439    -0.082119   -0.052576    -0.024920   \n",
       "open_acc                       0.083120     0.203134    0.238825    -0.034241   \n",
       "pub_rec                       -0.023186    -0.073299   -0.031636    -0.026014   \n",
       "revol_bal                      0.126244     0.407350    0.370592     0.001119   \n",
       "revol_util                     0.055483     0.134272    0.040381    -0.069792   \n",
       "total_acc                      0.107992     0.213479    0.322710     0.013901   \n",
       "collections_12_mths_ex_med    -0.004925    -0.011895   -0.003638    -0.019495   \n",
       "mths_since_last_major_derog   -0.014800    -0.031424    0.036006    -0.028201   \n",
       "acc_now_delinq                 0.002506     0.005363    0.021824    -0.007084   \n",
       "tot_coll_amt                  -0.024536    -0.048404   -0.024202    -0.021932   \n",
       "tot_cur_bal                    0.091079     0.254192    0.351802     0.008476   \n",
       "open_acc_6m                    0.004084     0.002784    0.056890    -0.037138   \n",
       "open_act_il                    0.013133     0.017025    0.091403    -0.025843   \n",
       "open_il_12m                    0.013452     0.004933    0.081754    -0.035740   \n",
       "open_il_24m                    0.017232     0.013064    0.094332    -0.030601   \n",
       "mths_since_rcnt_il            -0.007158     0.005378    0.027977    -0.009248   \n",
       "total_bal_il                   0.014524     0.027480    0.102862    -0.023870   \n",
       "il_util                        0.006868     0.002887    0.060990    -0.027818   \n",
       "...                                 ...          ...         ...          ...   \n",
       "addr_state_NC                  0.011352    -0.008434   -0.016974    -0.003622   \n",
       "addr_state_ND                 -0.000299     0.002171   -0.001193    -0.002090   \n",
       "addr_state_NE                  0.002374    -0.004841   -0.009079    -0.006749   \n",
       "addr_state_NH                 -0.000539    -0.000531    0.001934     0.010618   \n",
       "addr_state_NJ                  0.002813     0.014444    0.042134    -0.004963   \n",
       "addr_state_NM                 -0.001967     0.000447   -0.007479    -0.003390   \n",
       "addr_state_NV                 -0.007690    -0.007923   -0.014300    -0.008473   \n",
       "addr_state_NY                 -0.008330    -0.001036    0.012986    -0.015443   \n",
       "addr_state_OH                  0.008421    -0.017301   -0.035212    -0.008578   \n",
       "addr_state_OK                  0.001162    -0.002045   -0.010182    -0.009697   \n",
       "addr_state_OR                 -0.004860    -0.011418   -0.022356     0.015144   \n",
       "addr_state_PA                  0.012965    -0.012418   -0.019310    -0.003946   \n",
       "addr_state_RI                  0.001095    -0.005716   -0.004629     0.002230   \n",
       "addr_state_SC                  0.002962    -0.004484   -0.011890     0.008899   \n",
       "addr_state_SD                 -0.000941    -0.004456   -0.015484    -0.001807   \n",
       "addr_state_TN                  0.004288    -0.003449   -0.020866    -0.007141   \n",
       "addr_state_TX                 -0.005270     0.028433    0.042128     0.002480   \n",
       "addr_state_UT                  0.006874    -0.000797   -0.005720     0.006129   \n",
       "addr_state_VA                  0.012053     0.010594    0.025669    -0.000809   \n",
       "addr_state_VT                 -0.001937    -0.005489   -0.010514     0.006318   \n",
       "addr_state_WA                 -0.002266     0.003831    0.002949     0.014800   \n",
       "addr_state_WI                 -0.001120    -0.008558   -0.023125     0.009154   \n",
       "addr_state_WV                  0.006988    -0.004545   -0.012770     0.003936   \n",
       "addr_state_WY                  0.002007     0.003442   -0.001996     0.003163   \n",
       "initial_list_status_f         -0.105259    -0.039278   -0.070210     0.017221   \n",
       "initial_list_status_w          0.105259     0.039278    0.070210    -0.017221   \n",
       "application_type_Individual   -0.022416    -0.038442    0.038470    -0.003934   \n",
       "application_type_Joint App     0.022416     0.038442   -0.038470     0.003934   \n",
       "disbursement_method_Cash      -0.002836    -0.001185    0.018666     0.024749   \n",
       "disbursement_method_DirectPay  0.002836     0.001185   -0.018666    -0.024749   \n",
       "\n",
       "                               zip_code       dti  delinq_2yrs  \\\n",
       "loan_amnt                     -0.008859  0.059263     0.003954   \n",
       "funded_amnt                   -0.008743  0.059948     0.004267   \n",
       "funded_amnt_inv               -0.008051  0.063721     0.005081   \n",
       "term                          -0.015615  0.078886    -0.004714   \n",
       "installment                   -0.005181  0.061958     0.013088   \n",
       "annual_inc                    -0.018684 -0.204691     0.081714   \n",
       "loan_status                    0.010264 -0.116495    -0.022806   \n",
       "zip_code                       1.000000  0.030521    -0.027382   \n",
       "dti                            0.030521  1.000000    -0.003053   \n",
       "delinq_2yrs                   -0.027382 -0.003053     1.000000   \n",
       "inq_last_6mths                 0.006664  0.000136     0.022908   \n",
       "mths_since_last_delinq         0.002413 -0.011279     0.148953   \n",
       "mths_since_last_record         0.018015 -0.033241    -0.036506   \n",
       "open_acc                      -0.035829  0.342374     0.062467   \n",
       "pub_rec                        0.010331 -0.042525    -0.026153   \n",
       "revol_bal                     -0.020441  0.282319    -0.059145   \n",
       "revol_util                     0.012342  0.250044    -0.011423   \n",
       "total_acc                     -0.004693  0.260145     0.135472   \n",
       "collections_12_mths_ex_med     0.000612  0.000100     0.073898   \n",
       "mths_since_last_major_derog    0.019203 -0.015406     0.155710   \n",
       "acc_now_delinq                -0.005993  0.006679     0.143115   \n",
       "tot_coll_amt                   0.041351 -0.007472     0.028301   \n",
       "tot_cur_bal                    0.023773  0.186714     0.097165   \n",
       "open_acc_6m                    0.007804  0.043074     0.009822   \n",
       "open_act_il                    0.006574  0.136884     0.032467   \n",
       "open_il_12m                    0.016479  0.103037     0.005537   \n",
       "open_il_24m                    0.020456  0.120012     0.003462   \n",
       "mths_since_rcnt_il             0.004852 -0.017196     0.023197   \n",
       "total_bal_il                   0.012459  0.127342     0.025870   \n",
       "il_util                        0.008353  0.107211     0.020267   \n",
       "...                                 ...       ...          ...   \n",
       "addr_state_NC                 -0.073336  0.010181    -0.002436   \n",
       "addr_state_ND                  0.011922  0.005108     0.002449   \n",
       "addr_state_NE                  0.025932  0.010647     0.004759   \n",
       "addr_state_NH                 -0.165758  0.007087     0.000742   \n",
       "addr_state_NJ                 -0.332345 -0.028843     0.011549   \n",
       "addr_state_NM                  0.070747  0.013468    -0.000814   \n",
       "addr_state_NV                  0.120316  0.003828    -0.008792   \n",
       "addr_state_NY                 -0.399440 -0.060714     0.011194   \n",
       "addr_state_OH                  0.017512  0.029637    -0.002169   \n",
       "addr_state_OK                  0.068956  0.014286    -0.003952   \n",
       "addr_state_OR                  0.123261 -0.004554    -0.004876   \n",
       "addr_state_PA                 -0.174771  0.018475     0.001816   \n",
       "addr_state_RI                 -0.167882 -0.002469     0.003938   \n",
       "addr_state_SC                 -0.040314  0.013160     0.000619   \n",
       "addr_state_SD                  0.018615  0.012341    -0.001753   \n",
       "addr_state_TN                 -0.011346  0.023322     0.002393   \n",
       "addr_state_TX                  0.230943  0.033200     0.002162   \n",
       "addr_state_UT                  0.080240  0.007842    -0.002597   \n",
       "addr_state_VA                 -0.114757  0.002852     0.003023   \n",
       "addr_state_VT                 -0.088119  0.008995     0.002506   \n",
       "addr_state_WA                  0.166768 -0.003520    -0.008047   \n",
       "addr_state_WI                  0.037518  0.009876    -0.003831   \n",
       "addr_state_WV                 -0.032957  0.013316     0.001093   \n",
       "addr_state_WY                  0.041197  0.009351    -0.000627   \n",
       "initial_list_status_f         -0.004923 -0.035859    -0.018504   \n",
       "initial_list_status_w          0.004923  0.035859     0.018504   \n",
       "application_type_Individual   -0.010975 -0.050293    -0.002948   \n",
       "application_type_Joint App     0.010975  0.050293     0.002948   \n",
       "disbursement_method_Cash      -0.002253 -0.068471    -0.000463   \n",
       "disbursement_method_DirectPay  0.002253  0.068471     0.000463   \n",
       "\n",
       "                                           ...                addr_state_WA  \\\n",
       "loan_amnt                                  ...                     0.002824   \n",
       "funded_amnt                                ...                     0.002905   \n",
       "funded_amnt_inv                            ...                     0.002837   \n",
       "term                                       ...                    -0.002266   \n",
       "installment                                ...                     0.003831   \n",
       "annual_inc                                 ...                     0.002949   \n",
       "loan_status                                ...                     0.014800   \n",
       "zip_code                                   ...                     0.166768   \n",
       "dti                                        ...                    -0.003520   \n",
       "delinq_2yrs                                ...                    -0.008047   \n",
       "inq_last_6mths                             ...                    -0.001919   \n",
       "mths_since_last_delinq                     ...                    -0.004429   \n",
       "mths_since_last_record                     ...                     0.001441   \n",
       "open_acc                                   ...                    -0.019424   \n",
       "pub_rec                                    ...                    -0.001445   \n",
       "revol_bal                                  ...                     0.011318   \n",
       "revol_util                                 ...                     0.018996   \n",
       "total_acc                                  ...                    -0.013174   \n",
       "collections_12_mths_ex_med                 ...                    -0.001097   \n",
       "mths_since_last_major_derog                ...                    -0.006970   \n",
       "acc_now_delinq                             ...                    -0.003018   \n",
       "tot_coll_amt                               ...                    -0.004548   \n",
       "tot_cur_bal                                ...                     0.010835   \n",
       "open_acc_6m                                ...                    -0.004269   \n",
       "open_act_il                                ...                    -0.002705   \n",
       "open_il_12m                                ...                    -0.002164   \n",
       "open_il_24m                                ...                    -0.001343   \n",
       "mths_since_rcnt_il                         ...                    -0.002194   \n",
       "total_bal_il                               ...                    -0.001981   \n",
       "il_util                                    ...                    -0.002642   \n",
       "...                                        ...                          ...   \n",
       "addr_state_NC                              ...                    -0.025678   \n",
       "addr_state_ND                              ...                    -0.004158   \n",
       "addr_state_NE                              ...                    -0.006338   \n",
       "addr_state_NH                              ...                    -0.010297   \n",
       "addr_state_NJ                              ...                    -0.029291   \n",
       "addr_state_NM                              ...                    -0.011375   \n",
       "addr_state_NV                              ...                    -0.018702   \n",
       "addr_state_NY                              ...                    -0.045058   \n",
       "addr_state_OH                              ...                    -0.027556   \n",
       "addr_state_OK                              ...                    -0.014356   \n",
       "addr_state_OR                              ...                    -0.017108   \n",
       "addr_state_PA                              ...                    -0.028383   \n",
       "addr_state_RI                              ...                    -0.009931   \n",
       "addr_state_SC                              ...                    -0.016367   \n",
       "addr_state_SD                              ...                    -0.006879   \n",
       "addr_state_TN                              ...                    -0.018212   \n",
       "addr_state_TX                              ...                    -0.044648   \n",
       "addr_state_UT                              ...                    -0.013497   \n",
       "addr_state_VA                              ...                    -0.026166   \n",
       "addr_state_VT                              ...                    -0.006579   \n",
       "addr_state_WA                              ...                     1.000000   \n",
       "addr_state_WI                              ...                    -0.017164   \n",
       "addr_state_WV                              ...                    -0.009576   \n",
       "addr_state_WY                              ...                    -0.007163   \n",
       "initial_list_status_f                      ...                     0.001493   \n",
       "initial_list_status_w                      ...                    -0.001493   \n",
       "application_type_Individual                ...                    -0.001905   \n",
       "application_type_Joint App                 ...                     0.001905   \n",
       "disbursement_method_Cash                   ...                     0.001674   \n",
       "disbursement_method_DirectPay              ...                    -0.001674   \n",
       "\n",
       "                               addr_state_WI  addr_state_WV  addr_state_WY  \\\n",
       "loan_amnt                          -0.007850      -0.002438       0.003678   \n",
       "funded_amnt                        -0.007811      -0.002389       0.003698   \n",
       "funded_amnt_inv                    -0.007648      -0.002108       0.003833   \n",
       "term                               -0.001120       0.006988       0.002007   \n",
       "installment                        -0.008558      -0.004545       0.003442   \n",
       "annual_inc                         -0.023125      -0.012770      -0.001996   \n",
       "loan_status                         0.009154       0.003936       0.003163   \n",
       "zip_code                            0.037518      -0.032957       0.041197   \n",
       "dti                                 0.009876       0.013316       0.009351   \n",
       "delinq_2yrs                        -0.003831       0.001093      -0.000627   \n",
       "inq_last_6mths                      0.025113      -0.000835      -0.001463   \n",
       "mths_since_last_delinq             -0.002838      -0.003456       0.000555   \n",
       "mths_since_last_record              0.010812       0.005010       0.002368   \n",
       "open_acc                            0.002262      -0.000813      -0.005229   \n",
       "pub_rec                             0.011162       0.007195       0.001759   \n",
       "revol_bal                           0.001413      -0.003784      -0.003746   \n",
       "revol_util                          0.004234      -0.000311       0.003405   \n",
       "total_acc                           0.016408       0.007988       0.006066   \n",
       "collections_12_mths_ex_med         -0.005831      -0.003426      -0.002805   \n",
       "mths_since_last_major_derog        -0.003291      -0.007461      -0.006261   \n",
       "acc_now_delinq                     -0.002619       0.000762       0.001483   \n",
       "tot_coll_amt                        0.006249       0.004205       0.002751   \n",
       "tot_cur_bal                         0.002427       0.000077       0.007112   \n",
       "open_acc_6m                        -0.000244      -0.013507      -0.003015   \n",
       "open_act_il                        -0.000683      -0.015577      -0.001908   \n",
       "open_il_12m                         0.000218      -0.012711      -0.001096   \n",
       "open_il_24m                         0.001329      -0.015018      -0.001061   \n",
       "mths_since_rcnt_il                 -0.001283      -0.017463      -0.003023   \n",
       "total_bal_il                       -0.001393      -0.017649      -0.002387   \n",
       "il_util                             0.000166      -0.017607      -0.003270   \n",
       "...                                      ...            ...            ...   \n",
       "addr_state_NC                      -0.019316      -0.010776      -0.008062   \n",
       "addr_state_ND                      -0.003128      -0.001745      -0.001305   \n",
       "addr_state_NE                      -0.004768      -0.002660      -0.001990   \n",
       "addr_state_NH                      -0.007746      -0.004321      -0.003233   \n",
       "addr_state_NJ                      -0.022034      -0.012293      -0.009196   \n",
       "addr_state_NM                      -0.008557      -0.004774      -0.003571   \n",
       "addr_state_NV                      -0.014069      -0.007849      -0.005872   \n",
       "addr_state_NY                      -0.033895      -0.018910      -0.014146   \n",
       "addr_state_OH                      -0.020729      -0.011565      -0.008651   \n",
       "addr_state_OK                      -0.010799      -0.006025      -0.004507   \n",
       "addr_state_OR                      -0.012870      -0.007180      -0.005371   \n",
       "addr_state_PA                      -0.021351      -0.011912      -0.008911   \n",
       "addr_state_RI                      -0.007471      -0.004168      -0.003118   \n",
       "addr_state_SC                      -0.012312      -0.006869      -0.005138   \n",
       "addr_state_SD                      -0.005174      -0.002887      -0.002160   \n",
       "addr_state_TN                      -0.013700      -0.007643      -0.005718   \n",
       "addr_state_TX                      -0.033587      -0.018738      -0.014017   \n",
       "addr_state_UT                      -0.010154      -0.005665      -0.004238   \n",
       "addr_state_VA                      -0.019684      -0.010981      -0.008215   \n",
       "addr_state_VT                      -0.004949      -0.002761      -0.002066   \n",
       "addr_state_WA                      -0.017164      -0.009576      -0.007163   \n",
       "addr_state_WI                       1.000000      -0.007204      -0.005389   \n",
       "addr_state_WV                      -0.007204       1.000000      -0.003006   \n",
       "addr_state_WY                      -0.005389      -0.003006       1.000000   \n",
       "initial_list_status_f              -0.001632       0.004253       0.001128   \n",
       "initial_list_status_w               0.001632      -0.004253      -0.001128   \n",
       "application_type_Individual        -0.001972       0.004267      -0.004471   \n",
       "application_type_Joint App          0.001972      -0.004267       0.004471   \n",
       "disbursement_method_Cash           -0.000968      -0.000206      -0.002342   \n",
       "disbursement_method_DirectPay       0.000968       0.000206       0.002342   \n",
       "\n",
       "                               initial_list_status_f  initial_list_status_w  \\\n",
       "loan_amnt                                  -0.072259               0.072259   \n",
       "funded_amnt                                -0.073632               0.073632   \n",
       "funded_amnt_inv                            -0.079273               0.079273   \n",
       "term                                       -0.105259               0.105259   \n",
       "installment                                -0.039278               0.039278   \n",
       "annual_inc                                 -0.070210               0.070210   \n",
       "loan_status                                 0.017221              -0.017221   \n",
       "zip_code                                   -0.004923               0.004923   \n",
       "dti                                        -0.035859               0.035859   \n",
       "delinq_2yrs                                -0.018504               0.018504   \n",
       "inq_last_6mths                              0.063113              -0.063113   \n",
       "mths_since_last_delinq                     -0.027383               0.027383   \n",
       "mths_since_last_record                     -0.037918               0.037918   \n",
       "open_acc                                   -0.060844               0.060844   \n",
       "pub_rec                                    -0.040112               0.040112   \n",
       "revol_bal                                  -0.027849               0.027849   \n",
       "revol_util                                  0.055912              -0.055912   \n",
       "total_acc                                  -0.054287               0.054287   \n",
       "collections_12_mths_ex_med                 -0.021125               0.021125   \n",
       "mths_since_last_major_derog                -0.058677               0.058677   \n",
       "acc_now_delinq                             -0.007641               0.007641   \n",
       "tot_coll_amt                               -0.048259               0.048259   \n",
       "tot_cur_bal                                -0.260858               0.260858   \n",
       "open_acc_6m                                -0.181234               0.181234   \n",
       "open_act_il                                -0.231213               0.231213   \n",
       "open_il_12m                                -0.167113               0.167113   \n",
       "open_il_24m                                -0.212648               0.212648   \n",
       "mths_since_rcnt_il                         -0.253458               0.253458   \n",
       "total_bal_il                               -0.256680               0.256680   \n",
       "il_util                                    -0.251436               0.251436   \n",
       "...                                              ...                    ...   \n",
       "addr_state_NC                              -0.003295               0.003295   \n",
       "addr_state_ND                              -0.013843               0.013843   \n",
       "addr_state_NE                              -0.018000               0.018000   \n",
       "addr_state_NH                              -0.000857               0.000857   \n",
       "addr_state_NJ                               0.006840              -0.006840   \n",
       "addr_state_NM                              -0.000215               0.000215   \n",
       "addr_state_NV                              -0.001239               0.001239   \n",
       "addr_state_NY                               0.010430              -0.010430   \n",
       "addr_state_OH                              -0.002550               0.002550   \n",
       "addr_state_OK                               0.000990              -0.000990   \n",
       "addr_state_OR                               0.001039              -0.001039   \n",
       "addr_state_PA                               0.000901              -0.000901   \n",
       "addr_state_RI                              -0.000314               0.000314   \n",
       "addr_state_SC                               0.000764              -0.000764   \n",
       "addr_state_SD                              -0.000039               0.000039   \n",
       "addr_state_TN                              -0.014325               0.014325   \n",
       "addr_state_TX                              -0.004806               0.004806   \n",
       "addr_state_UT                              -0.002218               0.002218   \n",
       "addr_state_VA                               0.003798              -0.003798   \n",
       "addr_state_VT                               0.000603              -0.000603   \n",
       "addr_state_WA                               0.001493              -0.001493   \n",
       "addr_state_WI                              -0.001632               0.001632   \n",
       "addr_state_WV                               0.004253              -0.004253   \n",
       "addr_state_WY                               0.001128              -0.001128   \n",
       "initial_list_status_f                       1.000000              -1.000000   \n",
       "initial_list_status_w                      -1.000000               1.000000   \n",
       "application_type_Individual                 0.038353              -0.038353   \n",
       "application_type_Joint App                 -0.038353               0.038353   \n",
       "disbursement_method_Cash                    0.005658              -0.005658   \n",
       "disbursement_method_DirectPay              -0.005658               0.005658   \n",
       "\n",
       "                               application_type_Individual  \\\n",
       "loan_amnt                                        -0.039187   \n",
       "funded_amnt                                      -0.039297   \n",
       "funded_amnt_inv                                  -0.039320   \n",
       "term                                             -0.022416   \n",
       "installment                                      -0.038442   \n",
       "annual_inc                                        0.038470   \n",
       "loan_status                                      -0.003934   \n",
       "zip_code                                         -0.010975   \n",
       "dti                                              -0.050293   \n",
       "delinq_2yrs                                      -0.002948   \n",
       "inq_last_6mths                                    0.011322   \n",
       "mths_since_last_delinq                           -0.004510   \n",
       "mths_since_last_record                           -0.012144   \n",
       "open_acc                                          0.000770   \n",
       "pub_rec                                          -0.010278   \n",
       "revol_bal                                        -0.000068   \n",
       "revol_util                                       -0.000791   \n",
       "total_acc                                         0.002924   \n",
       "collections_12_mths_ex_med                        0.001222   \n",
       "mths_since_last_major_derog                      -0.003886   \n",
       "acc_now_delinq                                   -0.000368   \n",
       "tot_coll_amt                                     -0.006473   \n",
       "tot_cur_bal                                      -0.029434   \n",
       "open_acc_6m                                      -0.079814   \n",
       "open_act_il                                      -0.104828   \n",
       "open_il_12m                                      -0.071506   \n",
       "open_il_24m                                      -0.094283   \n",
       "mths_since_rcnt_il                               -0.116835   \n",
       "total_bal_il                                     -0.119410   \n",
       "il_util                                          -0.113361   \n",
       "...                                                    ...   \n",
       "addr_state_NC                                     0.000082   \n",
       "addr_state_ND                                    -0.004794   \n",
       "addr_state_NE                                    -0.012745   \n",
       "addr_state_NH                                     0.000639   \n",
       "addr_state_NJ                                     0.004732   \n",
       "addr_state_NM                                    -0.000711   \n",
       "addr_state_NV                                    -0.003763   \n",
       "addr_state_NY                                     0.009609   \n",
       "addr_state_OH                                    -0.002372   \n",
       "addr_state_OK                                    -0.002897   \n",
       "addr_state_OR                                    -0.002484   \n",
       "addr_state_PA                                    -0.000815   \n",
       "addr_state_RI                                     0.001861   \n",
       "addr_state_SC                                     0.001277   \n",
       "addr_state_SD                                    -0.003441   \n",
       "addr_state_TN                                    -0.002618   \n",
       "addr_state_TX                                    -0.002497   \n",
       "addr_state_UT                                    -0.004482   \n",
       "addr_state_VA                                     0.001431   \n",
       "addr_state_VT                                    -0.000385   \n",
       "addr_state_WA                                    -0.001905   \n",
       "addr_state_WI                                    -0.001972   \n",
       "addr_state_WV                                     0.004267   \n",
       "addr_state_WY                                    -0.004471   \n",
       "initial_list_status_f                             0.038353   \n",
       "initial_list_status_w                            -0.038353   \n",
       "application_type_Individual                       1.000000   \n",
       "application_type_Joint App                       -1.000000   \n",
       "disbursement_method_Cash                         -0.002663   \n",
       "disbursement_method_DirectPay                     0.002663   \n",
       "\n",
       "                               application_type_Joint App  \\\n",
       "loan_amnt                                        0.039187   \n",
       "funded_amnt                                      0.039297   \n",
       "funded_amnt_inv                                  0.039320   \n",
       "term                                             0.022416   \n",
       "installment                                      0.038442   \n",
       "annual_inc                                      -0.038470   \n",
       "loan_status                                      0.003934   \n",
       "zip_code                                         0.010975   \n",
       "dti                                              0.050293   \n",
       "delinq_2yrs                                      0.002948   \n",
       "inq_last_6mths                                  -0.011322   \n",
       "mths_since_last_delinq                           0.004510   \n",
       "mths_since_last_record                           0.012144   \n",
       "open_acc                                        -0.000770   \n",
       "pub_rec                                          0.010278   \n",
       "revol_bal                                        0.000068   \n",
       "revol_util                                       0.000791   \n",
       "total_acc                                       -0.002924   \n",
       "collections_12_mths_ex_med                      -0.001222   \n",
       "mths_since_last_major_derog                      0.003886   \n",
       "acc_now_delinq                                   0.000368   \n",
       "tot_coll_amt                                     0.006473   \n",
       "tot_cur_bal                                      0.029434   \n",
       "open_acc_6m                                      0.079814   \n",
       "open_act_il                                      0.104828   \n",
       "open_il_12m                                      0.071506   \n",
       "open_il_24m                                      0.094283   \n",
       "mths_since_rcnt_il                               0.116835   \n",
       "total_bal_il                                     0.119410   \n",
       "il_util                                          0.113361   \n",
       "...                                                   ...   \n",
       "addr_state_NC                                   -0.000082   \n",
       "addr_state_ND                                    0.004794   \n",
       "addr_state_NE                                    0.012745   \n",
       "addr_state_NH                                   -0.000639   \n",
       "addr_state_NJ                                   -0.004732   \n",
       "addr_state_NM                                    0.000711   \n",
       "addr_state_NV                                    0.003763   \n",
       "addr_state_NY                                   -0.009609   \n",
       "addr_state_OH                                    0.002372   \n",
       "addr_state_OK                                    0.002897   \n",
       "addr_state_OR                                    0.002484   \n",
       "addr_state_PA                                    0.000815   \n",
       "addr_state_RI                                   -0.001861   \n",
       "addr_state_SC                                   -0.001277   \n",
       "addr_state_SD                                    0.003441   \n",
       "addr_state_TN                                    0.002618   \n",
       "addr_state_TX                                    0.002497   \n",
       "addr_state_UT                                    0.004482   \n",
       "addr_state_VA                                   -0.001431   \n",
       "addr_state_VT                                    0.000385   \n",
       "addr_state_WA                                    0.001905   \n",
       "addr_state_WI                                    0.001972   \n",
       "addr_state_WV                                   -0.004267   \n",
       "addr_state_WY                                    0.004471   \n",
       "initial_list_status_f                           -0.038353   \n",
       "initial_list_status_w                            0.038353   \n",
       "application_type_Individual                     -1.000000   \n",
       "application_type_Joint App                       1.000000   \n",
       "disbursement_method_Cash                         0.002663   \n",
       "disbursement_method_DirectPay                   -0.002663   \n",
       "\n",
       "                               disbursement_method_Cash  \\\n",
       "loan_amnt                                      0.003903   \n",
       "funded_amnt                                    0.003854   \n",
       "funded_amnt_inv                                0.003639   \n",
       "term                                          -0.002836   \n",
       "installment                                   -0.001185   \n",
       "annual_inc                                     0.018666   \n",
       "loan_status                                    0.024749   \n",
       "zip_code                                      -0.002253   \n",
       "dti                                           -0.068471   \n",
       "delinq_2yrs                                   -0.000463   \n",
       "inq_last_6mths                                 0.003470   \n",
       "mths_since_last_delinq                        -0.001749   \n",
       "mths_since_last_record                        -0.000795   \n",
       "open_acc                                      -0.022420   \n",
       "pub_rec                                       -0.000406   \n",
       "revol_bal                                     -0.014646   \n",
       "revol_util                                    -0.009125   \n",
       "total_acc                                     -0.014356   \n",
       "collections_12_mths_ex_med                     0.000046   \n",
       "mths_since_last_major_derog                   -0.000933   \n",
       "acc_now_delinq                                -0.000081   \n",
       "tot_coll_amt                                   0.000184   \n",
       "tot_cur_bal                                   -0.010182   \n",
       "open_acc_6m                                   -0.050564   \n",
       "open_act_il                                   -0.082425   \n",
       "open_il_12m                                   -0.064204   \n",
       "open_il_24m                                   -0.076857   \n",
       "mths_since_rcnt_il                            -0.051046   \n",
       "total_bal_il                                  -0.079235   \n",
       "il_util                                       -0.071777   \n",
       "...                                                 ...   \n",
       "addr_state_NC                                 -0.000731   \n",
       "addr_state_ND                                 -0.002508   \n",
       "addr_state_NE                                 -0.003078   \n",
       "addr_state_NH                                  0.000627   \n",
       "addr_state_NJ                                  0.000977   \n",
       "addr_state_NM                                 -0.002388   \n",
       "addr_state_NV                                 -0.000970   \n",
       "addr_state_NY                                  0.002588   \n",
       "addr_state_OH                                 -0.001283   \n",
       "addr_state_OK                                 -0.000934   \n",
       "addr_state_OR                                  0.001319   \n",
       "addr_state_PA                                  0.000568   \n",
       "addr_state_RI                                  0.000962   \n",
       "addr_state_SC                                 -0.001714   \n",
       "addr_state_SD                                 -0.000444   \n",
       "addr_state_TN                                 -0.002327   \n",
       "addr_state_TX                                 -0.000796   \n",
       "addr_state_UT                                 -0.001424   \n",
       "addr_state_VA                                  0.000091   \n",
       "addr_state_VT                                 -0.002104   \n",
       "addr_state_WA                                  0.001674   \n",
       "addr_state_WI                                 -0.000968   \n",
       "addr_state_WV                                 -0.000206   \n",
       "addr_state_WY                                 -0.002342   \n",
       "initial_list_status_f                          0.005658   \n",
       "initial_list_status_w                         -0.005658   \n",
       "application_type_Individual                   -0.002663   \n",
       "application_type_Joint App                     0.002663   \n",
       "disbursement_method_Cash                       1.000000   \n",
       "disbursement_method_DirectPay                 -1.000000   \n",
       "\n",
       "                               disbursement_method_DirectPay  \n",
       "loan_amnt                                          -0.003903  \n",
       "funded_amnt                                        -0.003854  \n",
       "funded_amnt_inv                                    -0.003639  \n",
       "term                                                0.002836  \n",
       "installment                                         0.001185  \n",
       "annual_inc                                         -0.018666  \n",
       "loan_status                                        -0.024749  \n",
       "zip_code                                            0.002253  \n",
       "dti                                                 0.068471  \n",
       "delinq_2yrs                                         0.000463  \n",
       "inq_last_6mths                                     -0.003470  \n",
       "mths_since_last_delinq                              0.001749  \n",
       "mths_since_last_record                              0.000795  \n",
       "open_acc                                            0.022420  \n",
       "pub_rec                                             0.000406  \n",
       "revol_bal                                           0.014646  \n",
       "revol_util                                          0.009125  \n",
       "total_acc                                           0.014356  \n",
       "collections_12_mths_ex_med                         -0.000046  \n",
       "mths_since_last_major_derog                         0.000933  \n",
       "acc_now_delinq                                      0.000081  \n",
       "tot_coll_amt                                       -0.000184  \n",
       "tot_cur_bal                                         0.010182  \n",
       "open_acc_6m                                         0.050564  \n",
       "open_act_il                                         0.082425  \n",
       "open_il_12m                                         0.064204  \n",
       "open_il_24m                                         0.076857  \n",
       "mths_since_rcnt_il                                  0.051046  \n",
       "total_bal_il                                        0.079235  \n",
       "il_util                                             0.071777  \n",
       "...                                                      ...  \n",
       "addr_state_NC                                       0.000731  \n",
       "addr_state_ND                                       0.002508  \n",
       "addr_state_NE                                       0.003078  \n",
       "addr_state_NH                                      -0.000627  \n",
       "addr_state_NJ                                      -0.000977  \n",
       "addr_state_NM                                       0.002388  \n",
       "addr_state_NV                                       0.000970  \n",
       "addr_state_NY                                      -0.002588  \n",
       "addr_state_OH                                       0.001283  \n",
       "addr_state_OK                                       0.000934  \n",
       "addr_state_OR                                      -0.001319  \n",
       "addr_state_PA                                      -0.000568  \n",
       "addr_state_RI                                      -0.000962  \n",
       "addr_state_SC                                       0.001714  \n",
       "addr_state_SD                                       0.000444  \n",
       "addr_state_TN                                       0.002327  \n",
       "addr_state_TX                                       0.000796  \n",
       "addr_state_UT                                       0.001424  \n",
       "addr_state_VA                                      -0.000091  \n",
       "addr_state_VT                                       0.002104  \n",
       "addr_state_WA                                      -0.001674  \n",
       "addr_state_WI                                       0.000968  \n",
       "addr_state_WV                                       0.000206  \n",
       "addr_state_WY                                       0.002342  \n",
       "initial_list_status_f                              -0.005658  \n",
       "initial_list_status_w                               0.005658  \n",
       "application_type_Individual                         0.002663  \n",
       "application_type_Joint App                         -0.002663  \n",
       "disbursement_method_Cash                           -1.000000  \n",
       "disbursement_method_DirectPay                       1.000000  \n",
       "\n",
       "[221 rows x 221 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running corr() function to see how the features are correlated.\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "# for y in df.columns:\n",
    "    # plt.figure()\n",
    "    # df[y].plot.hist(bins=20, title=y)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 664548 samples.\n",
      "Testing set has 166137 samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.naive_bayes import GaussianNB\\nclf = GaussianNB()\\nresult = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\\nprint(result)\\n\\nfrom sklearn.tree import DecisionTreeClassifier\\nclf = DecisionTreeClassifier()\\nresult = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\\nprint(result)\\n\\nk_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\\nclf = GaussianNB()\\nprint(cross_val_score(clf, features, loan_status, cv=k_fold))\\n    \\n\\nk_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\\nclf = DecisionTreeClassifier()\\nprint(cross_val_score(clf, features, loan_status, cv=k_fold))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data in features and target label\n",
    "loan_status_raw = df['loan_status']\n",
    "loan_status = loan_status_raw.apply(lambda x: int(x > 0.1))\n",
    "features = df.drop('loan_status', axis=1)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "\n",
    "# Split the features and loan_status data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "    start = time() # Get start time\n",
    "    learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set,\n",
    "    #       then get predictions\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train)\n",
    "    end = time() # Get end time\n",
    "       \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # TODO: Compute accuracy\n",
    "    results['acc_train'] = accuracy_score(y_train, learner.predict(X_train))\n",
    "        \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test, learner.predict(X_test))\n",
    "    \n",
    "    # TODO: Compute F-score\n",
    "    results['f_train'] = fbeta_score(y_train, learner.predict(X_train), beta=0.5)\n",
    "        \n",
    "    # TODO: Compute F-score on the test set\n",
    "    results['f_test'] = fbeta_score(y_test, learner.predict(X_test), beta=0.5)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "clf = GaussianNB()\n",
    "print(cross_val_score(clf, features, loan_status, cv=k_fold))\n",
    "    \n",
    "\n",
    "k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "print(cross_val_score(clf, features, loan_status, cv=k_fold))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"-- Applying more strict rule to find outliers -- \")\\nfor feature in df.keys():\\n    \\n    # TODO: Calculate Q1 (25th percentile of the data) for the given feature\\n    Q1 = np.percentile(df[feature], 25)\\n    \\n    # TODO: Calculate Q3 (75th percentile of the data) for the given feature\\n    Q3 = np.percentile(df[feature], 75)\\n    \\n    # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\\n    step = 3*(Q3-Q1)\\n    \\n    # Display the outliers\\n    print(\"Data points considered outliers for the feature \\'{}\\':\".format(feature))\\n    display(df[~((df[feature] >= Q1 - step) & (df[feature] <= Q3 + step))])\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"-- Applying more strict rule to find outliers -- \")\n",
    "for feature in df.keys():\n",
    "    \n",
    "    # TODO: Calculate Q1 (25th percentile of the data) for the given feature\n",
    "    Q1 = np.percentile(df[feature], 25)\n",
    "    \n",
    "    # TODO: Calculate Q3 (75th percentile of the data) for the given feature\n",
    "    Q3 = np.percentile(df[feature], 75)\n",
    "    \n",
    "    # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "    step = 3*(Q3-Q1)\n",
    "    \n",
    "    # Display the outliers\n",
    "    print(\"Data points considered outliers for the feature '{}':\".format(feature))\n",
    "    display(df[~((df[feature] >= Q1 - step) & (df[feature] <= Q3 + step))])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/anilrajgr/udacity-machine-learning/blob/master/projects/customer_segments/customer_segments.ipynb\n",
    "# Apply PCA by fitting the data with the same number of dimensions as features\n",
    "from sklearn import decomposition\n",
    "\n",
    "# from vpython import *\n",
    "\n",
    "pca = decomposition.PCA(n_components=10)\n",
    "pca.fit(features)\n",
    "df_pca = pca.transform(features)\n",
    "\n",
    "# Generate PCA results plot\n",
    "# pca_results = vs.pca_results(features, pca)\n",
    "\n",
    "# print(pca_results['Explained Variance'].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51217575 0.16640004 0.08437912 0.05651567 0.03345007 0.02301765\n",
      " 0.01811418 0.01489836 0.01295687 0.01092446]\n",
      "[0.51217575 0.67857578 0.7629549  0.81947057 0.85292064 0.87593829\n",
      " 0.89405246 0.90895083 0.9219077  0.93283215]\n",
      "[19353.16645018 11031.11051081  7855.25024961  6428.75627727\n",
      "  4945.85100751  4102.73078348  3639.58472762  3300.74370823\n",
      "  3078.16997192  2826.45726687]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(np.cumsum(pca.explained_variance_ratio_))\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2b6f9feba8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(pca.explained_variance_ratio_).plot.bar()\n",
    "pd.Series(np.cumsum(pca.explained_variance_ratio_)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.25430865e+01, -3.63812036e+00, -5.86109209e+00, ...,\n",
       "        -2.43089591e+00,  7.95902593e-01, -2.76376507e+00],\n",
       "       [ 2.47984615e+00, -6.58026463e+00,  1.61272091e+00, ...,\n",
       "        -4.67954816e-01,  3.79294444e-01,  2.25044689e+00],\n",
       "       [ 1.17313735e+00, -6.94480992e+00,  5.15974168e+00, ...,\n",
       "        -1.73038030e+00,  1.07615609e+00,  1.31790248e+00],\n",
       "       ...,\n",
       "       [-1.69316331e-01, -5.21265500e+00,  4.46171966e-01, ...,\n",
       "        -6.58772607e+00,  2.44423067e+00,  4.82843761e+00],\n",
       "       [ 8.43928293e+00,  2.52948023e+01, -1.68121494e+00, ...,\n",
       "         1.79943600e-02, -5.49754180e+00,  7.07577516e-02],\n",
       "       [-2.00956073e+00, -5.43855470e+00, -6.48262920e+00, ...,\n",
       "        -2.37597641e+00, -7.09536061e+00,  4.03755184e-01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 664548 samples.\n",
      "Testing set has 166137 samples.\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.49657273292541504, 'pred_time': 0.5393543243408203, 'acc_train': 0.7931962777707554, 'acc_test': 0.7919849281015066, 'f_train': 0.82830653546155, 'f_test': 0.8272652269478087}\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 23.626851558685303, 'pred_time': 0.4553380012512207, 'acc_train': 1.0, 'acc_test': 0.6745156106105202, 'f_train': 1.0, 'f_test': 0.7974971646362633}\n",
      "[0.79198493 0.7928577  0.79344156 0.79442869 0.7921956 ]\n",
      "[0.67516568 0.67679686 0.67549673 0.67552682 0.67390166]\n"
     ]
    }
   ],
   "source": [
    "# Split the features (df_pca) and loan_status data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pca, loan_status, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "clf = GaussianNB()\n",
    "print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\n",
    "    \n",
    "\n",
    "k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor pca_comp in range(1,26):\\n    print(\"PCA component size: \" + str(pca_comp))\\n    pca = decomposition.PCA(n_components=pca_comp)\\n    pca.fit(features)\\n    df_pca = pca.transform(features)\\n    X_train, X_test, y_train, y_test = train_test_split(df_pca, loan_status, test_size = 0.2, random_state = 0)\\n    \\n    k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\\n    clf = GaussianNB()\\n    print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\\n    \\n    k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\\n    clf = DecisionTreeClassifier()\\n    print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for pca_comp in range(1,26):\n",
    "    print(\"PCA component size: \" + str(pca_comp))\n",
    "    pca = decomposition.PCA(n_components=pca_comp)\n",
    "    pca.fit(features)\n",
    "    df_pca = pca.transform(features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_pca, loan_status, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "    clf = GaussianNB()\n",
    "    print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\n",
    "    \n",
    "    k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(830685, 10)\n",
      "(830685, 221)\n",
      "(830685, 220)\n",
      "(830685,)\n"
     ]
    }
   ],
   "source": [
    "print(df_pca.shape)\n",
    "print(df.shape)\n",
    "# features = features[0:95]\n",
    "# loan_status = loan_status[0:95]\n",
    "print(features.shape)\n",
    "print(loan_status.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA data\n",
      "=============\n",
      "PCA component size: 1\n",
      "[[-12.54308653]\n",
      " [  2.47984615]\n",
      " [  1.17313735]\n",
      " ...\n",
      " [ -0.16931633]\n",
      " [  8.43928293]\n",
      " [ -2.00956073]]\n",
      "[[-0.5907049 ]\n",
      " [ 0.11678603]\n",
      " [ 0.0552478 ]\n",
      " ...\n",
      " [-0.00797379]\n",
      " [ 0.39744011]\n",
      " [-0.09463838]]\n",
      "(830685, 1)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 0.9582297801971436, 'pred_time': 0.04220008850097656, 'acc_train': 0.7941081757826373, 'acc_test': 0.7928035296171232, 'f_train': 0.8282113071611688, 'f_test': 0.8270988306304247}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 8.014352083206177, 'pred_time': 0.6022019386291504, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 15.59514594078064, 'pred_time': 1.5068175792694092, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 17.56389570236206, 'pred_time': 3.5575525760650635, 'acc_train': 0.7940795849208786, 'acc_test': 0.7928456635186623, 'f_train': 0.828187467807279, 'f_test': 0.8271137015254895}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.04579973220825195, 'pred_time': 0.02696061134338379, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.06351685523986816, 'pred_time': 0.03352475166320801, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "PCA component size: 2\n",
      "[[-12.54308653  -3.63812036]\n",
      " [  2.47984615  -6.58026463]\n",
      " [  1.17313735  -6.94480992]\n",
      " ...\n",
      " [ -0.16931633  -5.212655  ]\n",
      " [  8.43928293  25.29480234]\n",
      " [ -2.00956073  -5.4385547 ]]\n",
      "[[-0.5907049  -0.30059103]\n",
      " [ 0.11678603 -0.54367869]\n",
      " [ 0.0552478  -0.57379837]\n",
      " ...\n",
      " [-0.00797379 -0.4306832 ]\n",
      " [ 0.39744011  2.08992278]\n",
      " [-0.09463838 -0.44934762]]\n",
      "(830685, 2)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 1.540024995803833, 'pred_time': 0.04161334037780762, 'acc_train': 0.7940871088318677, 'acc_test': 0.7928215870034971, 'f_train': 0.8281926669347252, 'f_test': 0.8271052039992316}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.967271327972412, 'pred_time': 0.5552375316619873, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 16.48654055595398, 'pred_time': 1.5363423824310303, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 23.747621059417725, 'pred_time': 3.6120758056640625, 'acc_train': 0.7940810897030763, 'acc_test': 0.792839644389871, 'f_train': 0.8281920792408637, 'f_test': 0.8271136077924589}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.14616632461547852, 'pred_time': 0.09890365600585938, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.09329104423522949, 'pred_time': 0.08332538604736328, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "PCA component size: 3\n",
      "[[-12.54308653  -3.63812036  -5.86109209]\n",
      " [  2.47984615  -6.58026463   1.61272091]\n",
      " [  1.17313735  -6.94480992   5.15974168]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197]\n",
      " [  8.43928293  25.29480234  -1.68121493]\n",
      " [ -2.00956073  -5.4385547   -6.4826292 ]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352]\n",
      " [ 0.11678603 -0.54367869  0.18711878]\n",
      " [ 0.0552478  -0.57379837  0.5986681 ]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789]\n",
      " [ 0.39744011  2.08992278 -0.19506592]\n",
      " [-0.09463838 -0.44934762 -0.75215845]]\n",
      "(830685, 3)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 2.1406290531158447, 'pred_time': 0.043111562728881836, 'acc_train': 0.794084099267472, 'acc_test': 0.7928336252610797, 'f_train': 0.8281921179714709, 'f_test': 0.8271114834104234}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.494609355926514, 'pred_time': 0.540241003036499, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 13.134193897247314, 'pred_time': 1.7776429653167725, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 31.3887619972229, 'pred_time': 3.2360148429870605, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.1258082389831543, 'pred_time': 0.10788106918334961, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.104034423828125, 'pred_time': 0.09244704246520996, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "PCA component size: 4\n",
      "[[-12.54308653  -3.63812036  -5.86109209  -1.36630785]\n",
      " [  2.47984615  -6.58026463   1.61272091  -7.22735424]\n",
      " [  1.17313735  -6.94480992   5.15974168  -7.01145657]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197  -8.6425898 ]\n",
      " [  8.43928293  25.29480234  -1.68121494  -2.67209981]\n",
      " [ -2.00956073  -5.4385547   -6.4826292   -2.90062027]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 -0.19370453]\n",
      " [ 0.11678603 -0.54367869  0.18711878 -1.02463825]\n",
      " [ 0.0552478  -0.57379837  0.5986681  -0.99402995]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 -1.22527938]\n",
      " [ 0.39744011  2.08992278 -0.19506592 -0.37882959]\n",
      " [-0.09463838 -0.44934762 -0.75215845 -0.41122745]]\n",
      "(830685, 4)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 2.7076034545898438, 'pred_time': 0.04541134834289551, 'acc_train': 0.794084099267472, 'acc_test': 0.7928095487459145, 'f_train': 0.8281961999390418, 'f_test': 0.8271050162704447}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.421329736709595, 'pred_time': 0.5483002662658691, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 16.157415866851807, 'pred_time': 1.512570858001709, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 38.30947661399841, 'pred_time': 3.083472490310669, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.13126397132873535, 'pred_time': 0.11982369422912598, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.11880302429199219, 'pred_time': 0.12594866752624512, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "PCA component size: 5\n",
      "[[-12.54308653  -3.63812036  -5.86109209  -1.36630785   1.42592736]\n",
      " [  2.47984615  -6.58026463   1.61272091  -7.22735424   2.13429487]\n",
      " [  1.17313735  -6.94480992   5.15974168  -7.01145658  -3.92196906]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197  -8.6425898   11.48626628]\n",
      " [  8.43928293  25.29480234  -1.68121494  -2.6720998    1.41525329]\n",
      " [ -2.00956073  -5.4385547   -6.4826292   -2.90062027  -0.83084211]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 -0.19370453  0.26276926]\n",
      " [ 0.11678603 -0.54367869  0.18711878 -1.02463825  0.39330691]\n",
      " [ 0.0552478  -0.57379837  0.5986681  -0.99402995 -0.72273871]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 -1.22527938  2.11668404]\n",
      " [ 0.39744011  2.08992278 -0.19506592 -0.37882959  0.26080225]\n",
      " [-0.09463838 -0.44934762 -0.75215845 -0.41122745 -0.15310722]]\n",
      "(830685, 5)\n",
      "Decision Tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 3.3182408809661865, 'pred_time': 0.046865224838256836, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.376772403717041, 'pred_time': 0.5534989833831787, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 10.46353530883789, 'pred_time': 2.2440409660339355, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 46.153273582458496, 'pred_time': 3.0540482997894287, 'acc_train': 0.7940750705742851, 'acc_test': 0.7928456635186623, 'f_train': 0.8281858789991712, 'f_test': 0.8271137015254895}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.13507723808288574, 'pred_time': 0.11661934852600098, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.29937052726745605, 'pred_time': 0.13086485862731934, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928336252610797, 'f_train': 0.828186938205906, 'f_test': 0.8271094528050474}\n",
      "PCA component size: 6\n",
      "[[-12.54308653  -3.63812036  -5.86109209  -1.36630785   1.42592729\n",
      "   -6.09345214]\n",
      " [  2.47984615  -6.58026463   1.61272091  -7.22735424   2.13429488\n",
      "   -2.64167422]\n",
      " [  1.17313735  -6.94480992   5.15974168  -7.01145657  -3.92196893\n",
      "   -0.87341378]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197  -8.6425898   11.48626646\n",
      "    3.42855077]\n",
      " [  8.43928293  25.29480234  -1.68121494  -2.67209981   1.41525316\n",
      "   -1.99037003]\n",
      " [ -2.00956073  -5.4385547   -6.4826292   -2.90062027  -0.83084209\n",
      "   -4.65774359]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 -0.19370453  0.26276925 -1.3536568 ]\n",
      " [ 0.11678603 -0.54367869  0.18711878 -1.02463825  0.39330691 -0.58684637]\n",
      " [ 0.0552478  -0.57379837  0.5986681  -0.99402995 -0.72273869 -0.19402836]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 -1.22527938  2.11668407  0.76165053]\n",
      " [ 0.39744011  2.08992278 -0.19506592 -0.37882959  0.26080222 -0.44215953]\n",
      " [-0.09463838 -0.44934762 -0.75215845 -0.41122745 -0.15310721 -1.03471499]]\n",
      "(830685, 6)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 4.033948659896851, 'pred_time': 0.04679727554321289, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.43558931350708, 'pred_time': 0.5711805820465088, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 13.669924974441528, 'pred_time': 2.5031566619873047, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 55.68495512008667, 'pred_time': 3.1726603507995605, 'acc_train': 0.7940765753564829, 'acc_test': 0.7928456635186623, 'f_train': 0.8281858983876096, 'f_test': 0.8271137015254895}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.15611529350280762, 'pred_time': 0.11702537536621094, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.21699953079223633, 'pred_time': 0.1172034740447998, 'acc_train': 0.794023907979559, 'acc_test': 0.7928155678747059, 'f_train': 0.8281765453177369, 'f_test': 0.8271172944248443}\n",
      "PCA component size: 7\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...   1.42592729  -6.09345215\n",
      "   -2.51505283]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...   2.13429488  -2.64167401\n",
      "   -3.06232779]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...  -3.92196893  -0.87341397\n",
      "   -2.29112346]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...  11.48626646   3.4285508\n",
      "   14.87170344]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   1.41525315  -1.99036984\n",
      "    2.46895584]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...  -0.83084209  -4.65774367\n",
      "    4.54542938]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ...  0.26276925 -1.3536568\n",
      "  -0.62981567]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ...  0.39330691 -0.58684632\n",
      "  -0.76686343]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ... -0.72273869 -0.1940284\n",
      "  -0.57373962]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  2.11668407  0.76165054\n",
      "   3.72414916]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.26080222 -0.44215949\n",
      "   0.61827213]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -0.15310721 -1.03471501\n",
      "   1.13825945]]\n",
      "(830685, 7)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 4.651235342025757, 'pred_time': 0.05241823196411133, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.576172828674316, 'pred_time': 0.6288552284240723, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 17.984615564346313, 'pred_time': 3.185235023498535, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 67.71171474456787, 'pred_time': 3.9193012714385986, 'acc_train': 0.7940675466632959, 'acc_test': 0.792839644389871, 'f_train': 0.8281842513896636, 'f_test': 0.8271136077924589}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.2637157440185547, 'pred_time': 0.36505579948425293, 'acc_train': 0.7939832788602178, 'acc_test': 0.7927553765867928, 'f_train': 0.8281846960281581, 'f_test': 0.8271041713508374}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.2962329387664795, 'pred_time': 0.4199388027191162, 'acc_train': 0.7923114658384346, 'acc_test': 0.7909556570781945, 'f_train': 0.8279588045002735, 'f_test': 0.826870160498449}\n",
      "PCA component size: 8\n",
      "[[-1.25430865e+01 -3.63812036e+00 -5.86109209e+00 ... -6.09345220e+00\n",
      "  -2.51505264e+00 -2.43089601e+00]\n",
      " [ 2.47984615e+00 -6.58026463e+00  1.61272091e+00 ... -2.64167392e+00\n",
      "  -3.06232757e+00 -4.67958881e-01]\n",
      " [ 1.17313735e+00 -6.94480992e+00  5.15974168e+00 ... -8.73413938e-01\n",
      "  -2.29112364e+00 -1.73038041e+00]\n",
      " ...\n",
      " [-1.69316331e-01 -5.21265500e+00  4.46171966e-01 ...  3.42855066e+00\n",
      "   1.48717033e+01 -6.58772141e+00]\n",
      " [ 8.43928293e+00  2.52948023e+01 -1.68121494e+00 ... -1.99036995e+00\n",
      "   2.46895571e+00  1.79976551e-02]\n",
      " [-2.00956073e+00 -5.43855470e+00 -6.48262920e+00 ... -4.65774380e+00\n",
      "   4.54542937e+00 -2.37597317e+00]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -1.35365681 -0.62981562\n",
      "  -0.67123217]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -0.5868463  -0.76686337\n",
      "  -0.12921534]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ... -0.19402839 -0.57373967\n",
      "  -0.47780201]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  0.76165051  3.72414912\n",
      "  -1.8190373 ]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ... -0.44215951  0.6182721\n",
      "   0.00496961]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -1.03471504  1.13825945\n",
      "  -0.65606657]]\n",
      "(830685, 8)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 6.028779745101929, 'pred_time': 0.06753897666931152, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 8.58249568939209, 'pred_time': 0.7696282863616943, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 17.41123366355896, 'pred_time': 2.651376962661743, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 71.65729713439941, 'pred_time': 3.200566291809082, 'acc_train': 0.7940690514454938, 'acc_test': 0.7928276061322884, 'f_train': 0.8281878423591696, 'f_test': 0.8271093590070443}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.3210434913635254, 'pred_time': 0.358487606048584, 'acc_train': 0.7938644010665896, 'acc_test': 0.7925748027230539, 'f_train': 0.8281739749769418, 'f_test': 0.8270830689353168}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.41341066360473633, 'pred_time': 0.5266063213348389, 'acc_train': 0.7911693361502856, 'acc_test': 0.7898060034790565, 'f_train': 0.827866448128082, 'f_test': 0.8267249493079989}\n",
      "PCA component size: 9\n",
      "[[-1.25430865e+01 -3.63812036e+00 -5.86109209e+00 ... -2.51505264e+00\n",
      "  -2.43089605e+00  7.95902388e-01]\n",
      " [ 2.47984615e+00 -6.58026463e+00  1.61272091e+00 ... -3.06232774e+00\n",
      "  -4.67954601e-01  3.79294521e-01]\n",
      " [ 1.17313735e+00 -6.94480992e+00  5.15974168e+00 ... -2.29112365e+00\n",
      "  -1.73038049e+00  1.07615613e+00]\n",
      " ...\n",
      " [-1.69316331e-01 -5.21265500e+00  4.46171966e-01 ...  1.48717034e+01\n",
      "  -6.58772639e+00  2.44423073e+00]\n",
      " [ 8.43928293e+00  2.52948023e+01 -1.68121494e+00 ...  2.46895583e+00\n",
      "   1.79938560e-02 -5.49754198e+00]\n",
      " [-2.00956073e+00 -5.43855470e+00 -6.48262920e+00 ...  4.54542945e+00\n",
      "  -2.37597687e+00 -7.09536032e+00]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -0.62981562 -0.67123218\n",
      "   0.23565974]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -0.76686341 -0.12921416\n",
      "   0.11230579]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ... -0.57373967 -0.47780203\n",
      "   0.31864042]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  3.72414915 -1.81903868\n",
      "   0.72371535]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.61827213  0.00496856\n",
      "  -1.62777413]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ...  1.13825947 -0.6560676\n",
      "  -2.10087417]]\n",
      "(830685, 9)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 5.884078741073608, 'pred_time': 0.04911470413208008, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.437784910202026, 'pred_time': 0.5629334449768066, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 18.252683639526367, 'pred_time': 1.8809843063354492, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 83.25974369049072, 'pred_time': 3.2651138305664062, 'acc_train': 0.7940705562276916, 'acc_test': 0.7928456635186623, 'f_train': 0.8281853106124549, 'f_test': 0.8271157321531508}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.34868335723876953, 'pred_time': 0.4059717655181885, 'acc_train': 0.7934987389925182, 'acc_test': 0.7921113298061239, 'f_train': 0.8281508557491793, 'f_test': 0.8270310721495185}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.5504910945892334, 'pred_time': 0.7283825874328613, 'acc_train': 0.7869815272937395, 'acc_test': 0.7854361159765736, 'f_train': 0.8271656344843579, 'f_test': 0.8259982148700561}\n",
      "PCA component size: 10\n",
      "[[-1.25430865e+01 -3.63812036e+00 -5.86109209e+00 ... -2.43089667e+00\n",
      "   7.95900986e-01 -2.76376226e+00]\n",
      " [ 2.47984615e+00 -6.58026463e+00  1.61272091e+00 ... -4.67954438e-01\n",
      "   3.79294639e-01  2.25044554e+00]\n",
      " [ 1.17313735e+00 -6.94480992e+00  5.15974168e+00 ... -1.73037961e+00\n",
      "   1.07615774e+00  1.31790011e+00]\n",
      " ...\n",
      " [-1.69316331e-01 -5.21265500e+00  4.46171966e-01 ... -6.58772674e+00\n",
      "   2.44422905e+00  4.82843946e+00]\n",
      " [ 8.43928293e+00  2.52948023e+01 -1.68121494e+00 ...  1.79937580e-02\n",
      "  -5.49754275e+00  7.07598652e-02]\n",
      " [-2.00956073e+00 -5.43855470e+00 -6.48262920e+00 ... -2.37597732e+00\n",
      "  -7.09536252e+00  4.03757224e-01]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -0.67123235  0.23565933\n",
      "  -0.8912026 ]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -0.12921411  0.11230583\n",
      "   0.72567852]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ... -0.47780179  0.3186409\n",
      "   0.42496998]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ... -1.81903877  0.72371486\n",
      "   1.55697827]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.00496853 -1.62777435\n",
      "   0.02281722]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -0.65606772 -2.10087482\n",
      "   0.13019553]]\n",
      "(830685, 10)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 6.83873176574707, 'pred_time': 0.054847002029418945, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.655323028564453, 'pred_time': 0.5980839729309082, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 12.884826898574829, 'pred_time': 2.6318821907043457, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 93.49320578575134, 'pred_time': 3.8261172771453857, 'acc_train': 0.7940494892769221, 'acc_test': 0.7927373192004189, 'f_train': 0.8282105546037825, 'f_test': 0.8270998277856705}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.36661601066589355, 'pred_time': 0.46972107887268066, 'acc_train': 0.7931962777707554, 'acc_test': 0.7919849281015066, 'f_train': 0.82830653546155, 'f_test': 0.8272652269478087}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.5511841773986816, 'pred_time': 0.7296483516693115, 'acc_train': 0.7855429555126191, 'acc_test': 0.7835039756345666, 'f_train': 0.82806156336884, 'f_test': 0.8266100822450974}\n",
      "PCA component size: 11\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...   0.79590246  -2.7637641\n",
      "   -0.56358785]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...   0.37929413   2.25044619\n",
      "   -1.28226159]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   1.07615609   1.31790274\n",
      "    0.32576348]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   2.4442308    4.82843644\n",
      "    0.5500747 ]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...  -5.49754172   0.07075864\n",
      "    1.30208029]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...  -7.09536034   0.40375368\n",
      "   -0.75057986]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ...  0.23565976 -0.89120319\n",
      "  -0.21322497]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ...  0.11230568  0.72567873\n",
      "  -0.48512436]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  0.31864041  0.42497083\n",
      "   0.12324771]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  0.72371538  1.55697729\n",
      "   0.20811248]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ... -1.62777405  0.02281683\n",
      "   0.49262247]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -2.10087418  0.13019438\n",
      "  -0.28397059]]\n",
      "(830685, 11)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 7.542964696884155, 'pred_time': 0.060692548751831055, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.675943374633789, 'pred_time': 0.6271274089813232, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 13.684725761413574, 'pred_time': 2.7203001976013184, 'acc_train': 0.7940795849208786, 'acc_test': 0.792839644389871, 'f_train': 0.8281900189305778, 'f_test': 0.8271115771759403}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 93.24704909324646, 'pred_time': 3.1445508003234863, 'acc_train': 0.7940389558015373, 'acc_test': 0.7928035296171232, 'f_train': 0.8282303265390578, 'f_test': 0.8271455435980088}\n",
      "Naive Bayes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.34664249420166016, 'pred_time': 0.449460506439209, 'acc_train': 0.7933302033863618, 'acc_test': 0.7921053106773326, 'f_train': 0.8283906595349033, 'f_test': 0.8273445186126693}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.5251805782318115, 'pred_time': 0.6844885349273682, 'acc_train': 0.7839223050855619, 'acc_test': 0.7820353082094897, 'f_train': 0.8281050314439069, 'f_test': 0.8267531727271203}\n",
      "PCA component size: 12\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...  -2.76376479  -0.5635845\n",
      "   -1.38418549]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...   2.25044661  -1.28226399\n",
      "   -1.75843997]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   1.31790233   0.32576769\n",
      "   -0.63440304]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   4.82843737   0.5500701\n",
      "    2.2286469 ]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   0.07075801   1.30208332\n",
      "   -1.3374605 ]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...   0.40375452  -0.75058243\n",
      "   -1.83510617]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -0.89120341 -0.21322371\n",
      "  -0.59809021]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ...  0.72567887 -0.48512527\n",
      "  -0.75980115]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  0.4249707   0.1232493\n",
      "  -0.27411806]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  1.55697759  0.20811074\n",
      "   0.96297202]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.02281662  0.49262361\n",
      "  -0.57790089]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ...  0.13019466 -0.28397156\n",
      "  -0.79292771]]\n",
      "(830685, 12)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 7.7993268966674805, 'pred_time': 0.05806589126586914, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.513160705566406, 'pred_time': 0.5823159217834473, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 16.11449146270752, 'pred_time': 2.625140428543091, 'acc_train': 0.7940795849208786, 'acc_test': 0.7928456635186623, 'f_train': 0.828187467807279, 'f_test': 0.8271137015254895}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 101.09475302696228, 'pred_time': 3.16504168510437, 'acc_train': 0.7940570131879112, 'acc_test': 0.7928215870034971, 'f_train': 0.8282147340939365, 'f_test': 0.8271437920565357}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.35979771614074707, 'pred_time': 0.456723690032959, 'acc_train': 0.7933256890397684, 'acc_test': 0.7920210428742543, 'f_train': 0.8284351772987117, 'f_test': 0.8273248965347815}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.5843315124511719, 'pred_time': 0.591193675994873, 'acc_train': 0.7832812678692886, 'acc_test': 0.7814032996864034, 'f_train': 0.8282779738771708, 'f_test': 0.8267987663461079}\n",
      "PCA component size: 13\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...  -0.5635834   -1.38419113\n",
      "   -1.72080417]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...  -1.28226396  -1.75844022\n",
      "    3.41747176]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   0.3257657   -0.63439474\n",
      "    1.67796154]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   0.5500689    2.22865316\n",
      "    1.83733068]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   1.30208421  -1.33746527\n",
      "   -1.53913807]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...  -0.75058545  -1.83509259\n",
      "   -0.37474393]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -0.21322329 -0.59809265\n",
      "  -0.78558057]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -0.48512526 -0.75980126\n",
      "   1.56014231]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  0.12324855 -0.27411448\n",
      "   0.76602207]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  0.20811028  0.96297472\n",
      "   0.83877719]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.49262395 -0.57790296\n",
      "  -0.70264646]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -0.2839727  -0.79292185\n",
      "  -0.17107789]]\n",
      "(830685, 13)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 8.479849100112915, 'pred_time': 0.06343269348144531, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.394660234451294, 'pred_time': 0.5739936828613281, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 12.15645456314087, 'pred_time': 2.7002017498016357, 'acc_train': 0.7940028410287895, 'acc_test': 0.7928757591626188, 'f_train': 0.828224759858058, 'f_test': 0.8272015176165379}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 108.92567276954651, 'pred_time': 3.186314344406128, 'acc_train': 0.7941051662182416, 'acc_test': 0.7924423818896453, 'f_train': 0.8288696460552384, 'f_test': 0.8275188354460357}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.3764176368713379, 'pred_time': 0.4875762462615967, 'acc_train': 0.7928471683008601, 'acc_test': 0.7911843839722639, 'f_train': 0.8291578593351702, 'f_test': 0.8278243766113936}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.6319558620452881, 'pred_time': 0.6271135807037354, 'acc_train': 0.7821887959936679, 'acc_test': 0.7798744409734135, 'f_train': 0.829480189720961, 'f_test': 0.8277957041817412}\n",
      "PCA component size: 14\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...  -1.38419087  -1.72081388\n",
      "    0.06701459]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...  -1.75843967   3.41746813\n",
      "    2.76868983]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...  -0.63439507   1.67795399\n",
      "    1.90924759]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   2.22865278   1.8373455\n",
      "    2.78522006]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...  -1.33746508  -1.53914902\n",
      "   -1.13739734]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...  -1.83509234  -0.37474766\n",
      "    0.73885766]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -0.59809253 -0.785585\n",
      "   0.03098104]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -0.75980102  1.56014065\n",
      "   1.27997331]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ... -0.27411462  0.76601862\n",
      "   0.88265067]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  0.96297456  0.83878395\n",
      "   1.28761528]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ... -0.57790287 -0.70265146\n",
      "  -0.52582208]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -0.79292174 -0.17107959\n",
      "   0.34157603]]\n",
      "(830685, 14)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 9.767510414123535, 'pred_time': 0.06865668296813965, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 8.51644253730774, 'pred_time': 0.6686687469482422, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 21.107200145721436, 'pred_time': 2.624213933944702, 'acc_train': 0.7939757549492287, 'acc_test': 0.7927854722307494, 'f_train': 0.828335260925615, 'f_test': 0.8272631627903468}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 117.79206418991089, 'pred_time': 3.1747043132781982, 'acc_train': 0.7940991470894503, 'acc_test': 0.7928817782914102, 'f_train': 0.8290088657494289, 'f_test': 0.8279379000868732}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.48227620124816895, 'pred_time': 0.5489563941955566, 'acc_train': 0.7935499015872443, 'acc_test': 0.7921775402228282, 'f_train': 0.8292483337467043, 'f_test': 0.8280760786167616}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.7803258895874023, 'pred_time': 0.8293144702911377, 'acc_train': 0.7804176673468283, 'acc_test': 0.7781108362375629, 'f_train': 0.8297578154118179, 'f_test': 0.8280680859771062}\n",
      "PCA component size: 15\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...  -1.72080726   0.06701253\n",
      "   -1.62735067]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...   3.41746529   2.76869048\n",
      "    0.89141823]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   1.67796195   1.90924469\n",
      "    3.5789632 ]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   1.83734211   2.7852214\n",
      "    3.49393496]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...  -1.53914539  -1.13739861\n",
      "   -1.84969996]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...  -0.37474145   0.73885643\n",
      "    0.49446909]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5907049  -0.30059103 -0.68004352 ... -0.78558198  0.03098009\n",
      "  -0.77280211]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ...  1.56013936  1.2799736\n",
      "   0.42331988]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  0.76602226  0.88264934\n",
      "   1.69959085]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  0.8387824   1.2876159\n",
      "   1.65921233]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ... -0.7026498  -0.52582266\n",
      "  -0.87839213]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -0.17107676  0.34157546\n",
      "   0.23481525]]\n",
      "(830685, 15)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 9.643917322158813, 'pred_time': 0.06610393524169922, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.422440767288208, 'pred_time': 0.5858047008514404, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 19.072632312774658, 'pred_time': 2.711151361465454, 'acc_train': 0.793963716691646, 'acc_test': 0.7928035296171232, 'f_train': 0.8281936306516451, 'f_test': 0.827151638185854}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 128.65055871009827, 'pred_time': 3.3963871002197266, 'acc_train': 0.7941202140402198, 'acc_test': 0.792839644389871, 'f_train': 0.8291217884507032, 'f_test': 0.8279782812963115}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.49274778366088867, 'pred_time': 0.6065762042999268, 'acc_train': 0.7936085880929594, 'acc_test': 0.7922497697683237, 'f_train': 0.8293951231633145, 'f_test': 0.8281941334088672}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.8469822406768799, 'pred_time': 0.8853421211242676, 'acc_train': 0.7804823729813347, 'acc_test': 0.7777858032828329, 'f_train': 0.8299760850400099, 'f_test': 0.8281361421147807}\n",
      "PCA component size: 16\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...   0.06701341  -1.62735274\n",
      "    2.12962402]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...   2.76869126   0.89141855\n",
      "   -1.26419887]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   1.90924616   3.57896411\n",
      "    0.67035362]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   2.78521977   3.49393714\n",
      "   -1.39043793]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...  -1.13739754  -1.8497018\n",
      "    1.27817077]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...   0.73885651   0.49447109\n",
      "    0.86391037]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ...  0.03098049 -0.77280309\n",
      "   1.0786224 ]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ...  1.27997397  0.42332003\n",
      "  -0.64029763]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  0.88265002  1.69959128\n",
      "   0.33952398]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  1.28761515  1.65921337\n",
      "  -0.70423582]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ... -0.52582217 -0.87839301\n",
      "   0.64737419]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ...  0.3415755   0.2348162\n",
      "   0.43755756]]\n",
      "(830685, 16)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 10.887898921966553, 'pred_time': 0.0697784423828125, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.553871154785156, 'pred_time': 0.5992238521575928, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 16.150577068328857, 'pred_time': 3.110046148300171, 'acc_train': 0.7939336210476896, 'acc_test': 0.7927132426852538, 'f_train': 0.8281927328735185, 'f_test': 0.8271177327097002}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 136.06541657447815, 'pred_time': 3.3825507164001465, 'acc_train': 0.7941202140402198, 'acc_test': 0.7927975104883319, 'f_train': 0.8291686521633689, 'f_test': 0.827992052729509}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.5026657581329346, 'pred_time': 0.6053690910339355, 'acc_train': 0.7936447028657072, 'acc_test': 0.7921534637076629, 'f_train': 0.829507188787143, 'f_test': 0.8282484131633118}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.8477504253387451, 'pred_time': 0.7964894771575928, 'acc_train': 0.7789068660202122, 'acc_test': 0.7767384748731468, 'f_train': 0.8303448271309384, 'f_test': 0.8287292452817726}\n",
      "PCA component size: 17\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...  -1.62734962   2.12962154\n",
      "   -0.06906312]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...   0.8914175   -1.26419146\n",
      "    0.93964241]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   3.57896829   0.67034781\n",
      "   -0.04241779]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   3.49393352  -1.39043923\n",
      "   -0.16221452]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...  -1.84969846   1.27816731\n",
      "    1.26715108]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...   0.49447273   0.86390323\n",
      "   -0.40604354]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -0.77280161  1.07862115\n",
      "  -0.03901873]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ...  0.42331953 -0.64029388\n",
      "   0.53087168]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  1.69959327  0.33952104\n",
      "  -0.02396487]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  1.65921165 -0.70423647\n",
      "  -0.09164667]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ... -0.87839142  0.64737244\n",
      "   0.71590492]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ...  0.23481698  0.43755394\n",
      "  -0.22940324]]\n",
      "(830685, 17)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 11.420476198196411, 'pred_time': 0.11327075958251953, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.620087385177612, 'pred_time': 0.6576657295227051, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 18.33940052986145, 'pred_time': 4.069873332977295, 'acc_train': 0.7939306114832939, 'acc_test': 0.7927674148443754, 'f_train': 0.8282212827753024, 'f_test': 0.8271795277747412}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 143.71143794059753, 'pred_time': 3.353355884552002, 'acc_train': 0.7941202140402198, 'acc_test': 0.7927975104883319, 'f_train': 0.8291686521633689, 'f_test': 0.827992052729509}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.5651013851165771, 'pred_time': 0.6713500022888184, 'acc_train': 0.7933602990303183, 'acc_test': 0.7917682394650198, 'f_train': 0.8296096116826747, 'f_test': 0.8283011386884245}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.9670343399047852, 'pred_time': 1.0121850967407227, 'acc_train': 0.7780611784250347, 'acc_test': 0.7754503813118089, 'f_train': 0.8305530341990867, 'f_test': 0.8286531182223}\n",
      "PCA component size: 18\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...   2.12962367  -0.06906844\n",
      "    0.29731275]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...  -1.26418998   0.93963743\n",
      "   -0.48659991]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   0.67034598  -0.04240801\n",
      "    1.26827339]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...  -1.39044214  -0.16220588\n",
      "    1.35117777]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   1.27817061   1.26714302\n",
      "    2.03694185]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...   0.86390107  -0.40603555\n",
      "    1.61761411]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ...  1.07862223 -0.03902174\n",
      "   0.20043955]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -0.64029313  0.53086887\n",
      "  -0.32805142]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  0.33952012 -0.02395934\n",
      "   0.8550328 ]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ... -0.70423795 -0.09164178\n",
      "   0.91092451]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.64737411  0.71590036\n",
      "   1.37324658]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ...  0.43755285 -0.22939873\n",
      "   1.09054809]]\n",
      "(830685, 18)\n",
      "Decision Tree\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 11.632207155227661, 'pred_time': 0.11545968055725098, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.403136968612671, 'pred_time': 0.6476595401763916, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 22.671387195587158, 'pred_time': 2.672089099884033, 'acc_train': 0.7939697358204374, 'acc_test': 0.7928035296171232, 'f_train': 0.8281824800765822, 'f_test': 0.8271353867681953}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 151.91880440711975, 'pred_time': 3.8280160427093506, 'acc_train': 0.7939095445325244, 'acc_test': 0.7926650896549233, 'f_train': 0.8293113666855806, 'f_test': 0.8282159374719706}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.5982072353363037, 'pred_time': 0.7120821475982666, 'acc_train': 0.7933452512083401, 'acc_test': 0.7917862968513937, 'f_train': 0.8296307252129006, 'f_test': 0.8283425800051438}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 1.0811617374420166, 'pred_time': 1.1211798191070557, 'acc_train': 0.7772320434340334, 'acc_test': 0.775089233584331, 'f_train': 0.8305818660408579, 'f_test': 0.8288974191809415}\n",
      "PCA component size: 19\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...  -0.0690695    0.29731631\n",
      "   -1.53116886]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...   0.93963837  -0.48660819\n",
      "   -0.6083332 ]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...  -0.04240868   1.26826781\n",
      "    1.50964983]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...  -0.16220402   1.35118086\n",
      "    0.62769392]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   1.26714185   2.03694053\n",
      "    0.47269019]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...  -0.40603567   1.61762018\n",
      "   -0.30932671]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -0.03902234  0.20044196\n",
      "  -1.05268716]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ...  0.53086939 -0.328057\n",
      "  -0.41823248]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ... -0.02395972  0.85502904\n",
      "   1.03789271]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ... -0.09164073  0.91092659\n",
      "   0.43154308]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.7158997   1.37324569\n",
      "   0.32497715]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -0.2293988   1.09055218\n",
      "  -0.21266384]]\n",
      "(830685, 19)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 12.422574043273926, 'pred_time': 0.12168550491333008, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.460656642913818, 'pred_time': 0.6488037109375, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 23.336058139801025, 'pred_time': 2.699795961380005, 'acc_train': 0.7939260971367005, 'acc_test': 0.7927975104883319, 'f_train': 0.8281936569154906, 'f_test': 0.8271637354533382}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 156.0346097946167, 'pred_time': 3.3694264888763428, 'acc_train': 0.7939652214738439, 'acc_test': 0.7929058548065753, 'f_train': 0.8292923231170829, 'f_test': 0.8282621515785592}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.5068743228912354, 'pred_time': 0.6858413219451904, 'acc_train': 0.7931887538597663, 'acc_test': 0.791569608214907, 'f_train': 0.8298348611167052, 'f_test': 0.8285194090069973}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 0.9647858142852783, 'pred_time': 0.9166178703308105, 'acc_train': 0.7741156395023384, 'acc_test': 0.7720254970295599, 'f_train': 0.8305611813032613, 'f_test': 0.8288502339153889}\n",
      "PCA component size: 20\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...   0.29730117  -1.53117976\n",
      "   -0.53229951]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...  -0.48660481  -0.60829526\n",
      "   -2.58679422]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   1.26827351   1.50966118\n",
      "   -0.69736629]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   1.35119058   0.62774985\n",
      "    1.1334077 ]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   2.03692907   0.47268492\n",
      "    0.77351746]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...   1.61761175  -0.30930694\n",
      "    0.45063473]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ...  0.20043175 -1.05269465\n",
      "  -0.37782464]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -0.32805472 -0.4182064\n",
      "  -1.83609899]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  0.85503288  1.03790051\n",
      "  -0.49498856]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  0.91093314  0.43158154\n",
      "   0.80448948]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  1.37323796  0.32497353\n",
      "   0.54904044]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ...  1.0905465  -0.21265025\n",
      "   0.31985922]]\n",
      "(830685, 20)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 12.895258903503418, 'pred_time': 0.1285848617553711, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.3960442543029785, 'pred_time': 0.6640551090240479, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 18.85589098930359, 'pred_time': 2.652059555053711, 'acc_train': 0.7939321162654918, 'acc_test': 0.7928456635186623, 'f_train': 0.8282151752484337, 'f_test': 0.8272010553758206}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 166.83255004882812, 'pred_time': 3.4009060859680176, 'acc_train': 0.7939667262560417, 'acc_test': 0.7929058548065753, 'f_train': 0.8292928543580824, 'f_test': 0.8282621515785592}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.537177562713623, 'pred_time': 0.7363739013671875, 'acc_train': 0.7931797251665794, 'acc_test': 0.7917080481771068, 'f_train': 0.8298332220634667, 'f_test': 0.828609929995927}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 1.068485975265503, 'pred_time': 0.9602260589599609, 'acc_train': 0.7732248084412262, 'acc_test': 0.7712309720291085, 'f_train': 0.8305634018773239, 'f_test': 0.8288866556735224}\n",
      "PCA component size: 21\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...  -1.53116914  -0.53238288\n",
      "    1.29536595]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...  -0.60827976  -2.58680004\n",
      "   -0.16761282]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   1.50966776  -0.69740228\n",
      "   -1.77604106]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   0.62777092   1.13343897\n",
      "    1.77598905]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   0.47270076   0.77341978\n",
      "    0.57291857]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...  -0.30929187   0.45055409\n",
      "    1.5068734 ]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -1.05268735 -0.37788381\n",
      "   0.93318547]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -0.41819574 -1.83610311\n",
      "  -0.12074877]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  1.03790503 -0.4950141\n",
      "  -1.27946525]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  0.43159602  0.80451167\n",
      "   1.27942778]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.32498441  0.5489711\n",
      "   0.41273224]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -0.21263989  0.31980198\n",
      "   1.08555607]]\n",
      "(830685, 21)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 13.516766786575317, 'pred_time': 0.1294698715209961, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.6519646644592285, 'pred_time': 0.6708905696868896, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 16.235997915267944, 'pred_time': 3.5819671154022217, 'acc_train': 0.7938824584529636, 'acc_test': 0.7927493574580016, 'f_train': 0.8282165811353206, 'f_test': 0.8271853468695848}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 171.96786880493164, 'pred_time': 3.4196794033050537, 'acc_train': 0.7939035254037331, 'acc_test': 0.7930743904127316, 'f_train': 0.8292973716756794, 'f_test': 0.8283895869987786}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.5653491020202637, 'pred_time': 0.755756139755249, 'acc_train': 0.7925672788120648, 'acc_test': 0.7908774084039076, 'f_train': 0.8298756900591764, 'f_test': 0.8285523597648181}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 1.0868051052093506, 'pred_time': 1.0851082801818848, 'acc_train': 0.7693409655886407, 'acc_test': 0.767775992102903, 'f_train': 0.8298215663094705, 'f_test': 0.8283099373420552}\n",
      "PCA component size: 22\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...  -0.53171743   1.29483187\n",
      "    1.22747276]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...  -2.58687693  -0.16743276\n",
      "   -2.07093787]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...  -0.69754638  -1.77603067\n",
      "    0.27339874]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   1.13319137   1.77592728\n",
      "   -1.63497309]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   0.7743735    0.57180332\n",
      "    1.5493198 ]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...   0.45153454   1.50570324\n",
      "   -2.16958086]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -0.37741163  0.93280138\n",
      "   1.01446565]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -1.83615842 -0.12061914\n",
      "  -1.71156169]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ... -0.49511658 -1.27945868\n",
      "   0.22595502]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  0.80433624  1.2793842\n",
      "  -1.3512512 ]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.54964827  0.4119291\n",
      "   1.28046159]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ...  0.32049803  1.08471386\n",
      "  -1.79308686]]\n",
      "(830685, 22)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 14.20846438407898, 'pred_time': 0.13526296615600586, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.360973119735718, 'pred_time': 0.6736719608306885, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 18.881122827529907, 'pred_time': 3.6850175857543945, 'acc_train': 0.7939652214738439, 'acc_test': 0.7927493574580016, 'f_train': 0.8282053898749481, 'f_test': 0.8271264200316323}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 182.83499908447266, 'pred_time': 3.513605833053589, 'acc_train': 0.7938854680173592, 'acc_test': 0.7928938165489927, 'f_train': 0.8292590065851139, 'f_test': 0.8283071847294341}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.6130983829498291, 'pred_time': 0.7957189083099365, 'acc_train': 0.792531164039317, 'acc_test': 0.7909977909797336, 'f_train': 0.829999920513167, 'f_test': 0.8287381718316918}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 1.1334033012390137, 'pred_time': 1.0223026275634766, 'acc_train': 0.7686893948969826, 'acc_test': 0.7673305765723469, 'f_train': 0.8299119301183825, 'f_test': 0.8285461297777825}\n",
      "PCA component size: 23\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...   1.29546674   1.2261944\n",
      "   -1.46198253]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...  -0.16767403  -2.06983601\n",
      "    0.46369103]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...  -1.77590628   0.27268705\n",
      "   -0.03651527]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   1.77612959  -1.63499255\n",
      "    0.38601025]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   0.57310906   1.54949337\n",
      "   -0.46738829]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...   1.50681515  -2.17071725\n",
      "    1.0677365 ]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ...  0.93325815  1.01340805\n",
      "  -1.40138062]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -0.12079288 -1.7106492\n",
      "   0.44447017]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ... -1.27936824  0.22536659\n",
      "  -0.03500164]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  1.27952912 -1.35126585\n",
      "   0.3700094 ]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  0.4128695   1.28060367\n",
      "  -0.44801417]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ...  1.08551418 -1.79402413\n",
      "   1.02347682]]\n",
      "(830685, 23)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 15.092042684555054, 'pred_time': 0.1365499496459961, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.4442808628082275, 'pred_time': 0.6566812992095947, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 27.48665761947632, 'pred_time': 2.144521713256836, 'acc_train': 0.7939953171178004, 'acc_test': 0.7928817782914102, 'f_train': 0.8282762387591474, 'f_test': 0.8272625939828366}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 189.06153321266174, 'pred_time': 3.577529191970825, 'acc_train': 0.7939847836424156, 'acc_test': 0.7929841034808622, 'f_train': 0.8293157406393062, 'f_test': 0.8283535241386539}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.6345727443695068, 'pred_time': 0.8217062950134277, 'acc_train': 0.792607907931406, 'acc_test': 0.7907871214720381, 'f_train': 0.830055845280306, 'f_test': 0.8286403401089683}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 1.2564465999603271, 'pred_time': 1.0817220211029053, 'acc_train': 0.7657264787494658, 'acc_test': 0.7634602767595419, 'f_train': 0.8300584843669877, 'f_test': 0.8282108841399682}\n",
      "PCA component size: 24\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...   1.2260749   -1.46829553\n",
      "   -0.98953639]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...  -2.07154322   0.47377744\n",
      "   -0.53651759]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...   0.27671059  -0.06298341\n",
      "    0.5940822 ]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...  -1.63607464   0.39247113\n",
      "    1.92737415]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...   1.5493909   -0.47871848\n",
      "   -1.32341894]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...  -2.17047206   1.0612252\n",
      "    1.1039916 ]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ...  1.01330932 -1.40745854\n",
      "  -0.97843125]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ... -1.7120602   0.45414707\n",
      "  -0.53049649]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ...  0.22869192 -0.06037377\n",
      "   0.58741507]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ... -1.35216019  0.37620958\n",
      "   1.90574406]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ...  1.28051902 -0.45888338\n",
      "  -1.30856678]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ... -1.79382154  1.01725466\n",
      "   1.09160198]]\n",
      "(830685, 24)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 15.397124767303467, 'pred_time': 0.15813803672790527, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.403448820114136, 'pred_time': 0.6741049289703369, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 15.293610095977783, 'pred_time': 2.717299699783325, 'acc_train': 0.7940886136140655, 'acc_test': 0.7929299313217405, 'f_train': 0.8285289750202712, 'f_test': 0.8274974117315549}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 197.14585280418396, 'pred_time': 3.5825068950653076, 'acc_train': 0.793998326682196, 'acc_test': 0.7927914913595406, 'f_train': 0.8294501280186255, 'f_test': 0.8283613872835294}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.6300339698791504, 'pred_time': 0.8466510772705078, 'acc_train': 0.7927147474674515, 'acc_test': 0.7908774084039076, 'f_train': 0.830102111382963, 'f_test': 0.8286704258244728}\n",
      "QDA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 1.33268141746521, 'pred_time': 1.1320958137512207, 'acc_train': 0.7652449484461619, 'acc_test': 0.762858363880412, 'f_train': 0.8302614615204182, 'f_test': 0.8283605495376921}\n",
      "PCA component size: 25\n",
      "[[-12.54308653  -3.63812036  -5.86109209 ...  -1.46779648  -0.98695776\n",
      "   -0.88001663]\n",
      " [  2.47984615  -6.58026463   1.61272091 ...   0.46978805  -0.54128986\n",
      "    0.7331098 ]\n",
      " [  1.17313735  -6.94480992   5.15974168 ...  -0.03955599   0.60088208\n",
      "   -1.45457879]\n",
      " ...\n",
      " [ -0.16931633  -5.212655     0.44617197 ...   0.38767147   1.9229523\n",
      "    1.61751711]\n",
      " [  8.43928293  25.29480234  -1.68121494 ...  -0.4701689   -1.32032105\n",
      "   -1.21912299]\n",
      " [ -2.00956073  -5.4385547   -6.4826292  ...   1.0692545    1.10523463\n",
      "   -0.81000094]]\n",
      "[[-0.5907049  -0.30059103 -0.68004352 ... -1.40695283 -0.97587678\n",
      "  -0.90596621]\n",
      " [ 0.11678603 -0.54367869  0.18711878 ...  0.45031422 -0.53521257\n",
      "   0.75472746]\n",
      " [ 0.0552478  -0.57379837  0.5986681  ... -0.0379163   0.59413572\n",
      "  -1.49747083]\n",
      " ...\n",
      " [-0.00797379 -0.4306832   0.05176789 ...  0.37160156  1.90136251\n",
      "   1.66521381]\n",
      " [ 0.39744011  2.08992278 -0.19506592 ... -0.45067928 -1.30549726\n",
      "  -1.25507201]\n",
      " [-0.09463838 -0.44934762 -0.75215845 ...  1.02493136  1.0928257\n",
      "  -0.83388593]]\n",
      "(830685, 25)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 16.10640001296997, 'pred_time': 0.15184593200683594, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 7.368818044662476, 'pred_time': 0.6776840686798096, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 23.143908262252808, 'pred_time': 2.0875258445739746, 'acc_train': 0.794582182174952, 'acc_test': 0.7934054424962531, 'f_train': 0.8287842236467349, 'f_test': 0.8277387192579257}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 205.18433260917664, 'pred_time': 3.5773675441741943, 'acc_train': 0.794187929239122, 'acc_test': 0.793260983405262, 'f_train': 0.8297219221275726, 'f_test': 0.8287314126452815}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 0.660336971282959, 'pred_time': 0.8937160968780518, 'acc_train': 0.7925206305639322, 'acc_test': 0.790624604994673, 'f_train': 0.8300405124302466, 'f_test': 0.8285928038953984}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 1.4214963912963867, 'pred_time': 1.210724115371704, 'acc_train': 0.7664307168180478, 'acc_test': 0.7646159494874711, 'f_train': 0.8323538528320923, 'f_test': 0.8308216901140343}\n",
      "Original data\n",
      "=============\n",
      "(830685, 220)\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 15.725605249404907, 'pred_time': 1.0458731651306152, 'acc_train': 0.8079792580821852, 'acc_test': 0.8068702336023884, 'f_train': 0.8395549435198661, 'f_test': 0.8385287222096311}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 2.241774320602417, 'pred_time': 1.5162582397460938, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 187.6072998046875, 'pred_time': 3.391768217086792, 'acc_train': 0.7947687751674822, 'acc_test': 0.7936221311327398, 'f_train': 0.8287796908540527, 'f_test': 0.8277580724454912}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 240.73623943328857, 'pred_time': 6.790733575820923, 'acc_train': 0.8200521256553327, 'acc_test': 0.8181500809572823, 'f_train': 0.8581891583472446, 'f_test': 0.8566233043365482}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 5.890156030654907, 'pred_time': 7.9084861278533936, 'acc_train': 0.653411040286029, 'acc_test': 0.6517572846506197, 'f_train': 0.8189190190186905, 'f_test': 0.8166402936302094}\n",
      "QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 26.735657930374146, 'pred_time': 14.065266132354736, 'acc_train': 0.5659049459181278, 'acc_test': 0.5635650096005104, 'f_train': 0.7807446113651209, 'f_test': 0.7777622784074396}\n"
     ]
    }
   ],
   "source": [
    "## From http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "names = [\"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "\"\"\"\n",
    "\"Linear SVM\", \"RBF SVM\", \"Gaussian Process\", \"Nearest Neighbors\",\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    KNeighborsClassifier(3),\n",
    " \"\"\"    \n",
    "\n",
    "classifiers = [DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "    \n",
    "print(\"PCA data\")\n",
    "print(\"=============\")\n",
    "for pca_comp in range(1,26):\n",
    "    print(\"PCA component size: \" + str(pca_comp))\n",
    "    pca = decomposition.PCA(n_components=pca_comp)\n",
    "    pca.fit(features)\n",
    "    features_pca = pca.transform(features)\n",
    "    print(features_pca)\n",
    "    features_pca =  StandardScaler().fit_transform(features_pca)\n",
    "    print(features_pca)\n",
    "    print(features_pca.shape)\n",
    "    ###### StandardScalar\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        print(name)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_pca, loan_status, test_size = 0.2, random_state = 0)\n",
    "        result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "        print(result)\n",
    "\n",
    "print(\"Original data\")\n",
    "print(\"=============\")\n",
    "print(features.shape)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "    result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data after scaling\n",
      "=============\n",
      "        loan_amnt  funded_amnt  funded_amnt_inv      term  installment  \\\n",
      "341007  18.270678    18.270678        18.270678  4.792130     8.315257   \n",
      "439960  18.491718    18.491718        18.491718  4.792130     8.315257   \n",
      "158396  21.812732    21.812732        21.812732  4.792130    10.463745   \n",
      "543282  24.628632    24.628632        24.628632  5.684507    11.136082   \n",
      "660761  22.782058    22.782058        22.782058  4.792130    10.830886   \n",
      "692733  23.206076    23.206076        23.206076  4.792130    11.101459   \n",
      "705925  12.125370    12.125370        12.125370  4.792130     4.745132   \n",
      "170841  19.000645    19.000645        19.000645  4.792130     8.970600   \n",
      "83614   24.581490    24.581490        24.581490  5.684507    11.292803   \n",
      "681686  21.538377    21.538377        21.538377  4.792130    10.322492   \n",
      "266461  23.692253    23.692253        23.692253  5.684507    10.634887   \n",
      "475384  18.213642    18.213642        18.213642  4.792130     8.335517   \n",
      "202670  25.357236    25.357236        25.353802  5.684507    12.153411   \n",
      "800690  22.782058    22.782058        22.782058  5.684507    10.018228   \n",
      "755508  22.602295    22.602295        22.602295  5.684507    10.072965   \n",
      "447806  24.628632    24.628632        24.628632  5.684507    11.116894   \n",
      "338675  20.802161    20.802161        20.802161  4.792130    10.040245   \n",
      "808829  17.253669    17.253669        17.253669  4.792130     7.483296   \n",
      "368210  17.070370    17.070370        17.070370  4.792130     7.836797   \n",
      "3592    19.000645    19.000645        19.000645  4.792130     8.763534   \n",
      "390676  17.663696    17.663696        17.663696  4.792130     8.025268   \n",
      "646251  18.702272    18.702272        18.702272  4.792130     8.365619   \n",
      "741684  21.538377    21.538377        21.538377  5.684507     9.405519   \n",
      "265450  25.360669    25.360669        25.360669  4.792130    12.700940   \n",
      "425691  23.123972    23.123972        23.123972  4.792130    11.050764   \n",
      "755320  15.517294    15.517294        15.517294  4.792130     6.694191   \n",
      "101876  17.962596    17.962596        17.962596  4.792130     8.375577   \n",
      "220711  23.154912    23.154912        23.154912  5.684507    10.634887   \n",
      "80006   19.189158    19.189158        19.189158  4.792130     9.041487   \n",
      "98186   22.782058    22.782058        22.782058  4.792130    11.019154   \n",
      "...           ...          ...              ...       ...          ...   \n",
      "423196  20.777526    20.777526        20.777526  4.792130     9.835883   \n",
      "152975  22.998360    22.998360        22.993060  4.792130    11.101459   \n",
      "584468  25.360669    25.360669        25.360669  5.684507    11.843317   \n",
      "540353  25.360669    25.360669        25.357236  5.684507    11.864722   \n",
      "9251    18.753396    18.753396        18.753396  4.792130     8.658271   \n",
      "252892  20.256340    20.256340        20.256340  4.792130     9.459637   \n",
      "266894  17.916752    17.916752        17.916752  4.792130     7.897190   \n",
      "641001  19.512198    19.512198        19.512198  4.792130     9.103010   \n",
      "537048  21.380786    21.380786        21.380786  5.684507     9.258334   \n",
      "338142  20.610004    20.610004        20.610004  4.792130     9.721963   \n",
      "111081  22.320331    22.320331        22.320331  4.792130    10.714795   \n",
      "144113  22.320331    22.320331        22.308239  4.792130    10.661756   \n",
      "142640  25.360669    25.360669        25.360669  4.792130    12.689052   \n",
      "266727  19.370190    19.370190        19.370190  4.792130     8.797736   \n",
      "745998  21.538377    21.538377        21.538377  4.792130    10.477987   \n",
      "291560  23.598505    23.598505        23.598505  5.684507    10.753980   \n",
      "294589  24.933056    24.933056        24.933056  5.684507    11.219143   \n",
      "751790  26.008617    26.008617        26.008617  4.792130    12.876739   \n",
      "304575  19.436276    19.436276        19.436276  4.792130     9.412341   \n",
      "378727  18.753396    18.753396        18.753396  4.792130     8.622254   \n",
      "709210  17.253669    17.253669        17.253669  4.792130     7.483296   \n",
      "823509  23.206076    23.206076        23.206076  5.684507    10.444651   \n",
      "156102  20.939446    20.939446        20.939446  4.792130     9.984891   \n",
      "352007  19.874209    19.874209        19.874209  4.792130     9.251130   \n",
      "220387  23.598505    23.598505        23.598505  5.684507    10.607780   \n",
      "7898    17.916752    17.916752        17.901363  4.792130     8.025268   \n",
      "542413  19.670808    19.670808        19.670808  4.792130     9.148276   \n",
      "551670  17.916752    17.916752        17.916752  4.792130     7.920955   \n",
      "715107  19.874209    19.874209        19.874209  4.792130     9.265520   \n",
      "375400  19.874209    19.874209        19.874209  4.792130     9.265520   \n",
      "\n",
      "        annual_inc   zip_code       dti  delinq_2yrs  inq_last_6mths  \\\n",
      "341007   24.628632  11.892039  3.701973     0.000000        0.000000   \n",
      "439960   30.446771   8.002449  2.750250     0.730463        0.000000   \n",
      "158396   31.617040   6.047664  2.885846     0.000000        1.194318   \n",
      "543282   30.506041   4.380946  4.003419     0.000000        0.000000   \n",
      "660761   28.395339  10.184716  3.618223     0.730463        0.730463   \n",
      "692733   31.813889  11.514262  3.340760     0.000000        0.000000   \n",
      "705925   23.383907  11.984426  3.618223     0.000000        0.730463   \n",
      "170841   29.239480  11.999087  3.701973     0.000000        0.000000   \n",
      "83614    28.557548  11.800080  3.438110     0.000000        0.000000   \n",
      "681686   29.588763  11.916131  3.701973     0.000000        0.000000   \n",
      "266461   28.869811   8.473163  4.380946     1.540963        0.000000   \n",
      "475384   25.686058  11.541318  3.530419     0.000000        0.730463   \n",
      "202670   33.561213   7.685747  3.530419     0.000000        0.000000   \n",
      "800690   30.535477  11.800080  3.858807     0.000000        0.730463   \n",
      "755508   28.869811  10.736626  4.137711     0.000000        0.000000   \n",
      "447806   29.451339  11.993231  3.932510     0.000000        0.000000   \n",
      "338675   25.360669   6.732788  3.237728     0.000000        0.000000   \n",
      "808829   33.928699   6.826617  2.750250     0.000000        0.000000   \n",
      "368210   32.889081  10.210715  2.602594     1.540963        2.055642   \n",
      "3592     26.008617  10.881111  4.071754     0.000000        1.194318   \n",
      "390676   22.513737  10.860283  4.380946     0.000000        1.194318   \n",
      "646251   28.869811   6.899104  3.530419     0.000000        0.000000   \n",
      "741684   28.057555  12.082859  2.602594     0.000000        0.000000   \n",
      "265450   31.362625  12.048452  3.011340     0.000000        0.000000   \n",
      "425691   29.239480   5.942124  3.128239     0.000000        0.000000   \n",
      "755320   29.239480   9.033700  4.263161     0.730463        0.000000   \n",
      "101876   23.306941   6.314735  3.128239     0.000000        0.730463   \n",
      "220711   27.569792   6.654950  4.545286     0.000000        1.194318   \n",
      "80006    29.167258   9.894096  4.201461     0.000000        1.540963   \n",
      "98186    30.173194   5.914940  4.003419     0.000000        0.000000   \n",
      "...            ...        ...       ...          ...             ...   \n",
      "423196   32.327599   9.258334  2.259674     0.730463        0.730463   \n",
      "152975   31.362625   6.654950  4.322948     0.000000        0.000000   \n",
      "584468   30.234988   9.419146  4.545286     0.000000        0.000000   \n",
      "540353   30.234988  11.882959  4.792130     0.000000        0.000000   \n",
      "9251     29.919958   9.905600  3.530419     0.000000        0.730463   \n",
      "252892   29.588763  11.934084  3.011340     1.194318        0.000000   \n",
      "266894   28.476974   9.996045  2.885846     0.000000        0.000000   \n",
      "641001   25.758185  10.818201  3.438110     0.000000        0.000000   \n",
      "537048   27.069896  10.766932  4.545286     0.000000        0.000000   \n",
      "338142   28.057555  11.640795  2.440268     0.000000        1.540963   \n",
      "111081   30.923266  10.766932  3.128239     0.000000        0.000000   \n",
      "144113   26.008617   7.566243  4.647709     0.000000        0.000000   \n",
      "142640   36.723955  11.339779  3.530419     0.000000        1.820334   \n",
      "266727   24.628632  10.723546  4.003419     0.000000        0.730463   \n",
      "745998   28.057555   9.185445  3.340760     0.000000        2.055642   \n",
      "291560   26.914539   6.148461  4.071754     0.000000        0.000000   \n",
      "294589   29.723296   3.701973  3.618223     0.000000        0.730463   \n",
      "751790   32.763482   9.214828  3.618223     0.000000        0.730463   \n",
      "304575   24.628632   6.732788  4.263161     0.000000        0.730463   \n",
      "378727   27.417396  10.147932  3.011340     1.540963        0.000000   \n",
      "709210   28.476974  11.462910  3.128239     0.000000        0.000000   \n",
      "823509   28.945501  11.803188  3.858807     1.540963        1.540963   \n",
      "156102   31.465548  11.870812  3.618223     0.730463        0.730463   \n",
      "352007   25.884766  11.892039  2.885846     0.730463        1.194318   \n",
      "220387   33.370093   8.036603  1.194318     0.000000        0.000000   \n",
      "7898     24.378963  11.966746  2.602594     0.730463        0.000000   \n",
      "542413   28.228763   8.962610  3.858807     0.000000        0.000000   \n",
      "551670   29.919958   5.968981  2.602594     0.000000        0.000000   \n",
      "715107   26.914539  11.803188  4.263161     0.730463        1.194318   \n",
      "375400   27.607297   9.258334  3.858807     0.000000        0.000000   \n",
      "\n",
      "                    ...                addr_state_WA  addr_state_WI  \\\n",
      "341007              ...                     0.000000            0.0   \n",
      "439960              ...                     0.000000            0.0   \n",
      "158396              ...                     0.000000            0.0   \n",
      "543282              ...                     0.000000            0.0   \n",
      "660761              ...                     0.000000            0.0   \n",
      "692733              ...                     0.000000            0.0   \n",
      "705925              ...                     0.000000            0.0   \n",
      "170841              ...                     0.000000            0.0   \n",
      "83614               ...                     0.000000            0.0   \n",
      "681686              ...                     0.000000            0.0   \n",
      "266461              ...                     0.000000            0.0   \n",
      "475384              ...                     0.000000            0.0   \n",
      "202670              ...                     0.000000            0.0   \n",
      "800690              ...                     0.000000            0.0   \n",
      "755508              ...                     0.000000            0.0   \n",
      "447806              ...                     0.000000            0.0   \n",
      "338675              ...                     0.000000            0.0   \n",
      "808829              ...                     0.000000            0.0   \n",
      "368210              ...                     0.000000            0.0   \n",
      "3592                ...                     0.000000            0.0   \n",
      "390676              ...                     0.000000            0.0   \n",
      "646251              ...                     0.000000            0.0   \n",
      "741684              ...                     0.730463            0.0   \n",
      "265450              ...                     0.000000            0.0   \n",
      "425691              ...                     0.000000            0.0   \n",
      "755320              ...                     0.000000            0.0   \n",
      "101876              ...                     0.000000            0.0   \n",
      "220711              ...                     0.000000            0.0   \n",
      "80006               ...                     0.000000            0.0   \n",
      "98186               ...                     0.000000            0.0   \n",
      "...                 ...                          ...            ...   \n",
      "423196              ...                     0.000000            0.0   \n",
      "152975              ...                     0.000000            0.0   \n",
      "584468              ...                     0.000000            0.0   \n",
      "540353              ...                     0.000000            0.0   \n",
      "9251                ...                     0.000000            0.0   \n",
      "252892              ...                     0.000000            0.0   \n",
      "266894              ...                     0.000000            0.0   \n",
      "641001              ...                     0.000000            0.0   \n",
      "537048              ...                     0.000000            0.0   \n",
      "338142              ...                     0.000000            0.0   \n",
      "111081              ...                     0.000000            0.0   \n",
      "144113              ...                     0.000000            0.0   \n",
      "142640              ...                     0.000000            0.0   \n",
      "266727              ...                     0.000000            0.0   \n",
      "745998              ...                     0.000000            0.0   \n",
      "291560              ...                     0.000000            0.0   \n",
      "294589              ...                     0.000000            0.0   \n",
      "751790              ...                     0.000000            0.0   \n",
      "304575              ...                     0.000000            0.0   \n",
      "378727              ...                     0.000000            0.0   \n",
      "709210              ...                     0.000000            0.0   \n",
      "823509              ...                     0.000000            0.0   \n",
      "156102              ...                     0.000000            0.0   \n",
      "352007              ...                     0.000000            0.0   \n",
      "220387              ...                     0.000000            0.0   \n",
      "7898                ...                     0.000000            0.0   \n",
      "542413              ...                     0.000000            0.0   \n",
      "551670              ...                     0.000000            0.0   \n",
      "715107              ...                     0.000000            0.0   \n",
      "375400              ...                     0.000000            0.0   \n",
      "\n",
      "        addr_state_WV  addr_state_WY  initial_list_status_f  \\\n",
      "341007            0.0            0.0               0.730463   \n",
      "439960            0.0            0.0               0.000000   \n",
      "158396            0.0            0.0               0.730463   \n",
      "543282            0.0            0.0               0.000000   \n",
      "660761            0.0            0.0               0.000000   \n",
      "692733            0.0            0.0               0.000000   \n",
      "705925            0.0            0.0               0.000000   \n",
      "170841            0.0            0.0               0.730463   \n",
      "83614             0.0            0.0               0.730463   \n",
      "681686            0.0            0.0               0.000000   \n",
      "266461            0.0            0.0               0.000000   \n",
      "475384            0.0            0.0               0.730463   \n",
      "202670            0.0            0.0               0.730463   \n",
      "800690            0.0            0.0               0.000000   \n",
      "755508            0.0            0.0               0.000000   \n",
      "447806            0.0            0.0               0.000000   \n",
      "338675            0.0            0.0               0.000000   \n",
      "808829            0.0            0.0               0.730463   \n",
      "368210            0.0            0.0               0.000000   \n",
      "3592              0.0            0.0               0.730463   \n",
      "390676            0.0            0.0               0.730463   \n",
      "646251            0.0            0.0               0.730463   \n",
      "741684            0.0            0.0               0.000000   \n",
      "265450            0.0            0.0               0.730463   \n",
      "425691            0.0            0.0               0.730463   \n",
      "755320            0.0            0.0               0.730463   \n",
      "101876            0.0            0.0               0.730463   \n",
      "220711            0.0            0.0               0.000000   \n",
      "80006             0.0            0.0               0.730463   \n",
      "98186             0.0            0.0               0.730463   \n",
      "...               ...            ...                    ...   \n",
      "423196            0.0            0.0               0.730463   \n",
      "152975            0.0            0.0               0.730463   \n",
      "584468            0.0            0.0               0.000000   \n",
      "540353            0.0            0.0               0.730463   \n",
      "9251              0.0            0.0               0.730463   \n",
      "252892            0.0            0.0               0.000000   \n",
      "266894            0.0            0.0               0.730463   \n",
      "641001            0.0            0.0               0.000000   \n",
      "537048            0.0            0.0               0.000000   \n",
      "338142            0.0            0.0               0.730463   \n",
      "111081            0.0            0.0               0.000000   \n",
      "144113            0.0            0.0               0.730463   \n",
      "142640            0.0            0.0               0.000000   \n",
      "266727            0.0            0.0               0.000000   \n",
      "745998            0.0            0.0               0.000000   \n",
      "291560            0.0            0.0               0.000000   \n",
      "294589            0.0            0.0               0.730463   \n",
      "751790            0.0            0.0               0.730463   \n",
      "304575            0.0            0.0               0.730463   \n",
      "378727            0.0            0.0               0.000000   \n",
      "709210            0.0            0.0               0.730463   \n",
      "823509            0.0            0.0               0.000000   \n",
      "156102            0.0            0.0               0.730463   \n",
      "352007            0.0            0.0               0.000000   \n",
      "220387            0.0            0.0               0.000000   \n",
      "7898              0.0            0.0               0.730463   \n",
      "542413            0.0            0.0               0.730463   \n",
      "551670            0.0            0.0               0.000000   \n",
      "715107            0.0            0.0               0.000000   \n",
      "375400            0.0            0.0               0.000000   \n",
      "\n",
      "        initial_list_status_w  application_type_Individual  \\\n",
      "341007               0.000000                     0.730463   \n",
      "439960               0.730463                     0.730463   \n",
      "158396               0.000000                     0.730463   \n",
      "543282               0.730463                     0.730463   \n",
      "660761               0.730463                     0.730463   \n",
      "692733               0.730463                     0.730463   \n",
      "705925               0.730463                     0.730463   \n",
      "170841               0.000000                     0.730463   \n",
      "83614                0.000000                     0.730463   \n",
      "681686               0.730463                     0.730463   \n",
      "266461               0.730463                     0.730463   \n",
      "475384               0.000000                     0.730463   \n",
      "202670               0.000000                     0.730463   \n",
      "800690               0.730463                     0.730463   \n",
      "755508               0.730463                     0.730463   \n",
      "447806               0.730463                     0.730463   \n",
      "338675               0.730463                     0.730463   \n",
      "808829               0.000000                     0.730463   \n",
      "368210               0.730463                     0.730463   \n",
      "3592                 0.000000                     0.730463   \n",
      "390676               0.000000                     0.730463   \n",
      "646251               0.000000                     0.730463   \n",
      "741684               0.730463                     0.730463   \n",
      "265450               0.000000                     0.730463   \n",
      "425691               0.000000                     0.730463   \n",
      "755320               0.000000                     0.730463   \n",
      "101876               0.000000                     0.730463   \n",
      "220711               0.730463                     0.730463   \n",
      "80006                0.000000                     0.730463   \n",
      "98186                0.000000                     0.730463   \n",
      "...                       ...                          ...   \n",
      "423196               0.000000                     0.730463   \n",
      "152975               0.000000                     0.730463   \n",
      "584468               0.730463                     0.730463   \n",
      "540353               0.000000                     0.730463   \n",
      "9251                 0.000000                     0.730463   \n",
      "252892               0.730463                     0.730463   \n",
      "266894               0.000000                     0.730463   \n",
      "641001               0.730463                     0.730463   \n",
      "537048               0.730463                     0.730463   \n",
      "338142               0.000000                     0.730463   \n",
      "111081               0.730463                     0.730463   \n",
      "144113               0.000000                     0.730463   \n",
      "142640               0.730463                     0.730463   \n",
      "266727               0.730463                     0.730463   \n",
      "745998               0.730463                     0.730463   \n",
      "291560               0.730463                     0.730463   \n",
      "294589               0.000000                     0.730463   \n",
      "751790               0.000000                     0.730463   \n",
      "304575               0.000000                     0.730463   \n",
      "378727               0.730463                     0.730463   \n",
      "709210               0.000000                     0.730463   \n",
      "823509               0.730463                     0.730463   \n",
      "156102               0.000000                     0.730463   \n",
      "352007               0.730463                     0.730463   \n",
      "220387               0.730463                     0.730463   \n",
      "7898                 0.000000                     0.730463   \n",
      "542413               0.000000                     0.730463   \n",
      "551670               0.730463                     0.730463   \n",
      "715107               0.730463                     0.730463   \n",
      "375400               0.730463                     0.730463   \n",
      "\n",
      "        application_type_Joint App  disbursement_method_Cash  \\\n",
      "341007                         0.0                  0.730463   \n",
      "439960                         0.0                  0.730463   \n",
      "158396                         0.0                  0.730463   \n",
      "543282                         0.0                  0.730463   \n",
      "660761                         0.0                  0.730463   \n",
      "692733                         0.0                  0.730463   \n",
      "705925                         0.0                  0.730463   \n",
      "170841                         0.0                  0.730463   \n",
      "83614                          0.0                  0.730463   \n",
      "681686                         0.0                  0.730463   \n",
      "266461                         0.0                  0.730463   \n",
      "475384                         0.0                  0.730463   \n",
      "202670                         0.0                  0.730463   \n",
      "800690                         0.0                  0.730463   \n",
      "755508                         0.0                  0.730463   \n",
      "447806                         0.0                  0.730463   \n",
      "338675                         0.0                  0.730463   \n",
      "808829                         0.0                  0.730463   \n",
      "368210                         0.0                  0.730463   \n",
      "3592                           0.0                  0.730463   \n",
      "390676                         0.0                  0.730463   \n",
      "646251                         0.0                  0.730463   \n",
      "741684                         0.0                  0.730463   \n",
      "265450                         0.0                  0.730463   \n",
      "425691                         0.0                  0.730463   \n",
      "755320                         0.0                  0.730463   \n",
      "101876                         0.0                  0.730463   \n",
      "220711                         0.0                  0.730463   \n",
      "80006                          0.0                  0.730463   \n",
      "98186                          0.0                  0.730463   \n",
      "...                            ...                       ...   \n",
      "423196                         0.0                  0.730463   \n",
      "152975                         0.0                  0.730463   \n",
      "584468                         0.0                  0.730463   \n",
      "540353                         0.0                  0.730463   \n",
      "9251                           0.0                  0.730463   \n",
      "252892                         0.0                  0.730463   \n",
      "266894                         0.0                  0.730463   \n",
      "641001                         0.0                  0.730463   \n",
      "537048                         0.0                  0.730463   \n",
      "338142                         0.0                  0.730463   \n",
      "111081                         0.0                  0.730463   \n",
      "144113                         0.0                  0.730463   \n",
      "142640                         0.0                  0.730463   \n",
      "266727                         0.0                  0.730463   \n",
      "745998                         0.0                  0.730463   \n",
      "291560                         0.0                  0.730463   \n",
      "294589                         0.0                  0.730463   \n",
      "751790                         0.0                  0.730463   \n",
      "304575                         0.0                  0.730463   \n",
      "378727                         0.0                  0.730463   \n",
      "709210                         0.0                  0.730463   \n",
      "823509                         0.0                  0.730463   \n",
      "156102                         0.0                  0.730463   \n",
      "352007                         0.0                  0.730463   \n",
      "220387                         0.0                  0.730463   \n",
      "7898                           0.0                  0.730463   \n",
      "542413                         0.0                  0.730463   \n",
      "551670                         0.0                  0.730463   \n",
      "715107                         0.0                  0.730463   \n",
      "375400                         0.0                  0.730463   \n",
      "\n",
      "        disbursement_method_DirectPay  \n",
      "341007                            0.0  \n",
      "439960                            0.0  \n",
      "158396                            0.0  \n",
      "543282                            0.0  \n",
      "660761                            0.0  \n",
      "692733                            0.0  \n",
      "705925                            0.0  \n",
      "170841                            0.0  \n",
      "83614                             0.0  \n",
      "681686                            0.0  \n",
      "266461                            0.0  \n",
      "475384                            0.0  \n",
      "202670                            0.0  \n",
      "800690                            0.0  \n",
      "755508                            0.0  \n",
      "447806                            0.0  \n",
      "338675                            0.0  \n",
      "808829                            0.0  \n",
      "368210                            0.0  \n",
      "3592                              0.0  \n",
      "390676                            0.0  \n",
      "646251                            0.0  \n",
      "741684                            0.0  \n",
      "265450                            0.0  \n",
      "425691                            0.0  \n",
      "755320                            0.0  \n",
      "101876                            0.0  \n",
      "220711                            0.0  \n",
      "80006                             0.0  \n",
      "98186                             0.0  \n",
      "...                               ...  \n",
      "423196                            0.0  \n",
      "152975                            0.0  \n",
      "584468                            0.0  \n",
      "540353                            0.0  \n",
      "9251                              0.0  \n",
      "252892                            0.0  \n",
      "266894                            0.0  \n",
      "641001                            0.0  \n",
      "537048                            0.0  \n",
      "338142                            0.0  \n",
      "111081                            0.0  \n",
      "144113                            0.0  \n",
      "142640                            0.0  \n",
      "266727                            0.0  \n",
      "745998                            0.0  \n",
      "291560                            0.0  \n",
      "294589                            0.0  \n",
      "751790                            0.0  \n",
      "304575                            0.0  \n",
      "378727                            0.0  \n",
      "709210                            0.0  \n",
      "823509                            0.0  \n",
      "156102                            0.0  \n",
      "352007                            0.0  \n",
      "220387                            0.0  \n",
      "7898                              0.0  \n",
      "542413                            0.0  \n",
      "551670                            0.0  \n",
      "715107                            0.0  \n",
      "375400                            0.0  \n",
      "\n",
      "[830685 rows x 220 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After scaling\n",
      "[[-0.87480105 -0.87374528 -0.85834969 ... -0.07154192  0.03721709\n",
      "  -0.03721709]\n",
      " [-0.79345094 -0.79236693 -0.77779129 ... -0.07154192  0.03721709\n",
      "  -0.03721709]\n",
      " [ 0.4287911   0.43029935  0.43255576 ... -0.07154192  0.03721709\n",
      "  -0.03721709]\n",
      " ...\n",
      " [-1.00505713 -1.00404658 -0.98733811 ... -0.07154192  0.03721709\n",
      "  -0.03721709]\n",
      " [-0.28464869 -0.28338808 -0.27394076 ... -0.07154192  0.03721709\n",
      "  -0.03721709]\n",
      " [-0.28464869 -0.28338808 -0.27394076 ... -0.07154192  0.03721709\n",
      "  -0.03721709]]\n",
      "Decision Tree\n",
      "DecisionTreeClassifier trained on 664548 samples.\n",
      "{'train_time': 32.55089545249939, 'pred_time': 1.11134934425354, 'acc_train': 0.8079792580821852, 'acc_test': 0.8068702336023884, 'f_train': 0.8395549435198661, 'f_test': 0.8385287222096311}\n",
      "Random Forest\n",
      "RandomForestClassifier trained on 664548 samples.\n",
      "{'train_time': 3.1556789875030518, 'pred_time': 1.9517436027526855, 'acc_train': 0.7940780801386808, 'acc_test': 0.7928456635186623, 'f_train': 0.8281864279896232, 'f_test': 0.8271137015254895}\n",
      "Neural Net\n",
      "MLPClassifier trained on 664548 samples.\n",
      "{'train_time': 138.44742894172668, 'pred_time': 10.593616008758545, 'acc_train': 0.8181982339876126, 'acc_test': 0.8163744379638491, 'f_train': 0.8529034683673478, 'f_test': 0.8514407446268043}\n",
      "AdaBoost\n",
      "AdaBoostClassifier trained on 664548 samples.\n",
      "{'train_time': 415.4464852809906, 'pred_time': 8.206900596618652, 'acc_train': 0.8200521256553327, 'acc_test': 0.8181500809572823, 'f_train': 0.8581891583472446, 'f_test': 0.8566233043365482}\n",
      "Naive Bayes\n",
      "GaussianNB trained on 664548 samples.\n",
      "{'train_time': 5.932447671890259, 'pred_time': 8.571050882339478, 'acc_train': 0.6533914781174572, 'acc_test': 0.6517392272642458, 'f_train': 0.8189143280176999, 'f_test': 0.8166334260325664}\n",
      "QDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticDiscriminantAnalysis trained on 664548 samples.\n",
      "{'train_time': 18.29764223098755, 'pred_time': 13.204537630081177, 'acc_train': 0.6733253278920409, 'acc_test': 0.6725052215942264, 'f_train': 0.8119541867358825, 'f_test': 0.8105868125655467}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data after scaling\")\n",
    "print(\"=============\")\n",
    "print(features)\n",
    "features =  StandardScaler().fit_transform(features)\n",
    "print(\"After scaling\")\n",
    "print(features)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "    result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More fine tuning\n",
      "Unoptimized model\n",
      "------\n",
      "Accuracy score on testing data: 0.8324\n",
      "F-score on testing data: 0.8758\n",
      "\n",
      "Optimized Model\n",
      "------\n",
      "Final accuracy score on the testing data: 0.8434\n",
      "Final F-score on the testing data: 0.8805\n"
     ]
    }
   ],
   "source": [
    "print(\"More fine tuning\")\n",
    "    \n",
    "# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = MLPClassifier()\n",
    "\n",
    "## Note the features is already scaled\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune\n",
    "parameters = {\n",
    "    'hidden_layer_sizes' : [(100,), (50, 50), (100,50,3), (10, 50, 100), (10, 50, 100, 50, 10)],\n",
    "    'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    # 'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "    # 'alpha' : [0.0001, 0.001, 0.01, 0.1, 0.00001, 1],\n",
    "    # 'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "    # 'learning_rate_init' : [0.001, 0.01, 0.1, 0.0001],\n",
    "    # 'max_iter' : [200, 100, 50, 400],\n",
    "    # 'warm_start' : [False, True],\n",
    "    # 'momentum' : [0.9, 0.5, 0.8, 0.1],\n",
    "    ### ------\n",
    "    # nesterovs_momentum : boolean, default True\n",
    "    # early_stopping : bool, default False\n",
    "    # validation_fraction : float, optional, default 0.1\n",
    "    # beta_1 : float, optional, default 0.9\n",
    "    # beta_2 : float, optional, default 0.999\n",
    "    # epsilon : float, optional, default 1e-8\n",
    "    # n_iter_no_change : int, optional, default 10\n",
    "    # 'power_t' : double, optional, default 0.5\n",
    "    # 'batch_size' : int, optional, default ‘auto’\n",
    "    # 'shuffle' : bool, optional, default True\n",
    "    # random_state : int, RandomState instance or None, optional, default None\n",
    "    # tol : float, optional, default 1e-4\n",
    "    # verbose : bool, optional, default False\n",
    "}\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
