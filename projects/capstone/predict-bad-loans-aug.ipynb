{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',1000)\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_prncp\n",
      "out_prncp_inv\n",
      "total_pymnt\n",
      "total_pymnt_inv\n",
      "total_rec_prncp\n",
      "total_rec_int\n",
      "total_rec_late_fee\n",
      "recoveries\n",
      "collection_recovery_fee\n",
      "last_pymnt_amnt\n",
      "last_pymnt_d_month\n",
      "last_pymnt_d_year\n"
     ]
    }
   ],
   "source": [
    "# Load the loan data\n",
    "df = pd.read_pickle('data_cleaned.pkl')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# The following are not available during the loan process. So, dropping them.\n",
    "to_drop_list = ('out_prncp', 'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', 'last_pymnt_amnt', 'last_pymnt_d_month', 'last_pymnt_d_year') \n",
    "for f in to_drop_list:\n",
    "    print(f)\n",
    "    df = df.drop(f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the loan_status to numerical values\n",
    "# Fully Paid = 1\n",
    "# Charged Off = 0\n",
    "df['loan_status'] = df['loan_status'].apply(lambda x: int(x == 'Fully Paid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['grade', 'sub_grade', 'emp_length', 'home_ownership',\n",
      "       'verification_status', 'purpose', 'addr_state', 'initial_list_status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Categorical df from data-cleanup.ipynb\n",
    "# Categorical df \n",
    "cat_features = df.select_dtypes(include=['object']).columns\n",
    "print(cat_features)\n",
    "\n",
    "# cat_features = ['grade', 'sub_grade', 'emp_length', 'home_ownership', 'verification_status', \n",
    "                # 'purpose', 'addr_state', 'initial_list_status', 'application_type', 'disbursement_method']\n",
    "\n",
    "for y in cat_features:\n",
    "    # print(y + \" has \" + str(len(df[y].unique())) + \" unique values\")\n",
    "    df = df.join(pd.get_dummies(df[y], prefix=y))\n",
    "    df.drop(y, axis=1, inplace=True)\n",
    "\n",
    "# Remove int_rate also\n",
    "df.drop('int_rate', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_TX</th>\n",
       "      <th>addr_state_UT</th>\n",
       "      <th>addr_state_VA</th>\n",
       "      <th>addr_state_VT</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>7.697900e+05</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "      <td>769790.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14291.547760</td>\n",
       "      <td>14278.200711</td>\n",
       "      <td>14246.739587</td>\n",
       "      <td>41.738750</td>\n",
       "      <td>435.899255</td>\n",
       "      <td>7.548923e+04</td>\n",
       "      <td>0.807545</td>\n",
       "      <td>519.343105</td>\n",
       "      <td>17.787344</td>\n",
       "      <td>0.306419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080280</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.022378</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.506499</td>\n",
       "      <td>0.493501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8486.335554</td>\n",
       "      <td>8479.674172</td>\n",
       "      <td>8484.451273</td>\n",
       "      <td>10.237035</td>\n",
       "      <td>255.080380</td>\n",
       "      <td>6.541486e+04</td>\n",
       "      <td>0.394229</td>\n",
       "      <td>314.145951</td>\n",
       "      <td>8.257461</td>\n",
       "      <td>0.855870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271727</td>\n",
       "      <td>0.088802</td>\n",
       "      <td>0.167767</td>\n",
       "      <td>0.043761</td>\n",
       "      <td>0.147908</td>\n",
       "      <td>0.112634</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.047571</td>\n",
       "      <td>0.499958</td>\n",
       "      <td>0.499958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>14.010000</td>\n",
       "      <td>3.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>7975.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>251.110000</td>\n",
       "      <td>4.567625e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>11.610000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>12000.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>376.440000</td>\n",
       "      <td>6.500000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>574.880000</td>\n",
       "      <td>9.000000e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>826.000000</td>\n",
       "      <td>23.560000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1714.540000</td>\n",
       "      <td>9.550000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>49.950000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           loan_amnt    funded_amnt  funded_amnt_inv           term  \\\n",
       "count  769790.000000  769790.000000    769790.000000  769790.000000   \n",
       "mean    14291.547760   14278.200711     14246.739587      41.738750   \n",
       "std      8486.335554    8479.674172      8484.451273      10.237035   \n",
       "min       500.000000     500.000000         0.000000      36.000000   \n",
       "25%      8000.000000    8000.000000      7975.000000      36.000000   \n",
       "50%     12000.000000   12000.000000     12000.000000      36.000000   \n",
       "75%     20000.000000   20000.000000     20000.000000      36.000000   \n",
       "max     40000.000000   40000.000000     40000.000000      60.000000   \n",
       "\n",
       "         installment    annual_inc    loan_status       zip_code  \\\n",
       "count  769790.000000  7.697900e+05  769790.000000  769790.000000   \n",
       "mean      435.899255  7.548923e+04       0.807545     519.343105   \n",
       "std       255.080380  6.541486e+04       0.394229     314.145951   \n",
       "min        14.010000  3.000000e+03       0.000000       7.000000   \n",
       "25%       251.110000  4.567625e+04       1.000000     234.000000   \n",
       "50%       376.440000  6.500000e+04       1.000000     481.000000   \n",
       "75%       574.880000  9.000000e+04       1.000000     826.000000   \n",
       "max      1714.540000  9.550000e+06       1.000000     999.000000   \n",
       "\n",
       "                 dti    delinq_2yrs          ...            addr_state_TX  \\\n",
       "count  769790.000000  769790.000000          ...            769790.000000   \n",
       "mean       17.787344       0.306419          ...                 0.080280   \n",
       "std         8.257461       0.855870          ...                 0.271727   \n",
       "min        -1.000000       0.000000          ...                 0.000000   \n",
       "25%        11.610000       0.000000          ...                 0.000000   \n",
       "50%        17.300000       0.000000          ...                 0.000000   \n",
       "75%        23.560000       0.000000          ...                 0.000000   \n",
       "max        49.950000      39.000000          ...                 1.000000   \n",
       "\n",
       "       addr_state_UT  addr_state_VA  addr_state_VT  addr_state_WA  \\\n",
       "count  769790.000000  769790.000000  769790.000000  769790.000000   \n",
       "mean        0.007949       0.028986       0.001919       0.022378   \n",
       "std         0.088802       0.167767       0.043761       0.147908   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       addr_state_WI  addr_state_WV  addr_state_WY  initial_list_status_f  \\\n",
       "count  769790.000000  769790.000000  769790.000000          769790.000000   \n",
       "mean        0.012852       0.004078       0.002268               0.506499   \n",
       "std         0.112634       0.063727       0.047571               0.499958   \n",
       "min         0.000000       0.000000       0.000000               0.000000   \n",
       "25%         0.000000       0.000000       0.000000               0.000000   \n",
       "50%         0.000000       0.000000       0.000000               1.000000   \n",
       "75%         0.000000       0.000000       0.000000               1.000000   \n",
       "max         1.000000       1.000000       1.000000               1.000000   \n",
       "\n",
       "       initial_list_status_w  \n",
       "count          769790.000000  \n",
       "mean                0.493501  \n",
       "std                 0.499958  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 1.000000  \n",
       "max                 1.000000  \n",
       "\n",
       "[8 rows x 208 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming some column names\n",
    "df.rename(columns = {'emp_length_<1':'emp_length_less_than_1'}, inplace = True)\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Analysis\n",
    "# most correlated features\n",
    "corrmat = df.corr()\n",
    "# top_corr_features = corrmat.index[abs(corrmat[\"int_rate\"])>0.5]\n",
    "# plt.figure(figsize=(100,100))\n",
    "# g = sns.heatmap(df[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")\n",
    "# sns.heatmap(df.corr(),annot=True,cmap=\"RdYlGn\")\n",
    "\n",
    "def correlation_matrix(df):\n",
    "    from matplotlib import pyplot as plt\n",
    "    from matplotlib import cm as cm\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    cmap = cm.get_cmap('jet', 30)\n",
    "    cax = ax1.imshow(df.corr(), interpolation=\"nearest\")\n",
    "    ax1.grid(True)\n",
    "    plt.title('Feature Correlation')\n",
    "    # labels=['Sex','Length','Diam','Height','Whole','Shucked','Viscera','Shell','Rings',]\n",
    "    # ax1.set_xticklabels(labels,fontsize=6)\n",
    "    # ax1.set_yticklabels(labels,fontsize=6)\n",
    "    # Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "    fig.colorbar(cax) # , ticks=[.75,.8,.85,.90,.95,1])\n",
    "    plt.figure(figsize=(100,100))\n",
    "    plt.show()\n",
    "\n",
    "# correlation_matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_amnt                     -0.062782\n",
       "funded_amnt                   -0.062842\n",
       "funded_amnt_inv               -0.062542\n",
       "term                          -0.177213\n",
       "installment                   -0.044686\n",
       "annual_inc                     0.046263\n",
       "loan_status                    1.000000\n",
       "zip_code                       0.014210\n",
       "dti                           -0.125913\n",
       "delinq_2yrs                   -0.020983\n",
       "inq_last_6mths                -0.058257\n",
       "mths_since_last_delinq        -0.005249\n",
       "mths_since_last_record        -0.025147\n",
       "open_acc                      -0.032096\n",
       "pub_rec                       -0.024851\n",
       "revol_bal                      0.014671\n",
       "revol_util                    -0.072315\n",
       "total_acc                      0.014078\n",
       "collections_12_mths_ex_med    -0.018630\n",
       "mths_since_last_major_derog    0.023427\n",
       "acc_now_delinq                -0.007336\n",
       "tot_coll_amt                  -0.000049\n",
       "tot_cur_bal                    0.062382\n",
       "open_acc_6m                   -0.035170\n",
       "open_act_il                   -0.022449\n",
       "open_il_12m                   -0.033490\n",
       "open_il_24m                   -0.029900\n",
       "mths_since_rcnt_il            -0.000934\n",
       "total_bal_il                  -0.014823\n",
       "il_util                       -0.029775\n",
       "                                 ...   \n",
       "addr_state_MN                 -0.001030\n",
       "addr_state_MO                 -0.003883\n",
       "addr_state_MS                 -0.010460\n",
       "addr_state_MT                  0.003334\n",
       "addr_state_NC                 -0.002657\n",
       "addr_state_ND                 -0.001589\n",
       "addr_state_NE                 -0.006863\n",
       "addr_state_NH                  0.009145\n",
       "addr_state_NJ                 -0.005705\n",
       "addr_state_NM                 -0.001464\n",
       "addr_state_NV                 -0.009655\n",
       "addr_state_NY                 -0.009465\n",
       "addr_state_OH                 -0.009353\n",
       "addr_state_OK                 -0.009442\n",
       "addr_state_OR                  0.012266\n",
       "addr_state_PA                 -0.002804\n",
       "addr_state_RI                  0.002329\n",
       "addr_state_SC                  0.006433\n",
       "addr_state_SD                 -0.001917\n",
       "addr_state_TN                 -0.007935\n",
       "addr_state_TX                  0.003644\n",
       "addr_state_UT                  0.004847\n",
       "addr_state_VA                  0.000103\n",
       "addr_state_VT                  0.005290\n",
       "addr_state_WA                  0.014353\n",
       "addr_state_WI                  0.007166\n",
       "addr_state_WV                  0.001971\n",
       "addr_state_WY                  0.002565\n",
       "initial_list_status_f          0.016898\n",
       "initial_list_status_w         -0.016898\n",
       "Name: loan_status, Length: 208, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_corr_features = corrmat.loc[abs(corrmat['loan_status']) > 0.1]\n",
    "# plt.figure(figsize=(10,10))\n",
    "# sns.heatmap(df[top_corr_features].corr(), annot=True, cmap='RdYlGn')\n",
    "# sns.heatmap(top_corr_features.corr(), annot=True, cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Absolute Correlations\n",
      "<class 'pandas.core.series.Series'>\n",
      "initial_list_status_f     initial_list_status_w             1.000000\n",
      "loan_amnt                 funded_amnt                       0.999267\n",
      "funded_amnt               funded_amnt_inv                   0.998571\n",
      "loan_amnt                 funded_amnt_inv                   0.997695\n",
      "num_actv_rev_tl           num_rev_tl_bal_gt_0               0.986893\n",
      "tot_cur_bal               tot_hi_cred_lim                   0.980978\n",
      "funded_amnt               installment                       0.954760\n",
      "loan_amnt                 installment                       0.953663\n",
      "funded_amnt_inv           installment                       0.953258\n",
      "il_util                   all_util                          0.901608\n",
      "open_acc                  num_sats                          0.897047\n",
      "num_bc_tl                 num_rev_accts                     0.871491\n",
      "open_rv_12m               open_rv_24m                       0.870701\n",
      "total_bal_ex_mort         total_il_high_credit_limit        0.863166\n",
      "open_il_12m               open_il_24m                       0.853152\n",
      "bc_util                   percent_bc_gt_75                  0.849716\n",
      "tot_cur_bal               avg_cur_bal                       0.848027\n",
      "bc_open_to_buy            total_bc_limit                    0.842238\n",
      "num_op_rev_tl             num_sats                          0.840110\n",
      "num_actv_bc_tl            num_actv_rev_tl                   0.837203\n",
      "num_op_rev_tl             num_rev_tl_bal_gt_0               0.835850\n",
      "num_actv_bc_tl            num_bc_sats                       0.833152\n",
      "                          num_rev_tl_bal_gt_0               0.833088\n",
      "num_actv_rev_tl           num_op_rev_tl                     0.832058\n",
      "avg_cur_bal               tot_hi_cred_lim                   0.816413\n",
      "home_ownership_MORTGAGE   home_ownership_RENT               0.814072\n",
      "num_op_rev_tl             num_rev_accts                     0.812576\n",
      "acc_now_delinq            num_tl_30dpd                      0.800092\n",
      "mths_since_recent_bc_dlq  mths_since_recent_revol_delinq    0.792494\n",
      "mths_since_last_record    pub_rec_bankruptcies              0.788496\n",
      "revol_bal                 total_rev_hi_lim                  0.778610\n",
      "open_acc_6m               open_rv_12m                       0.768898\n",
      "num_bc_sats               num_op_rev_tl                     0.757514\n",
      "acc_open_past_24mths      num_tl_op_past_12m                0.757231\n",
      "open_acc                  num_op_rev_tl                     0.750559\n",
      "mo_sin_old_rev_tl_op      earliest_cr_line_year             0.743876\n",
      "open_il_24m               il_util                           0.737839\n",
      "open_act_il               total_bal_il                      0.731727\n",
      "num_bc_sats               num_bc_tl                         0.727796\n",
      "open_act_il               il_util                           0.718328\n",
      "revol_util                bc_util                           0.715555\n",
      "num_actv_bc_tl            num_op_rev_tl                     0.713643\n",
      "num_rev_tl_bal_gt_0       num_sats                          0.705514\n",
      "inq_fi                    inq_last_12m                      0.704738\n",
      "open_acc_6m               open_rv_24m                       0.703705\n",
      "open_act_il               all_util                          0.702865\n",
      "num_actv_rev_tl           num_sats                          0.700689\n",
      "total_rev_hi_lim          total_bc_limit                    0.696974\n",
      "open_il_24m               all_util                          0.693225\n",
      "num_actv_rev_tl           num_bc_sats                       0.691799\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(type(get_top_abs_correlations(df, 3)))\n",
    "print(get_top_abs_correlations(df, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/vjgupta/reach-top-10-with-simple-model-on-housing-prices\n",
    "    \n",
    "# c = df.corr().abs()\n",
    "# s = c.unstack()\n",
    "# so = s.sort_values(ascending=False).drop_duplicates()\n",
    "\n",
    "# with pd.option_context('display.max_rows', 1000, 'display.max_columns', 3):\n",
    "  # print(so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = 0.81 and sigma = 0.39\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target Variable \n",
    "def check_skewness(col):\n",
    "    sns.distplot(df[col], fit=norm)\n",
    "    fig = plt.figure()\n",
    "    res = stats.probplot(df[col], plot=plt)\n",
    "    (mu, sigma) = norm.fit(df[col])\n",
    "    print('mu = {:.2f} and sigma = {:.2f}'.format(mu, sigma))\n",
    "\n",
    "check_skewness('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <td>838.109658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_IA</th>\n",
       "      <td>392.370998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_amnt</th>\n",
       "      <td>74.964306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_rev_hi_lim</th>\n",
       "      <td>59.534298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose_educational</th>\n",
       "      <td>51.851459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <td>49.292749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>44.084050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax_liens</th>\n",
       "      <td>41.219025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_ID</th>\n",
       "      <td>39.679203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_ND</th>\n",
       "      <td>36.838210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose_renewable_energy</th>\n",
       "      <td>36.548132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_G5</th>\n",
       "      <td>35.776866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_ME</th>\n",
       "      <td>34.556995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_G4</th>\n",
       "      <td>32.316161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_G3</th>\n",
       "      <td>28.234708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NE</th>\n",
       "      <td>24.385748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_G2</th>\n",
       "      <td>23.477783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_VT</th>\n",
       "      <td>22.763716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_tl_30dpd</th>\n",
       "      <td>22.231336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_SD</th>\n",
       "      <td>22.054003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_WY</th>\n",
       "      <td>20.925822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_G1</th>\n",
       "      <td>20.470378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_bal_bc</th>\n",
       "      <td>19.814080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_AK</th>\n",
       "      <td>19.716825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose_wedding</th>\n",
       "      <td>19.131899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_DE</th>\n",
       "      <td>18.833797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_DC</th>\n",
       "      <td>18.715757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_MT</th>\n",
       "      <td>18.540635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <td>18.479928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub_grade_F5</th>\n",
       "      <td>17.370951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc</th>\n",
       "      <td>0.914726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status_Not Verified</th>\n",
       "      <td>0.822375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_sats</th>\n",
       "      <td>0.769068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.768188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>0.767621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>0.765954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_length_10+</th>\n",
       "      <td>0.745210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <td>0.733378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_rev_tl_op</th>\n",
       "      <td>0.711842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verification_status_Source Verified</th>\n",
       "      <td>0.573032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership_RENT</th>\n",
       "      <td>0.412676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_credit_pull_d_month</th>\n",
       "      <td>0.260780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>0.245930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <td>0.227785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <td>0.025999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <td>0.022731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_ownership_MORTGAGE</th>\n",
       "      <td>0.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue_d_month</th>\n",
       "      <td>-0.018204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <td>-0.025999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mo_sin_old_il_acct</th>\n",
       "      <td>-0.052109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>-0.064032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_month</th>\n",
       "      <td>-0.128330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purpose_debt_consolidation</th>\n",
       "      <td>-0.367730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc_util</th>\n",
       "      <td>-0.412165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <td>-0.666040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue_d_year</th>\n",
       "      <td>-0.755609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earliest_cr_line_year</th>\n",
       "      <td>-0.956356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>-1.560237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_credit_pull_d_year</th>\n",
       "      <td>-1.808024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <td>-2.644205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Skew\n",
       "tot_coll_amt                         838.109658\n",
       "addr_state_IA                        392.370998\n",
       "delinq_amnt                           74.964306\n",
       "total_rev_hi_lim                      59.534298\n",
       "purpose_educational                   51.851459\n",
       "num_tl_120dpd_2m                      49.292749\n",
       "annual_inc                            44.084050\n",
       "tax_liens                             41.219025\n",
       "addr_state_ID                         39.679203\n",
       "addr_state_ND                         36.838210\n",
       "purpose_renewable_energy              36.548132\n",
       "sub_grade_G5                          35.776866\n",
       "addr_state_ME                         34.556995\n",
       "sub_grade_G4                          32.316161\n",
       "sub_grade_G3                          28.234708\n",
       "addr_state_NE                         24.385748\n",
       "sub_grade_G2                          23.477783\n",
       "addr_state_VT                         22.763716\n",
       "num_tl_30dpd                          22.231336\n",
       "addr_state_SD                         22.054003\n",
       "addr_state_WY                         20.925822\n",
       "sub_grade_G1                          20.470378\n",
       "max_bal_bc                            19.814080\n",
       "addr_state_AK                         19.716825\n",
       "purpose_wedding                       19.131899\n",
       "addr_state_DE                         18.833797\n",
       "addr_state_DC                         18.715757\n",
       "addr_state_MT                         18.540635\n",
       "acc_now_delinq                        18.479928\n",
       "sub_grade_F5                          17.370951\n",
       "...                                         ...\n",
       "total_acc                              0.914726\n",
       "verification_status_Not Verified       0.822375\n",
       "num_sats                               0.769068\n",
       "funded_amnt                            0.768188\n",
       "funded_amnt_inv                        0.767621\n",
       "loan_amnt                              0.765954\n",
       "emp_length_10+                         0.745210\n",
       "verification_status_Verified           0.733378\n",
       "mo_sin_old_rev_tl_op                   0.711842\n",
       "verification_status_Source Verified    0.573032\n",
       "home_ownership_RENT                    0.412676\n",
       "last_credit_pull_d_month               0.260780\n",
       "dti                                    0.245930\n",
       "percent_bc_gt_75                       0.227785\n",
       "initial_list_status_w                  0.025999\n",
       "zip_code                               0.022731\n",
       "home_ownership_MORTGAGE                0.001611\n",
       "issue_d_month                         -0.018204\n",
       "initial_list_status_f                 -0.025999\n",
       "mo_sin_old_il_acct                    -0.052109\n",
       "revol_util                            -0.064032\n",
       "earliest_cr_line_month                -0.128330\n",
       "purpose_debt_consolidation            -0.367730\n",
       "bc_util                               -0.412165\n",
       "mths_since_last_major_derog           -0.666040\n",
       "issue_d_year                          -0.755609\n",
       "earliest_cr_line_year                 -0.956356\n",
       "loan_status                           -1.560237\n",
       "last_credit_pull_d_year               -1.808024\n",
       "pct_tl_nvr_dlq                        -2.644205\n",
       "\n",
       "[208 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highly skewed features\n",
    "\n",
    "skewed_features = df.apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew': skewed_features})\n",
    "skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 208 skewed features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print('There are {} skewed features to Box Cox transform'.format(skewness.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    df[feat] = boxcox1p(df[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(769790, 208)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_TX</th>\n",
       "      <th>addr_state_UT</th>\n",
       "      <th>addr_state_VA</th>\n",
       "      <th>addr_state_VT</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321150</th>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.850738</td>\n",
       "      <td>31.765210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.779829</td>\n",
       "      <td>4.033107</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705691</th>\n",
       "      <td>18.491718</td>\n",
       "      <td>18.491718</td>\n",
       "      <td>18.491718</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.243621</td>\n",
       "      <td>24.470542</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.881187</td>\n",
       "      <td>2.625605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377068</th>\n",
       "      <td>24.306440</td>\n",
       "      <td>24.306440</td>\n",
       "      <td>24.306440</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.237275</td>\n",
       "      <td>29.167258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.034756</td>\n",
       "      <td>3.782840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85052</th>\n",
       "      <td>19.000645</td>\n",
       "      <td>19.000645</td>\n",
       "      <td>19.000645</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.967806</td>\n",
       "      <td>28.476974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.640795</td>\n",
       "      <td>3.901909</td>\n",
       "      <td>1.540963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386388</th>\n",
       "      <td>20.610004</td>\n",
       "      <td>20.610004</td>\n",
       "      <td>20.610004</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.571590</td>\n",
       "      <td>28.869811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.234013</td>\n",
       "      <td>3.800769</td>\n",
       "      <td>1.820334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744945</th>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>8.520744</td>\n",
       "      <td>29.020291</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>12.074291</td>\n",
       "      <td>3.014966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752311</th>\n",
       "      <td>19.458096</td>\n",
       "      <td>19.458096</td>\n",
       "      <td>19.458096</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.050880</td>\n",
       "      <td>29.919958</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.899104</td>\n",
       "      <td>4.240562</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346005</th>\n",
       "      <td>23.598505</td>\n",
       "      <td>23.598505</td>\n",
       "      <td>23.598505</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.456122</td>\n",
       "      <td>30.296202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>2.465680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175060</th>\n",
       "      <td>19.403352</td>\n",
       "      <td>19.403352</td>\n",
       "      <td>19.403352</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.022056</td>\n",
       "      <td>23.964056</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>8.889640</td>\n",
       "      <td>4.319412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194471</th>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.326250</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>12.600135</td>\n",
       "      <td>30.737918</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.332597</td>\n",
       "      <td>4.155134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16968</th>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.114244</td>\n",
       "      <td>27.607297</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.673285</td>\n",
       "      <td>3.643754</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221877</th>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.286754</td>\n",
       "      <td>25.193510</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>7.087847</td>\n",
       "      <td>4.445579</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750553</th>\n",
       "      <td>21.366208</td>\n",
       "      <td>21.366208</td>\n",
       "      <td>21.366208</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.195819</td>\n",
       "      <td>26.591022</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.685037</td>\n",
       "      <td>4.856594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103124</th>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.278551</td>\n",
       "      <td>29.520421</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.934540</td>\n",
       "      <td>3.484859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611644</th>\n",
       "      <td>17.253669</td>\n",
       "      <td>17.253669</td>\n",
       "      <td>17.253669</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>7.746614</td>\n",
       "      <td>32.417002</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.259868</td>\n",
       "      <td>4.715434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88294</th>\n",
       "      <td>20.610004</td>\n",
       "      <td>20.610004</td>\n",
       "      <td>20.610004</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>9.334637</td>\n",
       "      <td>31.205218</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.868631</td>\n",
       "      <td>3.412347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262327</th>\n",
       "      <td>23.784389</td>\n",
       "      <td>23.784389</td>\n",
       "      <td>23.784389</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.420912</td>\n",
       "      <td>32.548972</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>8.081455</td>\n",
       "      <td>3.845224</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742732</th>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.207970</td>\n",
       "      <td>29.588763</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.808145</td>\n",
       "      <td>4.261338</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661855</th>\n",
       "      <td>22.998360</td>\n",
       "      <td>22.998360</td>\n",
       "      <td>22.998360</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.117664</td>\n",
       "      <td>30.110806</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.826617</td>\n",
       "      <td>2.691301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253918</th>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.376413</td>\n",
       "      <td>28.557548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.889015</td>\n",
       "      <td>2.542807</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285338</th>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.990468</td>\n",
       "      <td>27.120793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.682968</td>\n",
       "      <td>4.378659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484133</th>\n",
       "      <td>20.515322</td>\n",
       "      <td>20.515322</td>\n",
       "      <td>20.515322</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.685099</td>\n",
       "      <td>26.591022</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.192820</td>\n",
       "      <td>4.590490</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298125</th>\n",
       "      <td>19.000645</td>\n",
       "      <td>19.000645</td>\n",
       "      <td>19.000645</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.753449</td>\n",
       "      <td>26.008617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.174253</td>\n",
       "      <td>4.305205</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143478</th>\n",
       "      <td>21.944481</td>\n",
       "      <td>21.944481</td>\n",
       "      <td>21.944481</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.510913</td>\n",
       "      <td>26.365003</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.151348</td>\n",
       "      <td>4.009672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449990</th>\n",
       "      <td>13.856095</td>\n",
       "      <td>13.856095</td>\n",
       "      <td>13.856095</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>5.755915</td>\n",
       "      <td>26.008617</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.151348</td>\n",
       "      <td>3.764735</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650465</th>\n",
       "      <td>22.556361</td>\n",
       "      <td>22.556361</td>\n",
       "      <td>22.556361</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.813239</td>\n",
       "      <td>27.368970</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.215888</td>\n",
       "      <td>1.509852</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148158</th>\n",
       "      <td>19.953156</td>\n",
       "      <td>19.953156</td>\n",
       "      <td>19.953156</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.509980</td>\n",
       "      <td>28.476974</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.336190</td>\n",
       "      <td>4.039262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585083</th>\n",
       "      <td>18.803944</td>\n",
       "      <td>18.803944</td>\n",
       "      <td>18.803944</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.427938</td>\n",
       "      <td>27.069896</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.520315</td>\n",
       "      <td>3.613932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661892</th>\n",
       "      <td>20.088200</td>\n",
       "      <td>20.088200</td>\n",
       "      <td>20.088200</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.251634</td>\n",
       "      <td>23.598505</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.987364</td>\n",
       "      <td>3.870050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685296</th>\n",
       "      <td>23.405917</td>\n",
       "      <td>23.405917</td>\n",
       "      <td>23.405917</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.361691</td>\n",
       "      <td>30.234988</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.895060</td>\n",
       "      <td>4.292687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662335</th>\n",
       "      <td>24.933056</td>\n",
       "      <td>24.933056</td>\n",
       "      <td>24.933056</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.293276</td>\n",
       "      <td>33.747323</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>4.926918</td>\n",
       "      <td>2.587072</td>\n",
       "      <td>2.259674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62222</th>\n",
       "      <td>24.984658</td>\n",
       "      <td>24.984658</td>\n",
       "      <td>24.977316</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.281497</td>\n",
       "      <td>29.020291</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>7.169005</td>\n",
       "      <td>2.803080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569253</th>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.008014</td>\n",
       "      <td>28.228763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.102765</td>\n",
       "      <td>3.858807</td>\n",
       "      <td>1.194318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685999</th>\n",
       "      <td>20.610004</td>\n",
       "      <td>20.610004</td>\n",
       "      <td>20.610004</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>8.806050</td>\n",
       "      <td>31.258099</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.922126</td>\n",
       "      <td>3.657226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465029</th>\n",
       "      <td>17.253669</td>\n",
       "      <td>17.253669</td>\n",
       "      <td>17.253669</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>7.668440</td>\n",
       "      <td>36.083784</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.452540</td>\n",
       "      <td>3.183845</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193627</th>\n",
       "      <td>17.531355</td>\n",
       "      <td>17.531355</td>\n",
       "      <td>17.531355</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>7.869224</td>\n",
       "      <td>28.057555</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.762621</td>\n",
       "      <td>3.678908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689311</th>\n",
       "      <td>19.458096</td>\n",
       "      <td>19.458096</td>\n",
       "      <td>19.458096</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.975303</td>\n",
       "      <td>33.292174</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.892039</td>\n",
       "      <td>4.355640</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46736</th>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.851116</td>\n",
       "      <td>31.516424</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.758304</td>\n",
       "      <td>2.207161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157520</th>\n",
       "      <td>23.206076</td>\n",
       "      <td>23.206076</td>\n",
       "      <td>23.206076</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.091968</td>\n",
       "      <td>27.120793</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>10.991230</td>\n",
       "      <td>2.663253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154861</th>\n",
       "      <td>23.673634</td>\n",
       "      <td>23.673634</td>\n",
       "      <td>23.673634</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.369554</td>\n",
       "      <td>31.279135</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>7.511251</td>\n",
       "      <td>3.149580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653106</th>\n",
       "      <td>15.705168</td>\n",
       "      <td>15.705168</td>\n",
       "      <td>15.705168</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>6.890879</td>\n",
       "      <td>31.566920</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.800080</td>\n",
       "      <td>4.286098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249956</th>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>12.534749</td>\n",
       "      <td>31.205218</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.898079</td>\n",
       "      <td>2.888450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139750</th>\n",
       "      <td>18.213642</td>\n",
       "      <td>18.213642</td>\n",
       "      <td>18.213642</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.478906</td>\n",
       "      <td>24.820844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.895060</td>\n",
       "      <td>3.609631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312047</th>\n",
       "      <td>22.104477</td>\n",
       "      <td>22.104477</td>\n",
       "      <td>22.104477</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.584823</td>\n",
       "      <td>25.758185</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.692623</td>\n",
       "      <td>4.713020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102621</th>\n",
       "      <td>23.710807</td>\n",
       "      <td>23.710807</td>\n",
       "      <td>23.710807</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.547374</td>\n",
       "      <td>32.971576</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.901094</td>\n",
       "      <td>1.802404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183377</th>\n",
       "      <td>22.320331</td>\n",
       "      <td>22.320331</td>\n",
       "      <td>22.314289</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.137815</td>\n",
       "      <td>29.310888</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.695834</td>\n",
       "      <td>3.369546</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614893</th>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>19.874209</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>8.761210</td>\n",
       "      <td>28.057555</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.984891</td>\n",
       "      <td>3.663925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82179</th>\n",
       "      <td>21.126905</td>\n",
       "      <td>21.126905</td>\n",
       "      <td>21.126905</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.076813</td>\n",
       "      <td>27.241203</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.404587</td>\n",
       "      <td>3.657226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563208</th>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>9.506753</td>\n",
       "      <td>29.588763</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.901094</td>\n",
       "      <td>3.323665</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119484</th>\n",
       "      <td>19.060400</td>\n",
       "      <td>19.060400</td>\n",
       "      <td>19.060400</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.856576</td>\n",
       "      <td>25.884766</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>9.286968</td>\n",
       "      <td>3.884194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462623</th>\n",
       "      <td>20.256340</td>\n",
       "      <td>20.256340</td>\n",
       "      <td>20.256340</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.667206</td>\n",
       "      <td>26.591022</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.800080</td>\n",
       "      <td>4.212091</td>\n",
       "      <td>1.194318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236079</th>\n",
       "      <td>21.248010</td>\n",
       "      <td>21.248010</td>\n",
       "      <td>21.248010</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>9.531362</td>\n",
       "      <td>27.120793</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>7.606710</td>\n",
       "      <td>2.576118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395731</th>\n",
       "      <td>23.598505</td>\n",
       "      <td>23.598505</td>\n",
       "      <td>23.598505</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>10.850864</td>\n",
       "      <td>31.120480</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.966746</td>\n",
       "      <td>2.779652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427531</th>\n",
       "      <td>22.142137</td>\n",
       "      <td>22.142137</td>\n",
       "      <td>22.135880</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.845409</td>\n",
       "      <td>25.704175</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>11.346944</td>\n",
       "      <td>4.726982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263854</th>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.122975</td>\n",
       "      <td>26.808659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.178051</td>\n",
       "      <td>3.875274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>21.538377</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>10.244536</td>\n",
       "      <td>28.715631</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>5.802739</td>\n",
       "      <td>3.823130</td>\n",
       "      <td>1.194318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331637</th>\n",
       "      <td>19.458096</td>\n",
       "      <td>19.458096</td>\n",
       "      <td>19.458096</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>8.821255</td>\n",
       "      <td>28.869811</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>8.511220</td>\n",
       "      <td>4.378659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11293</th>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>22.782058</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>11.102736</td>\n",
       "      <td>27.221303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.102765</td>\n",
       "      <td>4.396881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638747</th>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>25.360669</td>\n",
       "      <td>5.684507</td>\n",
       "      <td>11.399088</td>\n",
       "      <td>46.288557</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.073289</td>\n",
       "      <td>2.539599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291880</th>\n",
       "      <td>20.256340</td>\n",
       "      <td>20.256340</td>\n",
       "      <td>20.256340</td>\n",
       "      <td>4.792130</td>\n",
       "      <td>9.460173</td>\n",
       "      <td>26.591022</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>6.654950</td>\n",
       "      <td>3.095148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769790 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_amnt  funded_amnt  funded_amnt_inv      term  installment  \\\n",
       "321150  22.782058    22.782058        22.782058  4.792130    10.850738   \n",
       "705691  18.491718    18.491718        18.491718  4.792130     8.243621   \n",
       "377068  24.306440    24.306440        24.306440  5.684507    11.237275   \n",
       "85052   19.000645    19.000645        19.000645  4.792130     8.967806   \n",
       "386388  20.610004    20.610004        20.610004  4.792130     9.571590   \n",
       "744945  19.874209    19.874209        19.874209  5.684507     8.520744   \n",
       "752311  19.458096    19.458096        19.458096  4.792130     9.050880   \n",
       "346005  23.598505    23.598505        23.598505  5.684507    10.456122   \n",
       "175060  19.403352    19.403352        19.403352  4.792130     9.022056   \n",
       "194471  25.360669    25.360669        25.326250  4.792130    12.600135   \n",
       "16968   19.874209    19.874209        19.874209  4.792130     9.114244   \n",
       "221877  19.874209    19.874209        19.874209  4.792130     9.286754   \n",
       "750553  21.366208    21.366208        21.366208  4.792130    10.195819   \n",
       "103124  19.874209    19.874209        19.874209  4.792130     9.278551   \n",
       "611644  17.253669    17.253669        17.253669  4.792130     7.746614   \n",
       "88294   20.610004    20.610004        20.610004  5.684507     9.334637   \n",
       "262327  23.784389    23.784389        23.784389  4.792130    11.420912   \n",
       "742732  21.538377    21.538377        21.538377  4.792130    10.207970   \n",
       "661855  22.998360    22.998360        22.998360  4.792130    11.117664   \n",
       "253918  22.782058    22.782058        22.782058  5.684507    10.376413   \n",
       "285338  22.782058    22.782058        22.782058  4.792130    10.990468   \n",
       "484133  20.515322    20.515322        20.515322  4.792130     9.685099   \n",
       "298125  19.000645    19.000645        19.000645  4.792130     8.753449   \n",
       "143478  21.944481    21.944481        21.944481  4.792130    10.510913   \n",
       "449990  13.856095    13.856095        13.856095  4.792130     5.755915   \n",
       "650465  22.556361    22.556361        22.556361  4.792130    10.813239   \n",
       "148158  19.953156    19.953156        19.953156  4.792130     9.509980   \n",
       "585083  18.803944    18.803944        18.803944  4.792130     8.427938   \n",
       "661892  20.088200    20.088200        20.088200  4.792130     9.251634   \n",
       "685296  23.405917    23.405917        23.405917  4.792130    11.361691   \n",
       "...           ...          ...              ...       ...          ...   \n",
       "662335  24.933056    24.933056        24.933056  5.684507    11.293276   \n",
       "62222   24.984658    24.984658        24.977316  5.684507    11.281497   \n",
       "569253  22.782058    22.782058        22.782058  4.792130    11.008014   \n",
       "685999  20.610004    20.610004        20.610004  5.684507     8.806050   \n",
       "465029  17.253669    17.253669        17.253669  4.792130     7.668440   \n",
       "193627  17.531355    17.531355        17.531355  4.792130     7.869224   \n",
       "689311  19.458096    19.458096        19.458096  4.792130     8.975303   \n",
       "46736   22.782058    22.782058        22.782058  4.792130    10.851116   \n",
       "157520  23.206076    23.206076        23.206076  4.792130    11.091968   \n",
       "154861  23.673634    23.673634        23.673634  4.792130    11.369554   \n",
       "653106  15.705168    15.705168        15.705168  4.792130     6.890879   \n",
       "249956  25.360669    25.360669        25.360669  4.792130    12.534749   \n",
       "139750  18.213642    18.213642        18.213642  4.792130     8.478906   \n",
       "312047  22.104477    22.104477        22.104477  4.792130    10.584823   \n",
       "102621  23.710807    23.710807        23.710807  4.792130    11.547374   \n",
       "183377  22.320331    22.320331        22.314289  5.684507    10.137815   \n",
       "614893  19.874209    19.874209        19.874209  5.684507     8.761210   \n",
       "82179   21.126905    21.126905        21.126905  4.792130    10.076813   \n",
       "563208  21.538377    21.538377        21.538377  5.684507     9.506753   \n",
       "119484  19.060400    19.060400        19.060400  4.792130     8.856576   \n",
       "462623  20.256340    20.256340        20.256340  4.792130     9.667206   \n",
       "236079  21.248010    21.248010        21.248010  5.684507     9.531362   \n",
       "395731  23.598505    23.598505        23.598505  5.684507    10.850864   \n",
       "427531  22.142137    22.142137        22.135880  4.792130    10.845409   \n",
       "263854  21.538377    21.538377        21.538377  4.792130    10.122975   \n",
       "5127    21.538377    21.538377        21.538377  4.792130    10.244536   \n",
       "331637  19.458096    19.458096        19.458096  4.792130     8.821255   \n",
       "11293   22.782058    22.782058        22.782058  4.792130    11.102736   \n",
       "638747  25.360669    25.360669        25.360669  5.684507    11.399088   \n",
       "291880  20.256340    20.256340        20.256340  4.792130     9.460173   \n",
       "\n",
       "        annual_inc  loan_status   zip_code       dti  delinq_2yrs  \\\n",
       "321150   31.765210     0.000000  10.779829  4.033107     0.730463   \n",
       "705691   24.470542     0.730463   6.881187  2.625605     0.000000   \n",
       "377068   29.167258     0.000000  10.034756  3.782840     0.000000   \n",
       "85052    28.476974     0.000000  11.640795  3.901909     1.540963   \n",
       "386388   28.869811     0.000000  11.234013  3.800769     1.820334   \n",
       "744945   29.020291     0.730463  12.074291  3.014966     0.000000   \n",
       "752311   29.919958     0.730463   6.899104  4.240562     0.730463   \n",
       "346005   30.296202     0.000000   5.684507  2.465680     0.000000   \n",
       "175060   23.964056     0.730463   8.889640  4.319412     0.000000   \n",
       "194471   30.737918     0.730463  11.332597  4.155134     0.000000   \n",
       "16968    27.607297     0.730463  11.673285  3.643754     0.730463   \n",
       "221877   25.193510     0.730463   7.087847  4.445579     0.000000   \n",
       "750553   26.591022     0.730463   9.685037  4.856594     0.000000   \n",
       "103124   29.520421     0.730463   6.934540  3.484859     0.000000   \n",
       "611644   32.417002     0.730463  11.259868  4.715434     0.000000   \n",
       "88294    31.205218     0.730463  10.868631  3.412347     0.000000   \n",
       "262327   32.548972     0.730463   8.081455  3.845224     0.730463   \n",
       "742732   29.588763     0.730463   6.808145  4.261338     0.000000   \n",
       "661855   30.110806     0.730463   6.826617  2.691301     0.000000   \n",
       "253918   28.557548     0.000000  11.889015  2.542807     0.000000   \n",
       "285338   27.120793     0.000000  11.682968  4.378659     0.000000   \n",
       "484133   26.591022     0.730463   9.192820  4.590490     0.730463   \n",
       "298125   26.008617     0.000000  10.174253  4.305205     0.730463   \n",
       "143478   26.365003     0.730463  11.151348  4.009672     0.000000   \n",
       "449990   26.008617     0.730463  11.151348  3.764735     0.730463   \n",
       "650465   27.368970     0.730463  10.215888  1.509852     0.730463   \n",
       "148158   28.476974     0.730463  11.336190  4.039262     0.000000   \n",
       "585083   27.069896     0.730463  10.520315  3.613932     0.000000   \n",
       "661892   23.598505     0.730463  11.987364  3.870050     0.000000   \n",
       "685296   30.234988     0.730463  11.895060  4.292687     0.000000   \n",
       "...            ...          ...        ...       ...          ...   \n",
       "662335   33.747323     0.730463   4.926918  2.587072     2.259674   \n",
       "62222    29.020291     0.730463   7.169005  2.803080     0.000000   \n",
       "569253   28.228763     0.000000  12.102765  3.858807     1.194318   \n",
       "685999   31.258099     0.730463  11.922126  3.657226     0.000000   \n",
       "465029   36.083784     0.730463  11.452540  3.183845     0.730463   \n",
       "193627   28.057555     0.730463  10.762621  3.678908     0.000000   \n",
       "689311   33.292174     0.730463  11.892039  4.355640     0.730463   \n",
       "46736    31.516424     0.730463  10.758304  2.207161     0.000000   \n",
       "157520   27.120793     0.730463  10.991230  2.663253     0.000000   \n",
       "154861   31.279135     0.730463   7.511251  3.149580     0.000000   \n",
       "653106   31.566920     0.730463  11.800080  4.286098     0.000000   \n",
       "249956   31.205218     0.730463  11.898079  2.888450     0.000000   \n",
       "139750   24.820844     0.000000  11.895060  3.609631     0.000000   \n",
       "312047   25.758185     0.730463  11.692623  4.713020     0.000000   \n",
       "102621   32.971576     0.730463  11.901094  1.802404     0.000000   \n",
       "183377   29.310888     0.730463  11.695834  3.369546     0.000000   \n",
       "614893   28.057555     0.730463   9.984891  3.663925     0.000000   \n",
       "82179    27.241203     0.730463   6.404587  3.657226     0.000000   \n",
       "563208   29.588763     0.000000  11.901094  3.323665     0.000000   \n",
       "119484   25.884766     0.730463   9.286968  3.884194     0.000000   \n",
       "462623   26.591022     0.730463  11.800080  4.212091     1.194318   \n",
       "236079   27.120793     0.730463   7.606710  2.576118     0.000000   \n",
       "395731   31.120480     0.730463  11.966746  2.779652     0.000000   \n",
       "427531   25.704175     0.730463  11.346944  4.726982     0.000000   \n",
       "263854   26.808659     0.000000   9.178051  3.875274     0.000000   \n",
       "5127     28.715631     0.730463   5.802739  3.823130     1.194318   \n",
       "331637   28.869811     0.730463   8.511220  4.378659     0.000000   \n",
       "11293    27.221303     0.000000  12.102765  4.396881     0.000000   \n",
       "638747   46.288557     0.730463   6.073289  2.539599     0.000000   \n",
       "291880   26.591022     0.730463   6.654950  3.095148     0.000000   \n",
       "\n",
       "                ...            addr_state_TX  addr_state_UT  addr_state_VA  \\\n",
       "321150          ...                 0.000000       0.000000       0.000000   \n",
       "705691          ...                 0.000000       0.000000       0.000000   \n",
       "377068          ...                 0.000000       0.000000       0.000000   \n",
       "85052           ...                 0.000000       0.730463       0.000000   \n",
       "386388          ...                 0.000000       0.000000       0.000000   \n",
       "744945          ...                 0.000000       0.000000       0.000000   \n",
       "752311          ...                 0.000000       0.000000       0.000000   \n",
       "346005          ...                 0.000000       0.000000       0.000000   \n",
       "175060          ...                 0.000000       0.000000       0.000000   \n",
       "194471          ...                 0.730463       0.000000       0.000000   \n",
       "16968           ...                 0.000000       0.000000       0.000000   \n",
       "221877          ...                 0.000000       0.000000       0.000000   \n",
       "750553          ...                 0.000000       0.000000       0.000000   \n",
       "103124          ...                 0.000000       0.000000       0.000000   \n",
       "611644          ...                 0.000000       0.000000       0.000000   \n",
       "88294           ...                 0.000000       0.000000       0.000000   \n",
       "262327          ...                 0.000000       0.000000       0.000000   \n",
       "742732          ...                 0.000000       0.000000       0.000000   \n",
       "661855          ...                 0.000000       0.000000       0.000000   \n",
       "253918          ...                 0.000000       0.000000       0.000000   \n",
       "285338          ...                 0.000000       0.000000       0.000000   \n",
       "484133          ...                 0.000000       0.000000       0.000000   \n",
       "298125          ...                 0.000000       0.000000       0.000000   \n",
       "143478          ...                 0.000000       0.000000       0.000000   \n",
       "449990          ...                 0.000000       0.000000       0.000000   \n",
       "650465          ...                 0.000000       0.000000       0.000000   \n",
       "148158          ...                 0.730463       0.000000       0.000000   \n",
       "585083          ...                 0.000000       0.000000       0.000000   \n",
       "661892          ...                 0.000000       0.000000       0.000000   \n",
       "685296          ...                 0.000000       0.000000       0.000000   \n",
       "...             ...                      ...            ...            ...   \n",
       "662335          ...                 0.000000       0.000000       0.000000   \n",
       "62222           ...                 0.000000       0.000000       0.000000   \n",
       "569253          ...                 0.000000       0.000000       0.000000   \n",
       "685999          ...                 0.000000       0.000000       0.000000   \n",
       "465029          ...                 0.730463       0.000000       0.000000   \n",
       "193627          ...                 0.000000       0.000000       0.000000   \n",
       "689311          ...                 0.000000       0.000000       0.000000   \n",
       "46736           ...                 0.000000       0.000000       0.000000   \n",
       "157520          ...                 0.000000       0.000000       0.000000   \n",
       "154861          ...                 0.000000       0.000000       0.000000   \n",
       "653106          ...                 0.000000       0.000000       0.000000   \n",
       "249956          ...                 0.000000       0.000000       0.000000   \n",
       "139750          ...                 0.000000       0.000000       0.000000   \n",
       "312047          ...                 0.000000       0.000000       0.000000   \n",
       "102621          ...                 0.000000       0.000000       0.000000   \n",
       "183377          ...                 0.000000       0.000000       0.000000   \n",
       "614893          ...                 0.000000       0.000000       0.000000   \n",
       "82179           ...                 0.000000       0.000000       0.000000   \n",
       "563208          ...                 0.000000       0.000000       0.000000   \n",
       "119484          ...                 0.000000       0.000000       0.000000   \n",
       "462623          ...                 0.000000       0.000000       0.000000   \n",
       "236079          ...                 0.000000       0.000000       0.000000   \n",
       "395731          ...                 0.000000       0.000000       0.000000   \n",
       "427531          ...                 0.730463       0.000000       0.000000   \n",
       "263854          ...                 0.000000       0.000000       0.000000   \n",
       "5127            ...                 0.000000       0.000000       0.000000   \n",
       "331637          ...                 0.000000       0.000000       0.730463   \n",
       "11293           ...                 0.000000       0.000000       0.000000   \n",
       "638747          ...                 0.000000       0.000000       0.000000   \n",
       "291880          ...                 0.000000       0.000000       0.000000   \n",
       "\n",
       "        addr_state_VT  addr_state_WA  addr_state_WI  addr_state_WV  \\\n",
       "321150            0.0       0.000000            0.0            0.0   \n",
       "705691            0.0       0.000000            0.0            0.0   \n",
       "377068            0.0       0.000000            0.0            0.0   \n",
       "85052             0.0       0.000000            0.0            0.0   \n",
       "386388            0.0       0.000000            0.0            0.0   \n",
       "744945            0.0       0.730463            0.0            0.0   \n",
       "752311            0.0       0.000000            0.0            0.0   \n",
       "346005            0.0       0.000000            0.0            0.0   \n",
       "175060            0.0       0.000000            0.0            0.0   \n",
       "194471            0.0       0.000000            0.0            0.0   \n",
       "16968             0.0       0.000000            0.0            0.0   \n",
       "221877            0.0       0.000000            0.0            0.0   \n",
       "750553            0.0       0.000000            0.0            0.0   \n",
       "103124            0.0       0.000000            0.0            0.0   \n",
       "611644            0.0       0.000000            0.0            0.0   \n",
       "88294             0.0       0.000000            0.0            0.0   \n",
       "262327            0.0       0.000000            0.0            0.0   \n",
       "742732            0.0       0.000000            0.0            0.0   \n",
       "661855            0.0       0.000000            0.0            0.0   \n",
       "253918            0.0       0.000000            0.0            0.0   \n",
       "285338            0.0       0.000000            0.0            0.0   \n",
       "484133            0.0       0.000000            0.0            0.0   \n",
       "298125            0.0       0.000000            0.0            0.0   \n",
       "143478            0.0       0.000000            0.0            0.0   \n",
       "449990            0.0       0.000000            0.0            0.0   \n",
       "650465            0.0       0.000000            0.0            0.0   \n",
       "148158            0.0       0.000000            0.0            0.0   \n",
       "585083            0.0       0.000000            0.0            0.0   \n",
       "661892            0.0       0.000000            0.0            0.0   \n",
       "685296            0.0       0.000000            0.0            0.0   \n",
       "...               ...            ...            ...            ...   \n",
       "662335            0.0       0.000000            0.0            0.0   \n",
       "62222             0.0       0.000000            0.0            0.0   \n",
       "569253            0.0       0.730463            0.0            0.0   \n",
       "685999            0.0       0.000000            0.0            0.0   \n",
       "465029            0.0       0.000000            0.0            0.0   \n",
       "193627            0.0       0.000000            0.0            0.0   \n",
       "689311            0.0       0.000000            0.0            0.0   \n",
       "46736             0.0       0.000000            0.0            0.0   \n",
       "157520            0.0       0.000000            0.0            0.0   \n",
       "154861            0.0       0.000000            0.0            0.0   \n",
       "653106            0.0       0.000000            0.0            0.0   \n",
       "249956            0.0       0.000000            0.0            0.0   \n",
       "139750            0.0       0.000000            0.0            0.0   \n",
       "312047            0.0       0.000000            0.0            0.0   \n",
       "102621            0.0       0.000000            0.0            0.0   \n",
       "183377            0.0       0.000000            0.0            0.0   \n",
       "614893            0.0       0.000000            0.0            0.0   \n",
       "82179             0.0       0.000000            0.0            0.0   \n",
       "563208            0.0       0.000000            0.0            0.0   \n",
       "119484            0.0       0.000000            0.0            0.0   \n",
       "462623            0.0       0.000000            0.0            0.0   \n",
       "236079            0.0       0.000000            0.0            0.0   \n",
       "395731            0.0       0.000000            0.0            0.0   \n",
       "427531            0.0       0.000000            0.0            0.0   \n",
       "263854            0.0       0.000000            0.0            0.0   \n",
       "5127              0.0       0.000000            0.0            0.0   \n",
       "331637            0.0       0.000000            0.0            0.0   \n",
       "11293             0.0       0.730463            0.0            0.0   \n",
       "638747            0.0       0.000000            0.0            0.0   \n",
       "291880            0.0       0.000000            0.0            0.0   \n",
       "\n",
       "        addr_state_WY  initial_list_status_f  initial_list_status_w  \n",
       "321150            0.0               0.000000               0.730463  \n",
       "705691            0.0               0.730463               0.000000  \n",
       "377068            0.0               0.730463               0.000000  \n",
       "85052             0.0               0.730463               0.000000  \n",
       "386388            0.0               0.000000               0.730463  \n",
       "744945            0.0               0.000000               0.730463  \n",
       "752311            0.0               0.000000               0.730463  \n",
       "346005            0.0               0.000000               0.730463  \n",
       "175060            0.0               0.730463               0.000000  \n",
       "194471            0.0               0.730463               0.000000  \n",
       "16968             0.0               0.000000               0.730463  \n",
       "221877            0.0               0.000000               0.730463  \n",
       "750553            0.0               0.000000               0.730463  \n",
       "103124            0.0               0.730463               0.000000  \n",
       "611644            0.0               0.000000               0.730463  \n",
       "88294             0.0               0.000000               0.730463  \n",
       "262327            0.0               0.000000               0.730463  \n",
       "742732            0.0               0.000000               0.730463  \n",
       "661855            0.0               0.000000               0.730463  \n",
       "253918            0.0               0.000000               0.730463  \n",
       "285338            0.0               0.000000               0.730463  \n",
       "484133            0.0               0.730463               0.000000  \n",
       "298125            0.0               0.730463               0.000000  \n",
       "143478            0.0               0.000000               0.730463  \n",
       "449990            0.0               0.000000               0.730463  \n",
       "650465            0.0               0.730463               0.000000  \n",
       "148158            0.0               0.000000               0.730463  \n",
       "585083            0.0               0.000000               0.730463  \n",
       "661892            0.0               0.000000               0.730463  \n",
       "685296            0.0               0.000000               0.730463  \n",
       "...               ...                    ...                    ...  \n",
       "662335            0.0               0.000000               0.730463  \n",
       "62222             0.0               0.730463               0.000000  \n",
       "569253            0.0               0.730463               0.000000  \n",
       "685999            0.0               0.000000               0.730463  \n",
       "465029            0.0               0.730463               0.000000  \n",
       "193627            0.0               0.730463               0.000000  \n",
       "689311            0.0               0.000000               0.730463  \n",
       "46736             0.0               0.000000               0.730463  \n",
       "157520            0.0               0.730463               0.000000  \n",
       "154861            0.0               0.730463               0.000000  \n",
       "653106            0.0               0.000000               0.730463  \n",
       "249956            0.0               0.730463               0.000000  \n",
       "139750            0.0               0.730463               0.000000  \n",
       "312047            0.0               0.730463               0.000000  \n",
       "102621            0.0               0.000000               0.730463  \n",
       "183377            0.0               0.730463               0.000000  \n",
       "614893            0.0               0.730463               0.000000  \n",
       "82179             0.0               0.000000               0.730463  \n",
       "563208            0.0               0.000000               0.730463  \n",
       "119484            0.0               0.730463               0.000000  \n",
       "462623            0.0               0.730463               0.000000  \n",
       "236079            0.0               0.000000               0.730463  \n",
       "395731            0.0               0.730463               0.000000  \n",
       "427531            0.0               0.730463               0.000000  \n",
       "263854            0.0               0.730463               0.000000  \n",
       "5127              0.0               0.000000               0.730463  \n",
       "331637            0.0               0.730463               0.000000  \n",
       "11293             0.0               0.000000               0.730463  \n",
       "638747            0.0               0.000000               0.730463  \n",
       "291880            0.0               0.000000               0.730463  \n",
       "\n",
       "[769790 rows x 208 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu = 0.59 and sigma = 0.29\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Produce a scatter matrix for each pair of features in the data\n",
    "# pd.scatter_matrix(df, alpha = 0.3, figsize = (14,8), diagonal = 'kde');\n",
    "\n",
    "# Check skew again\n",
    "check_skewness('loan_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>...</th>\n",
       "      <th>addr_state_TX</th>\n",
       "      <th>addr_state_UT</th>\n",
       "      <th>addr_state_VA</th>\n",
       "      <th>addr_state_VT</th>\n",
       "      <th>addr_state_WA</th>\n",
       "      <th>addr_state_WI</th>\n",
       "      <th>addr_state_WV</th>\n",
       "      <th>addr_state_WY</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>0.991096</td>\n",
       "      <td>0.390193</td>\n",
       "      <td>0.974018</td>\n",
       "      <td>0.477400</td>\n",
       "      <td>-0.066544</td>\n",
       "      <td>-0.009669</td>\n",
       "      <td>0.056308</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026023</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>-0.005485</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>-0.007797</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>-0.070802</td>\n",
       "      <td>0.070802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt</th>\n",
       "      <td>0.999485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992095</td>\n",
       "      <td>0.389246</td>\n",
       "      <td>0.974854</td>\n",
       "      <td>0.477231</td>\n",
       "      <td>-0.066608</td>\n",
       "      <td>-0.009558</td>\n",
       "      <td>0.056982</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026057</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>-0.005447</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>-0.007744</td>\n",
       "      <td>-0.002122</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>-0.072154</td>\n",
       "      <td>0.072154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <td>0.991096</td>\n",
       "      <td>0.992095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.387604</td>\n",
       "      <td>0.966986</td>\n",
       "      <td>0.473318</td>\n",
       "      <td>-0.065480</td>\n",
       "      <td>-0.008968</td>\n",
       "      <td>0.060703</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025973</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.012302</td>\n",
       "      <td>-0.005353</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>-0.001838</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>-0.077645</td>\n",
       "      <td>0.077645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <td>0.390193</td>\n",
       "      <td>0.389246</td>\n",
       "      <td>0.387604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202143</td>\n",
       "      <td>0.119207</td>\n",
       "      <td>-0.177213</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>0.077999</td>\n",
       "      <td>-0.003978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>-0.001682</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>-0.001286</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>-0.104144</td>\n",
       "      <td>0.104144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installment</th>\n",
       "      <td>0.974018</td>\n",
       "      <td>0.974854</td>\n",
       "      <td>0.966986</td>\n",
       "      <td>0.202143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463165</td>\n",
       "      <td>-0.054160</td>\n",
       "      <td>-0.006072</td>\n",
       "      <td>0.059020</td>\n",
       "      <td>0.012874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028221</td>\n",
       "      <td>-0.001156</td>\n",
       "      <td>0.010473</td>\n",
       "      <td>-0.005761</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>-0.008420</td>\n",
       "      <td>-0.004346</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>-0.037874</td>\n",
       "      <td>0.037874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_inc</th>\n",
       "      <td>0.477400</td>\n",
       "      <td>0.477231</td>\n",
       "      <td>0.473318</td>\n",
       "      <td>0.119207</td>\n",
       "      <td>0.463165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073179</td>\n",
       "      <td>-0.018996</td>\n",
       "      <td>-0.206780</td>\n",
       "      <td>0.082058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042691</td>\n",
       "      <td>-0.005789</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>-0.011048</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>-0.022968</td>\n",
       "      <td>-0.013172</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.072128</td>\n",
       "      <td>0.072128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>-0.066544</td>\n",
       "      <td>-0.066608</td>\n",
       "      <td>-0.065480</td>\n",
       "      <td>-0.177213</td>\n",
       "      <td>-0.054160</td>\n",
       "      <td>0.073179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>-0.112951</td>\n",
       "      <td>-0.021707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>0.014353</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>-0.016898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_code</th>\n",
       "      <td>-0.009669</td>\n",
       "      <td>-0.009558</td>\n",
       "      <td>-0.008968</td>\n",
       "      <td>-0.014858</td>\n",
       "      <td>-0.006072</td>\n",
       "      <td>-0.018996</td>\n",
       "      <td>0.007509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>-0.026868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230466</td>\n",
       "      <td>0.080285</td>\n",
       "      <td>-0.114895</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>0.166892</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>-0.033409</td>\n",
       "      <td>0.041353</td>\n",
       "      <td>-0.004527</td>\n",
       "      <td>0.004527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dti</th>\n",
       "      <td>0.056308</td>\n",
       "      <td>0.056982</td>\n",
       "      <td>0.060703</td>\n",
       "      <td>0.077999</td>\n",
       "      <td>0.059020</td>\n",
       "      <td>-0.206780</td>\n",
       "      <td>-0.112951</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033514</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>-0.003084</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>-0.033031</td>\n",
       "      <td>0.033031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.004916</td>\n",
       "      <td>-0.003978</td>\n",
       "      <td>0.012874</td>\n",
       "      <td>0.082058</td>\n",
       "      <td>-0.021707</td>\n",
       "      <td>-0.026868</td>\n",
       "      <td>-0.003484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>-0.008026</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>-0.018312</td>\n",
       "      <td>0.018312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <td>-0.020323</td>\n",
       "      <td>-0.020577</td>\n",
       "      <td>-0.022398</td>\n",
       "      <td>0.018652</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.047342</td>\n",
       "      <td>-0.059518</td>\n",
       "      <td>0.007723</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003229</td>\n",
       "      <td>-0.008222</td>\n",
       "      <td>-0.014345</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>-0.001528</td>\n",
       "      <td>0.025676</td>\n",
       "      <td>-0.001120</td>\n",
       "      <td>-0.000857</td>\n",
       "      <td>0.062647</td>\n",
       "      <td>-0.062647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_delinq</th>\n",
       "      <td>-0.014778</td>\n",
       "      <td>-0.014335</td>\n",
       "      <td>-0.013158</td>\n",
       "      <td>-0.003854</td>\n",
       "      <td>-0.006111</td>\n",
       "      <td>0.066305</td>\n",
       "      <td>-0.009994</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>-0.012592</td>\n",
       "      <td>0.149356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>-0.001918</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>-0.004514</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>-0.003506</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>-0.027498</td>\n",
       "      <td>0.027498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_record</th>\n",
       "      <td>-0.092025</td>\n",
       "      <td>-0.091660</td>\n",
       "      <td>-0.089168</td>\n",
       "      <td>-0.019571</td>\n",
       "      <td>-0.083766</td>\n",
       "      <td>-0.052798</td>\n",
       "      <td>-0.026642</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>-0.035089</td>\n",
       "      <td>-0.035875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049278</td>\n",
       "      <td>0.004727</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>-0.004452</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.011081</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>-0.037953</td>\n",
       "      <td>0.037953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc</th>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>0.212126</td>\n",
       "      <td>0.083154</td>\n",
       "      <td>0.203303</td>\n",
       "      <td>0.238623</td>\n",
       "      <td>-0.031532</td>\n",
       "      <td>-0.035427</td>\n",
       "      <td>0.343216</td>\n",
       "      <td>0.061422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023215</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>-0.006819</td>\n",
       "      <td>-0.019349</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>-0.005190</td>\n",
       "      <td>-0.060650</td>\n",
       "      <td>0.060650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pub_rec</th>\n",
       "      <td>-0.084330</td>\n",
       "      <td>-0.083944</td>\n",
       "      <td>-0.081429</td>\n",
       "      <td>-0.023251</td>\n",
       "      <td>-0.074744</td>\n",
       "      <td>-0.031704</td>\n",
       "      <td>-0.027696</td>\n",
       "      <td>0.010456</td>\n",
       "      <td>-0.044163</td>\n",
       "      <td>-0.025450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052377</td>\n",
       "      <td>0.007235</td>\n",
       "      <td>-0.006969</td>\n",
       "      <td>-0.005323</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>0.011187</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>-0.040101</td>\n",
       "      <td>0.040101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_bal</th>\n",
       "      <td>0.417355</td>\n",
       "      <td>0.417309</td>\n",
       "      <td>0.414715</td>\n",
       "      <td>0.125793</td>\n",
       "      <td>0.408449</td>\n",
       "      <td>0.370988</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>-0.020847</td>\n",
       "      <td>0.280467</td>\n",
       "      <td>-0.059159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006628</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>-0.000878</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>-0.003940</td>\n",
       "      <td>-0.027453</td>\n",
       "      <td>0.027453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revol_util</th>\n",
       "      <td>0.114590</td>\n",
       "      <td>0.115009</td>\n",
       "      <td>0.116574</td>\n",
       "      <td>0.054926</td>\n",
       "      <td>0.134621</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>-0.068937</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.247784</td>\n",
       "      <td>-0.011658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006662</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.019187</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.056269</td>\n",
       "      <td>-0.056269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_acc</th>\n",
       "      <td>0.233905</td>\n",
       "      <td>0.233907</td>\n",
       "      <td>0.233793</td>\n",
       "      <td>0.108196</td>\n",
       "      <td>0.213998</td>\n",
       "      <td>0.323543</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>-0.004780</td>\n",
       "      <td>0.260733</td>\n",
       "      <td>0.135193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035534</td>\n",
       "      <td>0.008228</td>\n",
       "      <td>0.014544</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>-0.013356</td>\n",
       "      <td>0.016553</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>0.006023</td>\n",
       "      <td>-0.054599</td>\n",
       "      <td>0.054599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <td>-0.014017</td>\n",
       "      <td>-0.013868</td>\n",
       "      <td>-0.013079</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>-0.011711</td>\n",
       "      <td>-0.003739</td>\n",
       "      <td>-0.019671</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.074574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016442</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.002788</td>\n",
       "      <td>-0.002203</td>\n",
       "      <td>-0.001233</td>\n",
       "      <td>-0.005726</td>\n",
       "      <td>-0.003231</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>-0.021584</td>\n",
       "      <td>0.021584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_last_major_derog</th>\n",
       "      <td>0.066331</td>\n",
       "      <td>0.069076</td>\n",
       "      <td>0.080548</td>\n",
       "      <td>-0.002716</td>\n",
       "      <td>0.072786</td>\n",
       "      <td>-0.020793</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.071132</td>\n",
       "      <td>-0.197962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>-0.004284</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.006124</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>-0.004456</td>\n",
       "      <td>0.004456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.005226</td>\n",
       "      <td>0.021702</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>-0.005468</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>0.142698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>-0.002030</td>\n",
       "      <td>-0.002552</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.002795</td>\n",
       "      <td>-0.002558</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.001834</td>\n",
       "      <td>-0.007478</td>\n",
       "      <td>0.007478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_coll_amt</th>\n",
       "      <td>-0.056732</td>\n",
       "      <td>-0.056263</td>\n",
       "      <td>-0.053595</td>\n",
       "      <td>-0.024417</td>\n",
       "      <td>-0.048988</td>\n",
       "      <td>-0.024507</td>\n",
       "      <td>-0.022856</td>\n",
       "      <td>0.040848</td>\n",
       "      <td>-0.007915</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050708</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>-0.009667</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>-0.048401</td>\n",
       "      <td>0.048401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_cur_bal</th>\n",
       "      <td>0.259181</td>\n",
       "      <td>0.262826</td>\n",
       "      <td>0.275526</td>\n",
       "      <td>0.090575</td>\n",
       "      <td>0.252833</td>\n",
       "      <td>0.353728</td>\n",
       "      <td>0.012812</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>0.183389</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020295</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.015648</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.010332</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>0.260173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_acc_6m</th>\n",
       "      <td>-0.010461</td>\n",
       "      <td>-0.009977</td>\n",
       "      <td>-0.007788</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>0.059917</td>\n",
       "      <td>-0.034417</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.038309</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008164</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>-0.002890</td>\n",
       "      <td>-0.001944</td>\n",
       "      <td>-0.004861</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>-0.012886</td>\n",
       "      <td>-0.003378</td>\n",
       "      <td>-0.178805</td>\n",
       "      <td>0.178805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_act_il</th>\n",
       "      <td>0.008038</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>0.011843</td>\n",
       "      <td>0.093968</td>\n",
       "      <td>-0.024757</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.128602</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>-0.002448</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>-0.015043</td>\n",
       "      <td>-0.002733</td>\n",
       "      <td>-0.227369</td>\n",
       "      <td>0.227369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_il_12m</th>\n",
       "      <td>-0.007968</td>\n",
       "      <td>-0.007516</td>\n",
       "      <td>-0.005486</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.083813</td>\n",
       "      <td>-0.033189</td>\n",
       "      <td>0.015035</td>\n",
       "      <td>0.097372</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>-0.002597</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>-0.012205</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>-0.165045</td>\n",
       "      <td>0.165045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open_il_24m</th>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>-0.028595</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>0.112441</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>-0.002010</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>-0.014250</td>\n",
       "      <td>-0.001778</td>\n",
       "      <td>-0.209616</td>\n",
       "      <td>0.209616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mths_since_rcnt_il</th>\n",
       "      <td>-0.001046</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>-0.008662</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.033931</td>\n",
       "      <td>-0.007973</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>-0.022155</td>\n",
       "      <td>0.022352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>-0.007544</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-0.002896</td>\n",
       "      <td>-0.001060</td>\n",
       "      <td>-0.016605</td>\n",
       "      <td>-0.003580</td>\n",
       "      <td>-0.249248</td>\n",
       "      <td>0.249248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_bal_il</th>\n",
       "      <td>0.017577</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>0.020821</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.021666</td>\n",
       "      <td>0.106103</td>\n",
       "      <td>-0.022399</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>0.118214</td>\n",
       "      <td>0.025130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>-0.003197</td>\n",
       "      <td>-0.252238</td>\n",
       "      <td>0.252238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il_util</th>\n",
       "      <td>-0.007202</td>\n",
       "      <td>-0.006567</td>\n",
       "      <td>-0.003754</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>0.065138</td>\n",
       "      <td>-0.025927</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.098631</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>-0.004476</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.003040</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>-0.016732</td>\n",
       "      <td>-0.003933</td>\n",
       "      <td>-0.247186</td>\n",
       "      <td>0.247186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_MN</th>\n",
       "      <td>-0.005582</td>\n",
       "      <td>-0.005597</td>\n",
       "      <td>-0.005361</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>-0.006600</td>\n",
       "      <td>-0.016137</td>\n",
       "      <td>-0.001030</td>\n",
       "      <td>0.049545</td>\n",
       "      <td>0.007473</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039762</td>\n",
       "      <td>-0.012047</td>\n",
       "      <td>-0.023253</td>\n",
       "      <td>-0.005901</td>\n",
       "      <td>-0.020362</td>\n",
       "      <td>-0.015356</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>-0.006417</td>\n",
       "      <td>-0.002408</td>\n",
       "      <td>0.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_MO</th>\n",
       "      <td>-0.006830</td>\n",
       "      <td>-0.006835</td>\n",
       "      <td>-0.006559</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>-0.008117</td>\n",
       "      <td>-0.023071</td>\n",
       "      <td>-0.003883</td>\n",
       "      <td>0.068795</td>\n",
       "      <td>0.016738</td>\n",
       "      <td>-0.002437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037230</td>\n",
       "      <td>-0.011280</td>\n",
       "      <td>-0.021772</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>-0.019065</td>\n",
       "      <td>-0.014378</td>\n",
       "      <td>-0.008063</td>\n",
       "      <td>-0.006008</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_MS</th>\n",
       "      <td>-0.001675</td>\n",
       "      <td>-0.001615</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>-0.001434</td>\n",
       "      <td>-0.009153</td>\n",
       "      <td>-0.010460</td>\n",
       "      <td>-0.003238</td>\n",
       "      <td>0.015894</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018805</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.010997</td>\n",
       "      <td>-0.002791</td>\n",
       "      <td>-0.009630</td>\n",
       "      <td>-0.007262</td>\n",
       "      <td>-0.004073</td>\n",
       "      <td>-0.003035</td>\n",
       "      <td>-0.016075</td>\n",
       "      <td>0.016075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_MT</th>\n",
       "      <td>-0.005340</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>-0.005121</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.005811</td>\n",
       "      <td>-0.016548</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.024477</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>-0.002616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015889</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.009292</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>-0.008137</td>\n",
       "      <td>-0.006136</td>\n",
       "      <td>-0.003441</td>\n",
       "      <td>-0.002564</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NC</th>\n",
       "      <td>-0.005754</td>\n",
       "      <td>-0.005707</td>\n",
       "      <td>-0.005446</td>\n",
       "      <td>0.011976</td>\n",
       "      <td>-0.008429</td>\n",
       "      <td>-0.016530</td>\n",
       "      <td>-0.002657</td>\n",
       "      <td>-0.073651</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>-0.002577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050198</td>\n",
       "      <td>-0.015209</td>\n",
       "      <td>-0.029356</td>\n",
       "      <td>-0.007450</td>\n",
       "      <td>-0.025706</td>\n",
       "      <td>-0.019386</td>\n",
       "      <td>-0.010872</td>\n",
       "      <td>-0.008101</td>\n",
       "      <td>-0.003035</td>\n",
       "      <td>0.003035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_ND</th>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>-0.000755</td>\n",
       "      <td>-0.001589</td>\n",
       "      <td>0.011713</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008014</td>\n",
       "      <td>-0.002428</td>\n",
       "      <td>-0.004687</td>\n",
       "      <td>-0.001189</td>\n",
       "      <td>-0.004104</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>-0.001736</td>\n",
       "      <td>-0.001293</td>\n",
       "      <td>-0.013773</td>\n",
       "      <td>0.013773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NE</th>\n",
       "      <td>-0.004595</td>\n",
       "      <td>-0.004542</td>\n",
       "      <td>-0.004615</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>-0.005212</td>\n",
       "      <td>-0.008733</td>\n",
       "      <td>-0.006863</td>\n",
       "      <td>0.025177</td>\n",
       "      <td>0.010432</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012095</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.007073</td>\n",
       "      <td>-0.001795</td>\n",
       "      <td>-0.006194</td>\n",
       "      <td>-0.004671</td>\n",
       "      <td>-0.002620</td>\n",
       "      <td>-0.001952</td>\n",
       "      <td>-0.017507</td>\n",
       "      <td>0.017507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NH</th>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>-0.166683</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020226</td>\n",
       "      <td>-0.006128</td>\n",
       "      <td>-0.011828</td>\n",
       "      <td>-0.003002</td>\n",
       "      <td>-0.010358</td>\n",
       "      <td>-0.007811</td>\n",
       "      <td>-0.004381</td>\n",
       "      <td>-0.003264</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.000718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NJ</th>\n",
       "      <td>0.015108</td>\n",
       "      <td>0.014905</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.014718</td>\n",
       "      <td>0.041771</td>\n",
       "      <td>-0.005705</td>\n",
       "      <td>-0.333219</td>\n",
       "      <td>-0.028679</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057342</td>\n",
       "      <td>-0.017373</td>\n",
       "      <td>-0.033533</td>\n",
       "      <td>-0.008510</td>\n",
       "      <td>-0.029364</td>\n",
       "      <td>-0.022145</td>\n",
       "      <td>-0.012419</td>\n",
       "      <td>-0.009254</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>-0.007361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NM</th>\n",
       "      <td>-0.000799</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>-0.000875</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>-0.007492</td>\n",
       "      <td>-0.001464</td>\n",
       "      <td>0.070449</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022187</td>\n",
       "      <td>-0.006722</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>-0.011362</td>\n",
       "      <td>-0.008569</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>-0.003581</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>-0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NV</th>\n",
       "      <td>-0.010230</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-0.009804</td>\n",
       "      <td>-0.007703</td>\n",
       "      <td>-0.008155</td>\n",
       "      <td>-0.014333</td>\n",
       "      <td>-0.009655</td>\n",
       "      <td>0.120347</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>-0.008730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036618</td>\n",
       "      <td>-0.011094</td>\n",
       "      <td>-0.021414</td>\n",
       "      <td>-0.005434</td>\n",
       "      <td>-0.018751</td>\n",
       "      <td>-0.014142</td>\n",
       "      <td>-0.007931</td>\n",
       "      <td>-0.005909</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_NY</th>\n",
       "      <td>-0.003521</td>\n",
       "      <td>-0.003567</td>\n",
       "      <td>-0.003917</td>\n",
       "      <td>-0.009874</td>\n",
       "      <td>-0.000572</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>-0.009465</td>\n",
       "      <td>-0.398167</td>\n",
       "      <td>-0.061914</td>\n",
       "      <td>0.010477</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087644</td>\n",
       "      <td>-0.026554</td>\n",
       "      <td>-0.051254</td>\n",
       "      <td>-0.013007</td>\n",
       "      <td>-0.044881</td>\n",
       "      <td>-0.033848</td>\n",
       "      <td>-0.018982</td>\n",
       "      <td>-0.014144</td>\n",
       "      <td>0.010405</td>\n",
       "      <td>-0.010405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_OH</th>\n",
       "      <td>-0.015240</td>\n",
       "      <td>-0.015183</td>\n",
       "      <td>-0.014860</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>-0.017845</td>\n",
       "      <td>-0.035246</td>\n",
       "      <td>-0.009353</td>\n",
       "      <td>0.017174</td>\n",
       "      <td>0.030194</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053771</td>\n",
       "      <td>-0.016291</td>\n",
       "      <td>-0.031445</td>\n",
       "      <td>-0.007980</td>\n",
       "      <td>-0.027535</td>\n",
       "      <td>-0.020766</td>\n",
       "      <td>-0.011646</td>\n",
       "      <td>-0.008678</td>\n",
       "      <td>-0.002595</td>\n",
       "      <td>0.002595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_OK</th>\n",
       "      <td>-0.001954</td>\n",
       "      <td>-0.001918</td>\n",
       "      <td>-0.001747</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>-0.002066</td>\n",
       "      <td>-0.009513</td>\n",
       "      <td>-0.009442</td>\n",
       "      <td>0.068716</td>\n",
       "      <td>0.014112</td>\n",
       "      <td>-0.004252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028030</td>\n",
       "      <td>-0.008492</td>\n",
       "      <td>-0.016392</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>-0.014354</td>\n",
       "      <td>-0.010825</td>\n",
       "      <td>-0.006071</td>\n",
       "      <td>-0.004523</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>-0.001710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_OR</th>\n",
       "      <td>-0.011694</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.011422</td>\n",
       "      <td>-0.004886</td>\n",
       "      <td>-0.011681</td>\n",
       "      <td>-0.022823</td>\n",
       "      <td>0.012266</td>\n",
       "      <td>0.124262</td>\n",
       "      <td>-0.004144</td>\n",
       "      <td>-0.004737</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033764</td>\n",
       "      <td>-0.010230</td>\n",
       "      <td>-0.019745</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>-0.017290</td>\n",
       "      <td>-0.013040</td>\n",
       "      <td>-0.007313</td>\n",
       "      <td>-0.005449</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>-0.001762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_PA</th>\n",
       "      <td>-0.008037</td>\n",
       "      <td>-0.008031</td>\n",
       "      <td>-0.007624</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>-0.011408</td>\n",
       "      <td>-0.018623</td>\n",
       "      <td>-0.002804</td>\n",
       "      <td>-0.174613</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055319</td>\n",
       "      <td>-0.016761</td>\n",
       "      <td>-0.032350</td>\n",
       "      <td>-0.008210</td>\n",
       "      <td>-0.028328</td>\n",
       "      <td>-0.021364</td>\n",
       "      <td>-0.011981</td>\n",
       "      <td>-0.008927</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>-0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_RI</th>\n",
       "      <td>-0.004595</td>\n",
       "      <td>-0.004659</td>\n",
       "      <td>-0.004468</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>-0.005246</td>\n",
       "      <td>-0.004308</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>-0.168337</td>\n",
       "      <td>-0.002333</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019450</td>\n",
       "      <td>-0.005893</td>\n",
       "      <td>-0.011375</td>\n",
       "      <td>-0.002887</td>\n",
       "      <td>-0.009960</td>\n",
       "      <td>-0.007512</td>\n",
       "      <td>-0.004213</td>\n",
       "      <td>-0.003139</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_SC</th>\n",
       "      <td>-0.003198</td>\n",
       "      <td>-0.003201</td>\n",
       "      <td>-0.003223</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>-0.003919</td>\n",
       "      <td>-0.012449</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>-0.040811</td>\n",
       "      <td>0.013998</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032231</td>\n",
       "      <td>-0.009765</td>\n",
       "      <td>-0.018849</td>\n",
       "      <td>-0.004783</td>\n",
       "      <td>-0.016505</td>\n",
       "      <td>-0.012448</td>\n",
       "      <td>-0.006981</td>\n",
       "      <td>-0.005202</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>-0.000823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_SD</th>\n",
       "      <td>-0.004340</td>\n",
       "      <td>-0.004320</td>\n",
       "      <td>-0.004168</td>\n",
       "      <td>-0.000481</td>\n",
       "      <td>-0.004327</td>\n",
       "      <td>-0.015648</td>\n",
       "      <td>-0.001917</td>\n",
       "      <td>0.018452</td>\n",
       "      <td>0.012674</td>\n",
       "      <td>-0.002203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013369</td>\n",
       "      <td>-0.004051</td>\n",
       "      <td>-0.007818</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>-0.006846</td>\n",
       "      <td>-0.005163</td>\n",
       "      <td>-0.002895</td>\n",
       "      <td>-0.002158</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_TN</th>\n",
       "      <td>-0.002756</td>\n",
       "      <td>-0.002632</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>-0.003048</td>\n",
       "      <td>-0.020496</td>\n",
       "      <td>-0.007935</td>\n",
       "      <td>-0.011565</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035638</td>\n",
       "      <td>-0.010797</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>-0.005289</td>\n",
       "      <td>-0.018250</td>\n",
       "      <td>-0.013763</td>\n",
       "      <td>-0.007718</td>\n",
       "      <td>-0.005751</td>\n",
       "      <td>-0.014877</td>\n",
       "      <td>0.014877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_TX</th>\n",
       "      <td>0.026023</td>\n",
       "      <td>0.026057</td>\n",
       "      <td>0.025973</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>0.028221</td>\n",
       "      <td>0.042691</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.230466</td>\n",
       "      <td>0.033514</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026446</td>\n",
       "      <td>-0.051045</td>\n",
       "      <td>-0.012954</td>\n",
       "      <td>-0.044699</td>\n",
       "      <td>-0.033710</td>\n",
       "      <td>-0.018905</td>\n",
       "      <td>-0.014087</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>0.005155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_UT</th>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>-0.001156</td>\n",
       "      <td>-0.005789</td>\n",
       "      <td>0.004847</td>\n",
       "      <td>0.080285</td>\n",
       "      <td>0.008002</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026446</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015466</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>-0.013543</td>\n",
       "      <td>-0.010213</td>\n",
       "      <td>-0.005728</td>\n",
       "      <td>-0.004268</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>0.001734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_VA</th>\n",
       "      <td>0.012829</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>0.012302</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>0.010473</td>\n",
       "      <td>0.026027</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>-0.114895</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051045</td>\n",
       "      <td>-0.015466</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007575</td>\n",
       "      <td>-0.026140</td>\n",
       "      <td>-0.019714</td>\n",
       "      <td>-0.011055</td>\n",
       "      <td>-0.008238</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>-0.003446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_VT</th>\n",
       "      <td>-0.005485</td>\n",
       "      <td>-0.005447</td>\n",
       "      <td>-0.005353</td>\n",
       "      <td>-0.001682</td>\n",
       "      <td>-0.005761</td>\n",
       "      <td>-0.011048</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012954</td>\n",
       "      <td>-0.003925</td>\n",
       "      <td>-0.007575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006633</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>-0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_WA</th>\n",
       "      <td>0.002654</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.014353</td>\n",
       "      <td>0.166892</td>\n",
       "      <td>-0.003084</td>\n",
       "      <td>-0.008026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044699</td>\n",
       "      <td>-0.013543</td>\n",
       "      <td>-0.026140</td>\n",
       "      <td>-0.006633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017263</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>-0.007214</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>-0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_WI</th>\n",
       "      <td>-0.007797</td>\n",
       "      <td>-0.007744</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>-0.001286</td>\n",
       "      <td>-0.008420</td>\n",
       "      <td>-0.022968</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>0.037495</td>\n",
       "      <td>0.009850</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033710</td>\n",
       "      <td>-0.010213</td>\n",
       "      <td>-0.019714</td>\n",
       "      <td>-0.005003</td>\n",
       "      <td>-0.017263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007301</td>\n",
       "      <td>-0.005440</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>0.002210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_WV</th>\n",
       "      <td>-0.002169</td>\n",
       "      <td>-0.002122</td>\n",
       "      <td>-0.001838</td>\n",
       "      <td>0.007475</td>\n",
       "      <td>-0.004346</td>\n",
       "      <td>-0.013172</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>-0.033409</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018905</td>\n",
       "      <td>-0.005728</td>\n",
       "      <td>-0.011055</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>-0.009681</td>\n",
       "      <td>-0.007301</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003051</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>-0.003592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addr_state_WY</th>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.003110</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.041353</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>-0.000282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014087</td>\n",
       "      <td>-0.004268</td>\n",
       "      <td>-0.008238</td>\n",
       "      <td>-0.002091</td>\n",
       "      <td>-0.007214</td>\n",
       "      <td>-0.005440</td>\n",
       "      <td>-0.003051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>-0.001019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <td>-0.070802</td>\n",
       "      <td>-0.072154</td>\n",
       "      <td>-0.077645</td>\n",
       "      <td>-0.104144</td>\n",
       "      <td>-0.037874</td>\n",
       "      <td>-0.072128</td>\n",
       "      <td>0.016898</td>\n",
       "      <td>-0.004527</td>\n",
       "      <td>-0.033031</td>\n",
       "      <td>-0.018312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005155</td>\n",
       "      <td>-0.001734</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <td>0.070802</td>\n",
       "      <td>0.072154</td>\n",
       "      <td>0.077645</td>\n",
       "      <td>0.104144</td>\n",
       "      <td>0.037874</td>\n",
       "      <td>0.072128</td>\n",
       "      <td>-0.016898</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.033031</td>\n",
       "      <td>0.018312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.001734</td>\n",
       "      <td>-0.003446</td>\n",
       "      <td>-0.000350</td>\n",
       "      <td>-0.001916</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>-0.003592</td>\n",
       "      <td>-0.001019</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             loan_amnt  funded_amnt  funded_amnt_inv  \\\n",
       "loan_amnt                     1.000000     0.999485         0.991096   \n",
       "funded_amnt                   0.999485     1.000000         0.992095   \n",
       "funded_amnt_inv               0.991096     0.992095         1.000000   \n",
       "term                          0.390193     0.389246         0.387604   \n",
       "installment                   0.974018     0.974854         0.966986   \n",
       "annual_inc                    0.477400     0.477231         0.473318   \n",
       "loan_status                  -0.066544    -0.066608        -0.065480   \n",
       "zip_code                     -0.009669    -0.009558        -0.008968   \n",
       "dti                           0.056308     0.056982         0.060703   \n",
       "delinq_2yrs                   0.003837     0.004144         0.004916   \n",
       "inq_last_6mths               -0.020323    -0.020577        -0.022398   \n",
       "mths_since_last_delinq       -0.014778    -0.014335        -0.013158   \n",
       "mths_since_last_record       -0.092025    -0.091660        -0.089168   \n",
       "open_acc                      0.211634     0.212034         0.212126   \n",
       "pub_rec                      -0.084330    -0.083944        -0.081429   \n",
       "revol_bal                     0.417355     0.417309         0.414715   \n",
       "revol_util                    0.114590     0.115009         0.116574   \n",
       "total_acc                     0.233905     0.233907         0.233793   \n",
       "collections_12_mths_ex_med   -0.014017    -0.013868        -0.013079   \n",
       "mths_since_last_major_derog   0.066331     0.069076         0.080548   \n",
       "acc_now_delinq                0.003039     0.003130         0.003473   \n",
       "tot_coll_amt                 -0.056732    -0.056263        -0.053595   \n",
       "tot_cur_bal                   0.259181     0.262826         0.275526   \n",
       "open_acc_6m                  -0.010461    -0.009977        -0.007788   \n",
       "open_act_il                   0.008038     0.008624         0.011046   \n",
       "open_il_12m                  -0.007968    -0.007516        -0.005486   \n",
       "open_il_24m                   0.001576     0.002131         0.004495   \n",
       "mths_since_rcnt_il           -0.001046    -0.000422         0.002275   \n",
       "total_bal_il                  0.017577     0.018227         0.020821   \n",
       "il_util                      -0.007202    -0.006567        -0.003754   \n",
       "...                                ...          ...              ...   \n",
       "addr_state_MN                -0.005582    -0.005597        -0.005361   \n",
       "addr_state_MO                -0.006830    -0.006835        -0.006559   \n",
       "addr_state_MS                -0.001675    -0.001615        -0.001555   \n",
       "addr_state_MT                -0.005340    -0.005309        -0.005121   \n",
       "addr_state_NC                -0.005754    -0.005707        -0.005446   \n",
       "addr_state_ND                 0.001564     0.001601         0.001739   \n",
       "addr_state_NE                -0.004595    -0.004542        -0.004615   \n",
       "addr_state_NH                 0.000324     0.000286         0.000245   \n",
       "addr_state_NJ                 0.015108     0.014905         0.014354   \n",
       "addr_state_NM                -0.000799    -0.000819        -0.000875   \n",
       "addr_state_NV                -0.010230    -0.010201        -0.009804   \n",
       "addr_state_NY                -0.003521    -0.003567        -0.003917   \n",
       "addr_state_OH                -0.015240    -0.015183        -0.014860   \n",
       "addr_state_OK                -0.001954    -0.001918        -0.001747   \n",
       "addr_state_OR                -0.011694    -0.011739        -0.011422   \n",
       "addr_state_PA                -0.008037    -0.008031        -0.007624   \n",
       "addr_state_RI                -0.004595    -0.004659        -0.004468   \n",
       "addr_state_SC                -0.003198    -0.003201        -0.003223   \n",
       "addr_state_SD                -0.004340    -0.004320        -0.004168   \n",
       "addr_state_TN                -0.002756    -0.002632        -0.002269   \n",
       "addr_state_TX                 0.026023     0.026057         0.025973   \n",
       "addr_state_UT                 0.000512     0.000545         0.000436   \n",
       "addr_state_VA                 0.012829     0.012826         0.012302   \n",
       "addr_state_VT                -0.005485    -0.005447        -0.005353   \n",
       "addr_state_WA                 0.002654     0.002737         0.002655   \n",
       "addr_state_WI                -0.007797    -0.007744        -0.007568   \n",
       "addr_state_WV                -0.002169    -0.002122        -0.001838   \n",
       "addr_state_WY                 0.003321     0.003354         0.003491   \n",
       "initial_list_status_f        -0.070802    -0.072154        -0.077645   \n",
       "initial_list_status_w         0.070802     0.072154         0.077645   \n",
       "\n",
       "                                 term  installment  annual_inc  loan_status  \\\n",
       "loan_amnt                    0.390193     0.974018    0.477400    -0.066544   \n",
       "funded_amnt                  0.389246     0.974854    0.477231    -0.066608   \n",
       "funded_amnt_inv              0.387604     0.966986    0.473318    -0.065480   \n",
       "term                         1.000000     0.202143    0.119207    -0.177213   \n",
       "installment                  0.202143     1.000000    0.463165    -0.054160   \n",
       "annual_inc                   0.119207     0.463165    1.000000     0.073179   \n",
       "loan_status                 -0.177213    -0.054160    0.073179     1.000000   \n",
       "zip_code                    -0.014858    -0.006072   -0.018996     0.007509   \n",
       "dti                          0.077999     0.059020   -0.206780    -0.112951   \n",
       "delinq_2yrs                 -0.003978     0.012874    0.082058    -0.021707   \n",
       "inq_last_6mths               0.018652     0.000333    0.047342    -0.059518   \n",
       "mths_since_last_delinq      -0.003854    -0.006111    0.066305    -0.009994   \n",
       "mths_since_last_record      -0.019571    -0.083766   -0.052798    -0.026642   \n",
       "open_acc                     0.083154     0.203303    0.238623    -0.031532   \n",
       "pub_rec                     -0.023251    -0.074744   -0.031704    -0.027696   \n",
       "revol_bal                    0.125793     0.408449    0.370988     0.003639   \n",
       "revol_util                   0.054926     0.134621    0.039400    -0.068937   \n",
       "total_acc                    0.108196     0.213998    0.323543     0.016822   \n",
       "collections_12_mths_ex_med  -0.004093    -0.011711   -0.003739    -0.019671   \n",
       "mths_since_last_major_derog -0.002716     0.072786   -0.020793     0.018716   \n",
       "acc_now_delinq               0.002878     0.005226    0.021702    -0.007299   \n",
       "tot_coll_amt                -0.024417    -0.048988   -0.024507    -0.022856   \n",
       "tot_cur_bal                  0.090575     0.252833    0.353728     0.012812   \n",
       "open_acc_6m                  0.002938    -0.000447    0.059917    -0.034417   \n",
       "open_act_il                  0.011019     0.011843    0.093968    -0.024757   \n",
       "open_il_12m                  0.011806     0.001592    0.083813    -0.033189   \n",
       "open_il_24m                  0.015047     0.008620    0.096779    -0.028595   \n",
       "mths_since_rcnt_il          -0.008662     0.000797    0.033931    -0.007973   \n",
       "total_bal_il                 0.012121     0.021666    0.106103    -0.022399   \n",
       "il_util                      0.005044    -0.002151    0.065138    -0.025927   \n",
       "...                               ...          ...         ...          ...   \n",
       "addr_state_MN                0.001851    -0.006600   -0.016137    -0.001030   \n",
       "addr_state_MO                0.003161    -0.008117   -0.023071    -0.003883   \n",
       "addr_state_MS                0.000543    -0.001434   -0.009153    -0.010460   \n",
       "addr_state_MT                0.000066    -0.005811   -0.016548     0.003334   \n",
       "addr_state_NC                0.011976    -0.008429   -0.016530    -0.002657   \n",
       "addr_state_ND               -0.000600     0.002103   -0.000755    -0.001589   \n",
       "addr_state_NE                0.002908    -0.005212   -0.008733    -0.006863   \n",
       "addr_state_NH               -0.000745    -0.000212    0.001880     0.009145   \n",
       "addr_state_NJ                0.002995     0.014718    0.041771    -0.005705   \n",
       "addr_state_NM               -0.002580    -0.000159   -0.007492    -0.001464   \n",
       "addr_state_NV               -0.007703    -0.008155   -0.014333    -0.009655   \n",
       "addr_state_NY               -0.009874    -0.000572    0.013225    -0.009465   \n",
       "addr_state_OH                0.008254    -0.017845   -0.035246    -0.009353   \n",
       "addr_state_OK                0.001166    -0.002066   -0.009513    -0.009442   \n",
       "addr_state_OR               -0.004886    -0.011681   -0.022823     0.012266   \n",
       "addr_state_PA                0.012666    -0.011408   -0.018623    -0.002804   \n",
       "addr_state_RI                0.001517    -0.005246   -0.004308     0.002329   \n",
       "addr_state_SC                0.003081    -0.003919   -0.012449     0.006433   \n",
       "addr_state_SD               -0.000481    -0.004327   -0.015648    -0.001917   \n",
       "addr_state_TN                0.004538    -0.003048   -0.020496    -0.007935   \n",
       "addr_state_TX               -0.005291     0.028221    0.042691     0.003644   \n",
       "addr_state_UT                0.006614    -0.001156   -0.005789     0.004847   \n",
       "addr_state_VA                0.011938     0.010473    0.026027     0.000103   \n",
       "addr_state_VT               -0.001682    -0.005761   -0.011048     0.005290   \n",
       "addr_state_WA               -0.002079     0.003707    0.001977     0.014353   \n",
       "addr_state_WI               -0.001286    -0.008420   -0.022968     0.007166   \n",
       "addr_state_WV                0.007475    -0.004346   -0.013172     0.001971   \n",
       "addr_state_WY                0.001953     0.003110   -0.002067     0.002565   \n",
       "initial_list_status_f       -0.104144    -0.037874   -0.072128     0.016898   \n",
       "initial_list_status_w        0.104144     0.037874    0.072128    -0.016898   \n",
       "\n",
       "                             zip_code       dti  delinq_2yrs  \\\n",
       "loan_amnt                   -0.009669  0.056308     0.003837   \n",
       "funded_amnt                 -0.009558  0.056982     0.004144   \n",
       "funded_amnt_inv             -0.008968  0.060703     0.004916   \n",
       "term                        -0.014858  0.077999    -0.003978   \n",
       "installment                 -0.006072  0.059020     0.012874   \n",
       "annual_inc                  -0.018996 -0.206780     0.082058   \n",
       "loan_status                  0.007509 -0.112951    -0.021707   \n",
       "zip_code                     1.000000  0.030912    -0.026868   \n",
       "dti                          0.030912  1.000000    -0.003484   \n",
       "delinq_2yrs                 -0.026868 -0.003484     1.000000   \n",
       "inq_last_6mths               0.007723  0.001506     0.023441   \n",
       "mths_since_last_delinq       0.002409 -0.012592     0.149356   \n",
       "mths_since_last_record       0.018135 -0.035089    -0.035875   \n",
       "open_acc                    -0.035427  0.343216     0.061422   \n",
       "pub_rec                      0.010456 -0.044163    -0.025450   \n",
       "revol_bal                   -0.020847  0.280467    -0.059159   \n",
       "revol_util                   0.012509  0.247784    -0.011658   \n",
       "total_acc                   -0.004780  0.260733     0.135193   \n",
       "collections_12_mths_ex_med   0.000739 -0.000011     0.074574   \n",
       "mths_since_last_major_derog  0.000080  0.071132    -0.197962   \n",
       "acc_now_delinq              -0.005468  0.006968     0.142698   \n",
       "tot_coll_amt                 0.040848 -0.007915     0.028569   \n",
       "tot_cur_bal                  0.023292  0.183389     0.097025   \n",
       "open_acc_6m                  0.006760  0.038309     0.009201   \n",
       "open_act_il                  0.005645  0.128602     0.031718   \n",
       "open_il_12m                  0.015035  0.097372     0.005347   \n",
       "open_il_24m                  0.019036  0.112441     0.003174   \n",
       "mths_since_rcnt_il           0.003797 -0.022155     0.022352   \n",
       "total_bal_il                 0.010924  0.118214     0.025130   \n",
       "il_util                      0.007148  0.098631     0.019798   \n",
       "...                               ...       ...          ...   \n",
       "addr_state_MN                0.049545  0.007473     0.002029   \n",
       "addr_state_MO                0.068795  0.016738    -0.002437   \n",
       "addr_state_MS               -0.003238  0.015894     0.007231   \n",
       "addr_state_MT                0.024477  0.007700    -0.002616   \n",
       "addr_state_NC               -0.073651  0.009903    -0.002577   \n",
       "addr_state_ND                0.011713  0.004494     0.002096   \n",
       "addr_state_NE                0.025177  0.010432     0.004587   \n",
       "addr_state_NH               -0.166683  0.006874     0.000933   \n",
       "addr_state_NJ               -0.333219 -0.028679     0.011390   \n",
       "addr_state_NM                0.070449  0.012963    -0.000688   \n",
       "addr_state_NV                0.120347  0.003895    -0.008730   \n",
       "addr_state_NY               -0.398167 -0.061914     0.010477   \n",
       "addr_state_OH                0.017174  0.030194    -0.002125   \n",
       "addr_state_OK                0.068716  0.014112    -0.004252   \n",
       "addr_state_OR                0.124262 -0.004144    -0.004737   \n",
       "addr_state_PA               -0.174613  0.018376     0.001326   \n",
       "addr_state_RI               -0.168337 -0.002333     0.004112   \n",
       "addr_state_SC               -0.040811  0.013998     0.000749   \n",
       "addr_state_SD                0.018452  0.012674    -0.002203   \n",
       "addr_state_TN               -0.011565  0.023392     0.002450   \n",
       "addr_state_TX                0.230466  0.033514     0.001988   \n",
       "addr_state_UT                0.080285  0.008002    -0.002704   \n",
       "addr_state_VA               -0.114895  0.002882     0.003085   \n",
       "addr_state_VT               -0.088853  0.009687     0.002054   \n",
       "addr_state_WA                0.166892 -0.003084    -0.008026   \n",
       "addr_state_WI                0.037495  0.009850    -0.003746   \n",
       "addr_state_WV               -0.033409  0.014000     0.000627   \n",
       "addr_state_WY                0.041353  0.009947    -0.000282   \n",
       "initial_list_status_f       -0.004527 -0.033031    -0.018312   \n",
       "initial_list_status_w        0.004527  0.033031     0.018312   \n",
       "\n",
       "                                     ...            addr_state_TX  \\\n",
       "loan_amnt                            ...                 0.026023   \n",
       "funded_amnt                          ...                 0.026057   \n",
       "funded_amnt_inv                      ...                 0.025973   \n",
       "term                                 ...                -0.005291   \n",
       "installment                          ...                 0.028221   \n",
       "annual_inc                           ...                 0.042691   \n",
       "loan_status                          ...                 0.003644   \n",
       "zip_code                             ...                 0.230466   \n",
       "dti                                  ...                 0.033514   \n",
       "delinq_2yrs                          ...                 0.001988   \n",
       "inq_last_6mths                       ...                -0.003229   \n",
       "mths_since_last_delinq               ...                 0.009666   \n",
       "mths_since_last_record               ...                -0.049278   \n",
       "open_acc                             ...                 0.023215   \n",
       "pub_rec                              ...                -0.052377   \n",
       "revol_bal                            ...                 0.006628   \n",
       "revol_util                           ...                -0.006662   \n",
       "total_acc                            ...                 0.035534   \n",
       "collections_12_mths_ex_med           ...                 0.016442   \n",
       "mths_since_last_major_derog          ...                 0.006155   \n",
       "acc_now_delinq                       ...                 0.004020   \n",
       "tot_coll_amt                         ...                 0.050708   \n",
       "tot_cur_bal                          ...                 0.020295   \n",
       "open_acc_6m                          ...                 0.008164   \n",
       "open_act_il                          ...                 0.008886   \n",
       "open_il_12m                          ...                 0.012393   \n",
       "open_il_24m                          ...                 0.015403   \n",
       "mths_since_rcnt_il                   ...                 0.000208   \n",
       "total_bal_il                         ...                 0.011392   \n",
       "il_util                              ...                 0.004494   \n",
       "...                                  ...                      ...   \n",
       "addr_state_MN                        ...                -0.039762   \n",
       "addr_state_MO                        ...                -0.037230   \n",
       "addr_state_MS                        ...                -0.018805   \n",
       "addr_state_MT                        ...                -0.015889   \n",
       "addr_state_NC                        ...                -0.050198   \n",
       "addr_state_ND                        ...                -0.008014   \n",
       "addr_state_NE                        ...                -0.012095   \n",
       "addr_state_NH                        ...                -0.020226   \n",
       "addr_state_NJ                        ...                -0.057342   \n",
       "addr_state_NM                        ...                -0.022187   \n",
       "addr_state_NV                        ...                -0.036618   \n",
       "addr_state_NY                        ...                -0.087644   \n",
       "addr_state_OH                        ...                -0.053771   \n",
       "addr_state_OK                        ...                -0.028030   \n",
       "addr_state_OR                        ...                -0.033764   \n",
       "addr_state_PA                        ...                -0.055319   \n",
       "addr_state_RI                        ...                -0.019450   \n",
       "addr_state_SC                        ...                -0.032231   \n",
       "addr_state_SD                        ...                -0.013369   \n",
       "addr_state_TN                        ...                -0.035638   \n",
       "addr_state_TX                        ...                 1.000000   \n",
       "addr_state_UT                        ...                -0.026446   \n",
       "addr_state_VA                        ...                -0.051045   \n",
       "addr_state_VT                        ...                -0.012954   \n",
       "addr_state_WA                        ...                -0.044699   \n",
       "addr_state_WI                        ...                -0.033710   \n",
       "addr_state_WV                        ...                -0.018905   \n",
       "addr_state_WY                        ...                -0.014087   \n",
       "initial_list_status_f                ...                -0.005155   \n",
       "initial_list_status_w                ...                 0.005155   \n",
       "\n",
       "                             addr_state_UT  addr_state_VA  addr_state_VT  \\\n",
       "loan_amnt                         0.000512       0.012829      -0.005485   \n",
       "funded_amnt                       0.000545       0.012826      -0.005447   \n",
       "funded_amnt_inv                   0.000436       0.012302      -0.005353   \n",
       "term                              0.006614       0.011938      -0.001682   \n",
       "installment                      -0.001156       0.010473      -0.005761   \n",
       "annual_inc                       -0.005789       0.026027      -0.011048   \n",
       "loan_status                       0.004847       0.000103       0.005290   \n",
       "zip_code                          0.080285      -0.114895      -0.088853   \n",
       "dti                               0.008002       0.002882       0.009687   \n",
       "delinq_2yrs                      -0.002704       0.003085       0.002054   \n",
       "inq_last_6mths                   -0.008222      -0.014345       0.003135   \n",
       "mths_since_last_delinq           -0.001918       0.002795      -0.000620   \n",
       "mths_since_last_record            0.004727      -0.008800      -0.004452   \n",
       "open_acc                          0.000987       0.001219      -0.006819   \n",
       "pub_rec                           0.007235      -0.006969      -0.005323   \n",
       "revol_bal                         0.002581       0.017007      -0.000878   \n",
       "revol_util                        0.009847       0.008418       0.005368   \n",
       "total_acc                         0.008228       0.014544       0.000785   \n",
       "collections_12_mths_ex_med       -0.003822      -0.002788      -0.002203   \n",
       "mths_since_last_major_derog       0.003007      -0.004284       0.005096   \n",
       "acc_now_delinq                   -0.002030      -0.002552       0.000851   \n",
       "tot_coll_amt                      0.000899      -0.009667      -0.004162   \n",
       "tot_cur_bal                       0.015232       0.015648       0.001722   \n",
       "open_acc_6m                      -0.000303      -0.002890      -0.001944   \n",
       "open_act_il                       0.004408      -0.002448       0.000479   \n",
       "open_il_12m                       0.001963       0.001945      -0.000196   \n",
       "open_il_24m                       0.005106       0.000362      -0.000646   \n",
       "mths_since_rcnt_il                0.002496      -0.007544       0.000339   \n",
       "total_bal_il                      0.004016      -0.003337      -0.000046   \n",
       "il_util                           0.004415      -0.004476       0.000800   \n",
       "...                                    ...            ...            ...   \n",
       "addr_state_MN                    -0.012047      -0.023253      -0.005901   \n",
       "addr_state_MO                    -0.011280      -0.021772      -0.005525   \n",
       "addr_state_MS                    -0.005697      -0.010997      -0.002791   \n",
       "addr_state_MT                    -0.004814      -0.009292      -0.002358   \n",
       "addr_state_NC                    -0.015209      -0.029356      -0.007450   \n",
       "addr_state_ND                    -0.002428      -0.004687      -0.001189   \n",
       "addr_state_NE                    -0.003665      -0.007073      -0.001795   \n",
       "addr_state_NH                    -0.006128      -0.011828      -0.003002   \n",
       "addr_state_NJ                    -0.017373      -0.033533      -0.008510   \n",
       "addr_state_NM                    -0.006722      -0.012975      -0.003293   \n",
       "addr_state_NV                    -0.011094      -0.021414      -0.005434   \n",
       "addr_state_NY                    -0.026554      -0.051254      -0.013007   \n",
       "addr_state_OH                    -0.016291      -0.031445      -0.007980   \n",
       "addr_state_OK                    -0.008492      -0.016392      -0.004160   \n",
       "addr_state_OR                    -0.010230      -0.019745      -0.005011   \n",
       "addr_state_PA                    -0.016761      -0.032350      -0.008210   \n",
       "addr_state_RI                    -0.005893      -0.011375      -0.002887   \n",
       "addr_state_SC                    -0.009765      -0.018849      -0.004783   \n",
       "addr_state_SD                    -0.004051      -0.007818      -0.001984   \n",
       "addr_state_TN                    -0.010797      -0.020841      -0.005289   \n",
       "addr_state_TX                    -0.026446      -0.051045      -0.012954   \n",
       "addr_state_UT                     1.000000      -0.015466      -0.003925   \n",
       "addr_state_VA                    -0.015466       1.000000      -0.007575   \n",
       "addr_state_VT                    -0.003925      -0.007575       1.000000   \n",
       "addr_state_WA                    -0.013543      -0.026140      -0.006633   \n",
       "addr_state_WI                    -0.010213      -0.019714      -0.005003   \n",
       "addr_state_WV                    -0.005728      -0.011055      -0.002806   \n",
       "addr_state_WY                    -0.004268      -0.008238      -0.002091   \n",
       "initial_list_status_f            -0.001734       0.003446       0.000350   \n",
       "initial_list_status_w             0.001734      -0.003446      -0.000350   \n",
       "\n",
       "                             addr_state_WA  addr_state_WI  addr_state_WV  \\\n",
       "loan_amnt                         0.002654      -0.007797      -0.002169   \n",
       "funded_amnt                       0.002737      -0.007744      -0.002122   \n",
       "funded_amnt_inv                   0.002655      -0.007568      -0.001838   \n",
       "term                             -0.002079      -0.001286       0.007475   \n",
       "installment                       0.003707      -0.008420      -0.004346   \n",
       "annual_inc                        0.001977      -0.022968      -0.013172   \n",
       "loan_status                       0.014353       0.007166       0.001971   \n",
       "zip_code                          0.166892       0.037495      -0.033409   \n",
       "dti                              -0.003084       0.009850       0.014000   \n",
       "delinq_2yrs                      -0.008026      -0.003746       0.000627   \n",
       "inq_last_6mths                   -0.001528       0.025676      -0.001120   \n",
       "mths_since_last_delinq           -0.004514      -0.003412      -0.003506   \n",
       "mths_since_last_record            0.001709       0.011081       0.005124   \n",
       "open_acc                         -0.019349       0.002299      -0.001011   \n",
       "pub_rec                          -0.001113       0.011187       0.007512   \n",
       "revol_bal                         0.010766       0.001429      -0.003951   \n",
       "revol_util                        0.019187       0.003865      -0.000338   \n",
       "total_acc                        -0.013356       0.016553       0.007634   \n",
       "collections_12_mths_ex_med       -0.001233      -0.005726      -0.003231   \n",
       "mths_since_last_major_derog       0.006124       0.004827       0.005823   \n",
       "acc_now_delinq                   -0.002795      -0.002558       0.000345   \n",
       "tot_coll_amt                     -0.004537       0.006103       0.004773   \n",
       "tot_cur_bal                       0.010332       0.003225       0.000686   \n",
       "open_acc_6m                      -0.004861       0.000457      -0.012886   \n",
       "open_act_il                      -0.002990      -0.000202      -0.015043   \n",
       "open_il_12m                      -0.002597       0.000596      -0.012205   \n",
       "open_il_24m                      -0.002010       0.001745      -0.014250   \n",
       "mths_since_rcnt_il               -0.002896      -0.001060      -0.016605   \n",
       "total_bal_il                     -0.002538      -0.000974      -0.016872   \n",
       "il_util                          -0.003040       0.000498      -0.016732   \n",
       "...                                    ...            ...            ...   \n",
       "addr_state_MN                    -0.020362      -0.015356      -0.008612   \n",
       "addr_state_MO                    -0.019065      -0.014378      -0.008063   \n",
       "addr_state_MS                    -0.009630      -0.007262      -0.004073   \n",
       "addr_state_MT                    -0.008137      -0.006136      -0.003441   \n",
       "addr_state_NC                    -0.025706      -0.019386      -0.010872   \n",
       "addr_state_ND                    -0.004104      -0.003095      -0.001736   \n",
       "addr_state_NE                    -0.006194      -0.004671      -0.002620   \n",
       "addr_state_NH                    -0.010358      -0.007811      -0.004381   \n",
       "addr_state_NJ                    -0.029364      -0.022145      -0.012419   \n",
       "addr_state_NM                    -0.011362      -0.008569      -0.004805   \n",
       "addr_state_NV                    -0.018751      -0.014142      -0.007931   \n",
       "addr_state_NY                    -0.044881      -0.033848      -0.018982   \n",
       "addr_state_OH                    -0.027535      -0.020766      -0.011646   \n",
       "addr_state_OK                    -0.014354      -0.010825      -0.006071   \n",
       "addr_state_OR                    -0.017290      -0.013040      -0.007313   \n",
       "addr_state_PA                    -0.028328      -0.021364      -0.011981   \n",
       "addr_state_RI                    -0.009960      -0.007512      -0.004213   \n",
       "addr_state_SC                    -0.016505      -0.012448      -0.006981   \n",
       "addr_state_SD                    -0.006846      -0.005163      -0.002895   \n",
       "addr_state_TN                    -0.018250      -0.013763      -0.007718   \n",
       "addr_state_TX                    -0.044699      -0.033710      -0.018905   \n",
       "addr_state_UT                    -0.013543      -0.010213      -0.005728   \n",
       "addr_state_VA                    -0.026140      -0.019714      -0.011055   \n",
       "addr_state_VT                    -0.006633      -0.005003      -0.002806   \n",
       "addr_state_WA                     1.000000      -0.017263      -0.009681   \n",
       "addr_state_WI                    -0.017263       1.000000      -0.007301   \n",
       "addr_state_WV                    -0.009681      -0.007301       1.000000   \n",
       "addr_state_WY                    -0.007214      -0.005440      -0.003051   \n",
       "initial_list_status_f             0.001916      -0.002210       0.003592   \n",
       "initial_list_status_w            -0.001916       0.002210      -0.003592   \n",
       "\n",
       "                             addr_state_WY  initial_list_status_f  \\\n",
       "loan_amnt                         0.003321              -0.070802   \n",
       "funded_amnt                       0.003354              -0.072154   \n",
       "funded_amnt_inv                   0.003491              -0.077645   \n",
       "term                              0.001953              -0.104144   \n",
       "installment                       0.003110              -0.037874   \n",
       "annual_inc                       -0.002067              -0.072128   \n",
       "loan_status                       0.002565               0.016898   \n",
       "zip_code                          0.041353              -0.004527   \n",
       "dti                               0.009947              -0.033031   \n",
       "delinq_2yrs                      -0.000282              -0.018312   \n",
       "inq_last_6mths                   -0.000857               0.062647   \n",
       "mths_since_last_delinq            0.000637              -0.027498   \n",
       "mths_since_last_record            0.002525              -0.037953   \n",
       "open_acc                         -0.005190              -0.060650   \n",
       "pub_rec                           0.002013              -0.040101   \n",
       "revol_bal                        -0.003940              -0.027453   \n",
       "revol_util                        0.003353               0.056269   \n",
       "total_acc                         0.006023              -0.054599   \n",
       "collections_12_mths_ex_med       -0.003086              -0.021584   \n",
       "mths_since_last_major_derog       0.005070              -0.004456   \n",
       "acc_now_delinq                    0.001834              -0.007478   \n",
       "tot_coll_amt                      0.002876              -0.048401   \n",
       "tot_cur_bal                       0.007141              -0.260173   \n",
       "open_acc_6m                      -0.003378              -0.178805   \n",
       "open_act_il                      -0.002733              -0.227369   \n",
       "open_il_12m                      -0.001572              -0.165045   \n",
       "open_il_24m                      -0.001778              -0.209616   \n",
       "mths_since_rcnt_il               -0.003580              -0.249248   \n",
       "total_bal_il                     -0.003197              -0.252238   \n",
       "il_util                          -0.003933              -0.247186   \n",
       "...                                    ...                    ...   \n",
       "addr_state_MN                    -0.006417              -0.002408   \n",
       "addr_state_MO                    -0.006008              -0.000413   \n",
       "addr_state_MS                    -0.003035              -0.016075   \n",
       "addr_state_MT                    -0.002564              -0.000408   \n",
       "addr_state_NC                    -0.008101              -0.003035   \n",
       "addr_state_ND                    -0.001293              -0.013773   \n",
       "addr_state_NE                    -0.001952              -0.017507   \n",
       "addr_state_NH                    -0.003264              -0.000718   \n",
       "addr_state_NJ                    -0.009254               0.007361   \n",
       "addr_state_NM                    -0.003581               0.000050   \n",
       "addr_state_NV                    -0.005909              -0.001122   \n",
       "addr_state_NY                    -0.014144               0.010405   \n",
       "addr_state_OH                    -0.008678              -0.002595   \n",
       "addr_state_OK                    -0.004523               0.001710   \n",
       "addr_state_OR                    -0.005449               0.001762   \n",
       "addr_state_PA                    -0.008927               0.000410   \n",
       "addr_state_RI                    -0.003139              -0.000658   \n",
       "addr_state_SC                    -0.005202               0.000823   \n",
       "addr_state_SD                    -0.002158               0.000073   \n",
       "addr_state_TN                    -0.005751              -0.014877   \n",
       "addr_state_TX                    -0.014087              -0.005155   \n",
       "addr_state_UT                    -0.004268              -0.001734   \n",
       "addr_state_VA                    -0.008238               0.003446   \n",
       "addr_state_VT                    -0.002091               0.000350   \n",
       "addr_state_WA                    -0.007214               0.001916   \n",
       "addr_state_WI                    -0.005440              -0.002210   \n",
       "addr_state_WV                    -0.003051               0.003592   \n",
       "addr_state_WY                     1.000000               0.001019   \n",
       "initial_list_status_f             0.001019               1.000000   \n",
       "initial_list_status_w            -0.001019              -1.000000   \n",
       "\n",
       "                             initial_list_status_w  \n",
       "loan_amnt                                 0.070802  \n",
       "funded_amnt                               0.072154  \n",
       "funded_amnt_inv                           0.077645  \n",
       "term                                      0.104144  \n",
       "installment                               0.037874  \n",
       "annual_inc                                0.072128  \n",
       "loan_status                              -0.016898  \n",
       "zip_code                                  0.004527  \n",
       "dti                                       0.033031  \n",
       "delinq_2yrs                               0.018312  \n",
       "inq_last_6mths                           -0.062647  \n",
       "mths_since_last_delinq                    0.027498  \n",
       "mths_since_last_record                    0.037953  \n",
       "open_acc                                  0.060650  \n",
       "pub_rec                                   0.040101  \n",
       "revol_bal                                 0.027453  \n",
       "revol_util                               -0.056269  \n",
       "total_acc                                 0.054599  \n",
       "collections_12_mths_ex_med                0.021584  \n",
       "mths_since_last_major_derog               0.004456  \n",
       "acc_now_delinq                            0.007478  \n",
       "tot_coll_amt                              0.048401  \n",
       "tot_cur_bal                               0.260173  \n",
       "open_acc_6m                               0.178805  \n",
       "open_act_il                               0.227369  \n",
       "open_il_12m                               0.165045  \n",
       "open_il_24m                               0.209616  \n",
       "mths_since_rcnt_il                        0.249248  \n",
       "total_bal_il                              0.252238  \n",
       "il_util                                   0.247186  \n",
       "...                                            ...  \n",
       "addr_state_MN                             0.002408  \n",
       "addr_state_MO                             0.000413  \n",
       "addr_state_MS                             0.016075  \n",
       "addr_state_MT                             0.000408  \n",
       "addr_state_NC                             0.003035  \n",
       "addr_state_ND                             0.013773  \n",
       "addr_state_NE                             0.017507  \n",
       "addr_state_NH                             0.000718  \n",
       "addr_state_NJ                            -0.007361  \n",
       "addr_state_NM                            -0.000050  \n",
       "addr_state_NV                             0.001122  \n",
       "addr_state_NY                            -0.010405  \n",
       "addr_state_OH                             0.002595  \n",
       "addr_state_OK                            -0.001710  \n",
       "addr_state_OR                            -0.001762  \n",
       "addr_state_PA                            -0.000410  \n",
       "addr_state_RI                             0.000658  \n",
       "addr_state_SC                            -0.000823  \n",
       "addr_state_SD                            -0.000073  \n",
       "addr_state_TN                             0.014877  \n",
       "addr_state_TX                             0.005155  \n",
       "addr_state_UT                             0.001734  \n",
       "addr_state_VA                            -0.003446  \n",
       "addr_state_VT                            -0.000350  \n",
       "addr_state_WA                            -0.001916  \n",
       "addr_state_WI                             0.002210  \n",
       "addr_state_WV                            -0.003592  \n",
       "addr_state_WY                            -0.001019  \n",
       "initial_list_status_f                    -1.000000  \n",
       "initial_list_status_w                     1.000000  \n",
       "\n",
       "[208 rows x 208 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running corr() function to see how the features are correlated.\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histogram\n",
    "# for y in df.columns:\n",
    "    # plt.figure()\n",
    "    # df[y].plot.hist(bins=20, title=y)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 615832 samples.\n",
      "Testing set has 153958 samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.naive_bayes import GaussianNB\\nclf = GaussianNB()\\nresult = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\\nprint(result)\\n\\nfrom sklearn.tree import DecisionTreeClassifier\\nclf = DecisionTreeClassifier()\\nresult = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\\nprint(result)\\n\\nk_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\\nclf = GaussianNB()\\nprint(cross_val_score(clf, features, loan_status, cv=k_fold))\\n    \\n\\nk_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\\nclf = DecisionTreeClassifier()\\nprint(cross_val_score(clf, features, loan_status, cv=k_fold))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data in features and target label\n",
    "loan_status_raw = df['loan_status']\n",
    "loan_status = loan_status_raw.apply(lambda x: int(x > 0.1))\n",
    "features = df.drop('loan_status', axis=1)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "\n",
    "# Split the features and loan_status data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(learner)\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "    start = time() # Get start time\n",
    "    learner.fit(X_train, y_train)\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set,\n",
    "    #       then get predictions\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train)\n",
    "    end = time() # Get end time\n",
    "       \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # TODO: Compute accuracy\n",
    "    results['acc_train'] = accuracy_score(y_train, learner.predict(X_train))\n",
    "        \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['acc_test'] = accuracy_score(y_test, learner.predict(X_test))\n",
    "    \n",
    "    # TODO: Compute F-score\n",
    "    results['f_train'] = fbeta_score(y_train, learner.predict(X_train), beta=0.5)\n",
    "        \n",
    "    # TODO: Compute F-score on the test set\n",
    "    results['f_test'] = fbeta_score(y_test, learner.predict(X_test), beta=0.5)\n",
    "       \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "        \n",
    "    # Return the results\n",
    "    return results\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "clf = GaussianNB()\n",
    "print(cross_val_score(clf, features, loan_status, cv=k_fold))\n",
    "    \n",
    "\n",
    "k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "print(cross_val_score(clf, features, loan_status, cv=k_fold))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"-- Applying more strict rule to find outliers -- \")\\nfor feature in df.keys():\\n    \\n    # TODO: Calculate Q1 (25th percentile of the data) for the given feature\\n    Q1 = np.percentile(df[feature], 25)\\n    \\n    # TODO: Calculate Q3 (75th percentile of the data) for the given feature\\n    Q3 = np.percentile(df[feature], 75)\\n    \\n    # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\\n    step = 3*(Q3-Q1)\\n    \\n    # Display the outliers\\n    print(\"Data points considered outliers for the feature \\'{}\\':\".format(feature))\\n    display(df[~((df[feature] >= Q1 - step) & (df[feature] <= Q3 + step))])\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"-- Applying more strict rule to find outliers -- \")\n",
    "for feature in df.keys():\n",
    "    \n",
    "    # TODO: Calculate Q1 (25th percentile of the data) for the given feature\n",
    "    Q1 = np.percentile(df[feature], 25)\n",
    "    \n",
    "    # TODO: Calculate Q3 (75th percentile of the data) for the given feature\n",
    "    Q3 = np.percentile(df[feature], 75)\n",
    "    \n",
    "    # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
    "    step = 3*(Q3-Q1)\n",
    "    \n",
    "    # Display the outliers\n",
    "    print(\"Data points considered outliers for the feature '{}':\".format(feature))\n",
    "    display(df[~((df[feature] >= Q1 - step) & (df[feature] <= Q3 + step))])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/anilrajgr/udacity-machine-learning/blob/master/projects/customer_segments/customer_segments.ipynb\n",
    "# Apply PCA by fitting the data with the same number of dimensions as features\n",
    "from sklearn import decomposition\n",
    "\n",
    "# from vpython import *\n",
    "\n",
    "pca = decomposition.PCA(n_components=10)\n",
    "pca.fit(features)\n",
    "df_pca = pca.transform(features)\n",
    "\n",
    "# Generate PCA results plot\n",
    "# pca_results = vs.pca_results(features, pca)\n",
    "\n",
    "# print(pca_results['Explained Variance'].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5067649  0.16131948 0.08431858 0.05719553 0.03294425 0.02574678\n",
      " 0.01914838 0.01610658 0.01451966 0.01122624]\n",
      "[0.5067649  0.66808438 0.75240296 0.80959849 0.84254274 0.86828952\n",
      " 0.8874379  0.90354448 0.91806414 0.92929037]\n",
      "[18637.39072587 10515.38679082  7602.27333931  6261.27651078\n",
      "  4751.94752026  4200.90954065  3622.82891913  3322.64167141\n",
      "  3154.71460775  2773.95184308]\n"
     ]
    }
   ],
   "source": [
    "print(pca.explained_variance_ratio_)\n",
    "print(np.cumsum(pca.explained_variance_ratio_))\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe8f0e15c18>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(pca.explained_variance_ratio_).plot.bar()\n",
    "pd.Series(np.cumsum(pca.explained_variance_ratio_)).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 12.46983991,  -6.55456452,  -8.72809831, ...,  -2.73953901,\n",
       "         -2.65822229,  -0.67899332],\n",
       "       [-65.27065182,   6.3824733 ,  -7.30861801, ...,  -3.62688931,\n",
       "          0.63313722,   2.16293799],\n",
       "       [ 16.04387375,  -8.36548683,  -6.24562892, ...,   1.49698974,\n",
       "         -1.29312465,  -3.83380301],\n",
       "       ...,\n",
       "       [ 10.84425189,  24.1418814 ,   4.77704498, ...,  -0.56878723,\n",
       "          2.69335028,  -1.51163186],\n",
       "       [ 48.0798472 ,  23.83093534,   2.74081456, ...,   2.37630422,\n",
       "         -2.50334283,   6.86678563],\n",
       "       [-11.94604686,  -4.1518861 ,   1.94048067, ...,  -2.74786595,\n",
       "          5.24968345,  -4.20516888]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 615832 samples.\n",
      "Testing set has 153958 samples.\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB trained on 615832 samples.\n",
      "{'train_time': 0.1892251968383789, 'pred_time': 0.20077919960021973, 'acc_train': 0.8073825328985827, 'acc_test': 0.8078631834656205, 'f_train': 0.8398073849291176, 'f_test': 0.840226435186374}\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "DecisionTreeClassifier trained on 615832 samples.\n",
      "{'train_time': 17.872413158416748, 'pred_time': 0.3335249423980713, 'acc_train': 1.0, 'acc_test': 0.6905779498304733, 'f_train': 1.0, 'f_test': 0.8116333569371512}\n",
      "[0.80786318 0.80666805 0.80767482 0.80755791 0.8075709 ]\n",
      "[0.69161719 0.69066239 0.69126645 0.69130542 0.69142234]\n"
     ]
    }
   ],
   "source": [
    "# Split the features (df_pca) and loan_status data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pca, loan_status, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "clf = GaussianNB()\n",
    "print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\n",
    "    \n",
    "\n",
    "k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "clf = DecisionTreeClassifier()\n",
    "print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor pca_comp in range(1,26):\\n    print(\"PCA component size: \" + str(pca_comp))\\n    pca = decomposition.PCA(n_components=pca_comp)\\n    pca.fit(features)\\n    df_pca = pca.transform(features)\\n    X_train, X_test, y_train, y_test = train_test_split(df_pca, loan_status, test_size = 0.2, random_state = 0)\\n    \\n    k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\\n    clf = GaussianNB()\\n    print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\\n    \\n    k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\\n    clf = DecisionTreeClassifier()\\n    print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for pca_comp in range(1,26):\n",
    "    print(\"PCA component size: \" + str(pca_comp))\n",
    "    pca = decomposition.PCA(n_components=pca_comp)\n",
    "    pca.fit(features)\n",
    "    df_pca = pca.transform(features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_pca, loan_status, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "    clf = GaussianNB()\n",
    "    print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\n",
    "    \n",
    "    k_fold = KFold(len(loan_status), n_folds=5, shuffle=True, random_state=0)\n",
    "    clf = DecisionTreeClassifier()\n",
    "    print(cross_val_score(clf, df_pca, loan_status, cv=k_fold))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(769790, 10)\n",
      "(769790, 208)\n",
      "(769790, 207)\n",
      "(769790,)\n"
     ]
    }
   ],
   "source": [
    "print(df_pca.shape)\n",
    "print(df.shape)\n",
    "# features = features[0:95]\n",
    "# loan_status = loan_status[0:95]\n",
    "print(features.shape)\n",
    "print(loan_status.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data\n",
      "=============\n",
      "(769790, 207)\n",
      "XGBoost\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 615832 samples.\n",
      "{'train_time': 273.7087504863739, 'pred_time': 4.388766288757324, 'acc_train': 0.848625923953286, 'acc_test': 0.8481793735953962, 'f_train': 0.877928251001055, 'f_test': 0.8775348027423189}\n",
      "-----------------------------------\n",
      "Decision Tree\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "DecisionTreeClassifier trained on 615832 samples.\n",
      "{'train_time': 11.388459920883179, 'pred_time': 0.38187479972839355, 'acc_train': 0.8347195338988556, 'acc_test': 0.8338183140856598, 'f_train': 0.8735138626721308, 'f_test': 0.8728762797972536}\n",
      "-----------------------------------\n",
      "Random Forest\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "RandomForestClassifier trained on 615832 samples.\n",
      "{'train_time': 1.3620502948760986, 'pred_time': 0.8454875946044922, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "Neural Net\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "MLPClassifier trained on 615832 samples.\n",
      "{'train_time': 130.09251832962036, 'pred_time': 8.788004636764526, 'acc_train': 0.810022863378324, 'acc_test': 0.8106106860312553, 'f_train': 0.8429408284567822, 'f_test': 0.84336348394109}\n",
      "-----------------------------------\n",
      "AdaBoost\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "AdaBoostClassifier trained on 615832 samples.\n",
      "{'train_time': 114.49720454216003, 'pred_time': 6.846264839172363, 'acc_train': 0.8319898933475364, 'acc_test': 0.830836981514439, 'f_train': 0.8676524880554248, 'f_test': 0.866917350579005}\n",
      "-----------------------------------\n",
      "Naive Bayes\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB trained on 615832 samples.\n",
      "{'train_time': 2.338545322418213, 'pred_time': 2.913602828979492, 'acc_train': 0.696707868379688, 'acc_test': 0.6979565855622962, 'f_train': 0.8374139063372146, 'f_test': 0.8381986507744102}\n",
      "-----------------------------------\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticDiscriminantAnalysis trained on 615832 samples.\n",
      "{'train_time': 17.64940857887268, 'pred_time': 6.382497072219849, 'acc_train': 0.5545554631782694, 'acc_test': 0.5551124332610192, 'f_train': 0.7616845459479327, 'f_test': 0.7619965387905216}\n",
      "-----------------------------------\n",
      "PCA data\n",
      "=============\n",
      "PCA component size: 1\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 615832 samples.\n",
      "{'train_time': 12.907331943511963, 'pred_time': 2.0308330059051514, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "DecisionTreeClassifier trained on 615832 samples.\n",
      "{'train_time': 0.6030781269073486, 'pred_time': 0.03420734405517578, 'acc_train': 0.8074718429701607, 'acc_test': 0.8079021551332182, 'f_train': 0.8398076830188118, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "RandomForestClassifier trained on 615832 samples.\n",
      "{'train_time': 4.2026519775390625, 'pred_time': 0.5144689083099365, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "MLPClassifier trained on 615832 samples.\n",
      "{'train_time': 13.960830450057983, 'pred_time': 0.7337024211883545, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "AdaBoostClassifier trained on 615832 samples.\n",
      "{'train_time': 9.310431957244873, 'pred_time': 2.949209451675415, 'acc_train': 0.807460476233778, 'acc_test': 0.8078956598552852, 'f_train': 0.8398003208188749, 'f_test': 0.8401793542652027}\n",
      "-----------------------------------\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB trained on 615832 samples.\n",
      "{'train_time': 0.028026819229125977, 'pred_time': 0.019958019256591797, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis trained on 615832 samples.\n",
      "{'train_time': 0.039576053619384766, 'pred_time': 0.021703481674194336, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "PCA component size: 2\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 615832 samples.\n",
      "{'train_time': 17.529640436172485, 'pred_time': 2.1811327934265137, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "DecisionTreeClassifier trained on 615832 samples.\n",
      "{'train_time': 0.9235944747924805, 'pred_time': 0.03514695167541504, 'acc_train': 0.8074588524142948, 'acc_test': 0.8079021551332182, 'f_train': 0.8397974448899658, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "RandomForestClassifier trained on 615832 samples.\n",
      "{'train_time': 3.8425581455230713, 'pred_time': 0.519752025604248, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "MLPClassifier trained on 615832 samples.\n",
      "{'train_time': 17.796229362487793, 'pred_time': 1.4105899333953857, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "AdaBoostClassifier trained on 615832 samples.\n",
      "{'train_time': 14.433330059051514, 'pred_time': 2.9874980449676514, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB trained on 615832 samples.\n",
      "{'train_time': 0.09282994270324707, 'pred_time': 0.06884241104125977, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis trained on 615832 samples.\n",
      "{'train_time': 0.06534266471862793, 'pred_time': 0.06316208839416504, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "PCA component size: 3\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 615832 samples.\n",
      "{'train_time': 22.586288690567017, 'pred_time': 2.132150650024414, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "DecisionTreeClassifier trained on 615832 samples.\n",
      "{'train_time': 1.3756062984466553, 'pred_time': 0.0391697883605957, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "RandomForestClassifier trained on 615832 samples.\n",
      "{'train_time': 3.6991543769836426, 'pred_time': 0.5463252067565918, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "MLPClassifier trained on 615832 samples.\n",
      "{'train_time': 13.745409488677979, 'pred_time': 1.617872714996338, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "AdaBoostClassifier trained on 615832 samples.\n",
      "{'train_time': 18.745909929275513, 'pred_time': 3.02945613861084, 'acc_train': 0.8074539809558451, 'acc_test': 0.8078956598552852, 'f_train': 0.8397946213935711, 'f_test': 0.8401793542652027}\n",
      "-----------------------------------\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB trained on 615832 samples.\n",
      "{'train_time': 0.09948086738586426, 'pred_time': 0.07936644554138184, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis trained on 615832 samples.\n",
      "{'train_time': 0.07803058624267578, 'pred_time': 0.07502388954162598, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "PCA component size: 4\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 615832 samples.\n",
      "{'train_time': 28.096595287322998, 'pred_time': 2.079728364944458, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "DecisionTreeClassifier trained on 615832 samples.\n",
      "{'train_time': 1.9280765056610107, 'pred_time': 0.04021263122558594, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "RandomForestClassifier trained on 615832 samples.\n",
      "{'train_time': 4.067602872848511, 'pred_time': 0.5436885356903076, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "MLPClassifier trained on 615832 samples.\n",
      "{'train_time': 18.260048389434814, 'pred_time': 2.397339344024658, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "AdaBoostClassifier trained on 615832 samples.\n",
      "{'train_time': 24.486289501190186, 'pred_time': 3.059351921081543, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB trained on 615832 samples.\n",
      "{'train_time': 0.10924768447875977, 'pred_time': 0.08964681625366211, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis trained on 615832 samples.\n",
      "{'train_time': 0.09738326072692871, 'pred_time': 0.08622312545776367, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "PCA component size: 5\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 615832 samples.\n",
      "{'train_time': 32.68738055229187, 'pred_time': 2.1642277240753174, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "DecisionTreeClassifier trained on 615832 samples.\n",
      "{'train_time': 2.2547378540039062, 'pred_time': 0.044091224670410156, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "RandomForestClassifier trained on 615832 samples.\n",
      "{'train_time': 3.660187005996704, 'pred_time': 0.5776605606079102, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "MLPClassifier trained on 615832 samples.\n",
      "{'train_time': 19.074443340301514, 'pred_time': 2.628875494003296, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "AdaBoostClassifier trained on 615832 samples.\n",
      "{'train_time': 30.09772300720215, 'pred_time': 3.0714094638824463, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB trained on 615832 samples.\n",
      "{'train_time': 0.1168215274810791, 'pred_time': 0.10405325889587402, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n",
      "QuadraticDiscriminantAnalysis trained on 615832 samples.\n",
      "{'train_time': 0.11621356010437012, 'pred_time': 0.10476994514465332, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "## From http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "names = [\"XGBoost\", \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "\"\"\"\n",
    "\"Linear SVM\", \"RBF SVM\", \"Gaussian Process\", \"Nearest Neighbors\",\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    KNeighborsClassifier(3),\n",
    " \"\"\"    \n",
    "\n",
    "classifiers = [XGBClassifier(), DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "print(\"Original data\")\n",
    "print(\"=============\")\n",
    "print(features.shape)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "    result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "    print(result)\n",
    "    print('-----------------------------------')\n",
    "    \n",
    "print(\"PCA data\")\n",
    "print(\"=============\")\n",
    "for pca_comp in range(1,6):\n",
    "    print(\"PCA component size: \" + str(pca_comp))\n",
    "    pca = decomposition.PCA(n_components=pca_comp)\n",
    "    pca.fit(features)\n",
    "    features_pca = pca.transform(features)\n",
    "    # print(features_pca)\n",
    "    # features_pca =  StandardScaler().fit_transform(features_pca)\n",
    "    # print(features_pca)\n",
    "    # print(features_pca.shape)\n",
    "    ###### StandardScalar\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features_pca, loan_status, test_size = 0.2, random_state = 0)\n",
    "        result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "        print(result)\n",
    "        print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data after scaling\n",
      "=============\n",
      "        loan_amnt  funded_amnt  funded_amnt_inv      term  installment  \\\n",
      "321150  22.782058    22.782058        22.782058  4.792130    10.850738   \n",
      "705691  18.491718    18.491718        18.491718  4.792130     8.243621   \n",
      "377068  24.306440    24.306440        24.306440  5.684507    11.237275   \n",
      "85052   19.000645    19.000645        19.000645  4.792130     8.967806   \n",
      "386388  20.610004    20.610004        20.610004  4.792130     9.571590   \n",
      "744945  19.874209    19.874209        19.874209  5.684507     8.520744   \n",
      "752311  19.458096    19.458096        19.458096  4.792130     9.050880   \n",
      "346005  23.598505    23.598505        23.598505  5.684507    10.456122   \n",
      "175060  19.403352    19.403352        19.403352  4.792130     9.022056   \n",
      "194471  25.360669    25.360669        25.326250  4.792130    12.600135   \n",
      "16968   19.874209    19.874209        19.874209  4.792130     9.114244   \n",
      "221877  19.874209    19.874209        19.874209  4.792130     9.286754   \n",
      "750553  21.366208    21.366208        21.366208  4.792130    10.195819   \n",
      "103124  19.874209    19.874209        19.874209  4.792130     9.278551   \n",
      "611644  17.253669    17.253669        17.253669  4.792130     7.746614   \n",
      "88294   20.610004    20.610004        20.610004  5.684507     9.334637   \n",
      "262327  23.784389    23.784389        23.784389  4.792130    11.420912   \n",
      "742732  21.538377    21.538377        21.538377  4.792130    10.207970   \n",
      "661855  22.998360    22.998360        22.998360  4.792130    11.117664   \n",
      "253918  22.782058    22.782058        22.782058  5.684507    10.376413   \n",
      "285338  22.782058    22.782058        22.782058  4.792130    10.990468   \n",
      "484133  20.515322    20.515322        20.515322  4.792130     9.685099   \n",
      "298125  19.000645    19.000645        19.000645  4.792130     8.753449   \n",
      "143478  21.944481    21.944481        21.944481  4.792130    10.510913   \n",
      "449990  13.856095    13.856095        13.856095  4.792130     5.755915   \n",
      "650465  22.556361    22.556361        22.556361  4.792130    10.813239   \n",
      "148158  19.953156    19.953156        19.953156  4.792130     9.509980   \n",
      "585083  18.803944    18.803944        18.803944  4.792130     8.427938   \n",
      "661892  20.088200    20.088200        20.088200  4.792130     9.251634   \n",
      "685296  23.405917    23.405917        23.405917  4.792130    11.361691   \n",
      "...           ...          ...              ...       ...          ...   \n",
      "662335  24.933056    24.933056        24.933056  5.684507    11.293276   \n",
      "62222   24.984658    24.984658        24.977316  5.684507    11.281497   \n",
      "569253  22.782058    22.782058        22.782058  4.792130    11.008014   \n",
      "685999  20.610004    20.610004        20.610004  5.684507     8.806050   \n",
      "465029  17.253669    17.253669        17.253669  4.792130     7.668440   \n",
      "193627  17.531355    17.531355        17.531355  4.792130     7.869224   \n",
      "689311  19.458096    19.458096        19.458096  4.792130     8.975303   \n",
      "46736   22.782058    22.782058        22.782058  4.792130    10.851116   \n",
      "157520  23.206076    23.206076        23.206076  4.792130    11.091968   \n",
      "154861  23.673634    23.673634        23.673634  4.792130    11.369554   \n",
      "653106  15.705168    15.705168        15.705168  4.792130     6.890879   \n",
      "249956  25.360669    25.360669        25.360669  4.792130    12.534749   \n",
      "139750  18.213642    18.213642        18.213642  4.792130     8.478906   \n",
      "312047  22.104477    22.104477        22.104477  4.792130    10.584823   \n",
      "102621  23.710807    23.710807        23.710807  4.792130    11.547374   \n",
      "183377  22.320331    22.320331        22.314289  5.684507    10.137815   \n",
      "614893  19.874209    19.874209        19.874209  5.684507     8.761210   \n",
      "82179   21.126905    21.126905        21.126905  4.792130    10.076813   \n",
      "563208  21.538377    21.538377        21.538377  5.684507     9.506753   \n",
      "119484  19.060400    19.060400        19.060400  4.792130     8.856576   \n",
      "462623  20.256340    20.256340        20.256340  4.792130     9.667206   \n",
      "236079  21.248010    21.248010        21.248010  5.684507     9.531362   \n",
      "395731  23.598505    23.598505        23.598505  5.684507    10.850864   \n",
      "427531  22.142137    22.142137        22.135880  4.792130    10.845409   \n",
      "263854  21.538377    21.538377        21.538377  4.792130    10.122975   \n",
      "5127    21.538377    21.538377        21.538377  4.792130    10.244536   \n",
      "331637  19.458096    19.458096        19.458096  4.792130     8.821255   \n",
      "11293   22.782058    22.782058        22.782058  4.792130    11.102736   \n",
      "638747  25.360669    25.360669        25.360669  5.684507    11.399088   \n",
      "291880  20.256340    20.256340        20.256340  4.792130     9.460173   \n",
      "\n",
      "        annual_inc   zip_code       dti  delinq_2yrs  inq_last_6mths  \\\n",
      "321150   31.765210  10.779829  4.033107     0.730463        0.000000   \n",
      "705691   24.470542   6.881187  2.625605     0.000000        0.000000   \n",
      "377068   29.167258  10.034756  3.782840     0.000000        1.194318   \n",
      "85052    28.476974  11.640795  3.901909     1.540963        1.540963   \n",
      "386388   28.869811  11.234013  3.800769     1.820334        0.000000   \n",
      "744945   29.020291  12.074291  3.014966     0.000000        0.000000   \n",
      "752311   29.919958   6.899104  4.240562     0.730463        0.730463   \n",
      "346005   30.296202   5.684507  2.465680     0.000000        0.000000   \n",
      "175060   23.964056   8.889640  4.319412     0.000000        0.000000   \n",
      "194471   30.737918  11.332597  4.155134     0.000000        0.000000   \n",
      "16968    27.607297  11.673285  3.643754     0.730463        0.000000   \n",
      "221877   25.193510   7.087847  4.445579     0.000000        0.000000   \n",
      "750553   26.591022   9.685037  4.856594     0.000000        0.000000   \n",
      "103124   29.520421   6.934540  3.484859     0.000000        0.000000   \n",
      "611644   32.417002  11.259868  4.715434     0.000000        1.194318   \n",
      "88294    31.205218  10.868631  3.412347     0.000000        0.000000   \n",
      "262327   32.548972   8.081455  3.845224     0.730463        0.000000   \n",
      "742732   29.588763   6.808145  4.261338     0.000000        0.000000   \n",
      "661855   30.110806   6.826617  2.691301     0.000000        0.000000   \n",
      "253918   28.557548  11.889015  2.542807     0.000000        2.055642   \n",
      "285338   27.120793  11.682968  4.378659     0.000000        0.000000   \n",
      "484133   26.591022   9.192820  4.590490     0.730463        0.730463   \n",
      "298125   26.008617  10.174253  4.305205     0.730463        0.000000   \n",
      "143478   26.365003  11.151348  4.009672     0.000000        1.194318   \n",
      "449990   26.008617  11.151348  3.764735     0.730463        1.194318   \n",
      "650465   27.368970  10.215888  1.509852     0.730463        0.000000   \n",
      "148158   28.476974  11.336190  4.039262     0.000000        0.730463   \n",
      "585083   27.069896  10.520315  3.613932     0.000000        0.000000   \n",
      "661892   23.598505  11.987364  3.870050     0.000000        0.000000   \n",
      "685296   30.234988  11.895060  4.292687     0.000000        0.000000   \n",
      "...            ...        ...       ...          ...             ...   \n",
      "662335   33.747323   4.926918  2.587072     2.259674        0.000000   \n",
      "62222    29.020291   7.169005  2.803080     0.000000        0.000000   \n",
      "569253   28.228763  12.102765  3.858807     1.194318        0.730463   \n",
      "685999   31.258099  11.922126  3.657226     0.000000        0.000000   \n",
      "465029   36.083784  11.452540  3.183845     0.730463        0.730463   \n",
      "193627   28.057555  10.762621  3.678908     0.000000        0.000000   \n",
      "689311   33.292174  11.892039  4.355640     0.730463        1.194318   \n",
      "46736    31.516424  10.758304  2.207161     0.000000        0.730463   \n",
      "157520   27.120793  10.991230  2.663253     0.000000        0.000000   \n",
      "154861   31.279135   7.511251  3.149580     0.000000        1.194318   \n",
      "653106   31.566920  11.800080  4.286098     0.000000        0.730463   \n",
      "249956   31.205218  11.898079  2.888450     0.000000        0.730463   \n",
      "139750   24.820844  11.895060  3.609631     0.000000        1.194318   \n",
      "312047   25.758185  11.692623  4.713020     0.000000        0.000000   \n",
      "102621   32.971576  11.901094  1.802404     0.000000        0.000000   \n",
      "183377   29.310888  11.695834  3.369546     0.000000        0.730463   \n",
      "614893   28.057555   9.984891  3.663925     0.000000        1.194318   \n",
      "82179    27.241203   6.404587  3.657226     0.000000        0.000000   \n",
      "563208   29.588763  11.901094  3.323665     0.000000        0.730463   \n",
      "119484   25.884766   9.286968  3.884194     0.000000        0.000000   \n",
      "462623   26.591022  11.800080  4.212091     1.194318        0.000000   \n",
      "236079   27.120793   7.606710  2.576118     0.000000        0.730463   \n",
      "395731   31.120480  11.966746  2.779652     0.000000        0.000000   \n",
      "427531   25.704175  11.346944  4.726982     0.000000        0.000000   \n",
      "263854   26.808659   9.178051  3.875274     0.000000        0.000000   \n",
      "5127     28.715631   5.802739  3.823130     1.194318        0.730463   \n",
      "331637   28.869811   8.511220  4.378659     0.000000        0.000000   \n",
      "11293    27.221303  12.102765  4.396881     0.000000        0.000000   \n",
      "638747   46.288557   6.073289  2.539599     0.000000        0.000000   \n",
      "291880   26.591022   6.654950  3.095148     0.000000        0.000000   \n",
      "\n",
      "                ...            addr_state_TX  addr_state_UT  addr_state_VA  \\\n",
      "321150          ...                 0.000000       0.000000       0.000000   \n",
      "705691          ...                 0.000000       0.000000       0.000000   \n",
      "377068          ...                 0.000000       0.000000       0.000000   \n",
      "85052           ...                 0.000000       0.730463       0.000000   \n",
      "386388          ...                 0.000000       0.000000       0.000000   \n",
      "744945          ...                 0.000000       0.000000       0.000000   \n",
      "752311          ...                 0.000000       0.000000       0.000000   \n",
      "346005          ...                 0.000000       0.000000       0.000000   \n",
      "175060          ...                 0.000000       0.000000       0.000000   \n",
      "194471          ...                 0.730463       0.000000       0.000000   \n",
      "16968           ...                 0.000000       0.000000       0.000000   \n",
      "221877          ...                 0.000000       0.000000       0.000000   \n",
      "750553          ...                 0.000000       0.000000       0.000000   \n",
      "103124          ...                 0.000000       0.000000       0.000000   \n",
      "611644          ...                 0.000000       0.000000       0.000000   \n",
      "88294           ...                 0.000000       0.000000       0.000000   \n",
      "262327          ...                 0.000000       0.000000       0.000000   \n",
      "742732          ...                 0.000000       0.000000       0.000000   \n",
      "661855          ...                 0.000000       0.000000       0.000000   \n",
      "253918          ...                 0.000000       0.000000       0.000000   \n",
      "285338          ...                 0.000000       0.000000       0.000000   \n",
      "484133          ...                 0.000000       0.000000       0.000000   \n",
      "298125          ...                 0.000000       0.000000       0.000000   \n",
      "143478          ...                 0.000000       0.000000       0.000000   \n",
      "449990          ...                 0.000000       0.000000       0.000000   \n",
      "650465          ...                 0.000000       0.000000       0.000000   \n",
      "148158          ...                 0.730463       0.000000       0.000000   \n",
      "585083          ...                 0.000000       0.000000       0.000000   \n",
      "661892          ...                 0.000000       0.000000       0.000000   \n",
      "685296          ...                 0.000000       0.000000       0.000000   \n",
      "...             ...                      ...            ...            ...   \n",
      "662335          ...                 0.000000       0.000000       0.000000   \n",
      "62222           ...                 0.000000       0.000000       0.000000   \n",
      "569253          ...                 0.000000       0.000000       0.000000   \n",
      "685999          ...                 0.000000       0.000000       0.000000   \n",
      "465029          ...                 0.730463       0.000000       0.000000   \n",
      "193627          ...                 0.000000       0.000000       0.000000   \n",
      "689311          ...                 0.000000       0.000000       0.000000   \n",
      "46736           ...                 0.000000       0.000000       0.000000   \n",
      "157520          ...                 0.000000       0.000000       0.000000   \n",
      "154861          ...                 0.000000       0.000000       0.000000   \n",
      "653106          ...                 0.000000       0.000000       0.000000   \n",
      "249956          ...                 0.000000       0.000000       0.000000   \n",
      "139750          ...                 0.000000       0.000000       0.000000   \n",
      "312047          ...                 0.000000       0.000000       0.000000   \n",
      "102621          ...                 0.000000       0.000000       0.000000   \n",
      "183377          ...                 0.000000       0.000000       0.000000   \n",
      "614893          ...                 0.000000       0.000000       0.000000   \n",
      "82179           ...                 0.000000       0.000000       0.000000   \n",
      "563208          ...                 0.000000       0.000000       0.000000   \n",
      "119484          ...                 0.000000       0.000000       0.000000   \n",
      "462623          ...                 0.000000       0.000000       0.000000   \n",
      "236079          ...                 0.000000       0.000000       0.000000   \n",
      "395731          ...                 0.000000       0.000000       0.000000   \n",
      "427531          ...                 0.730463       0.000000       0.000000   \n",
      "263854          ...                 0.000000       0.000000       0.000000   \n",
      "5127            ...                 0.000000       0.000000       0.000000   \n",
      "331637          ...                 0.000000       0.000000       0.730463   \n",
      "11293           ...                 0.000000       0.000000       0.000000   \n",
      "638747          ...                 0.000000       0.000000       0.000000   \n",
      "291880          ...                 0.000000       0.000000       0.000000   \n",
      "\n",
      "        addr_state_VT  addr_state_WA  addr_state_WI  addr_state_WV  \\\n",
      "321150            0.0       0.000000            0.0            0.0   \n",
      "705691            0.0       0.000000            0.0            0.0   \n",
      "377068            0.0       0.000000            0.0            0.0   \n",
      "85052             0.0       0.000000            0.0            0.0   \n",
      "386388            0.0       0.000000            0.0            0.0   \n",
      "744945            0.0       0.730463            0.0            0.0   \n",
      "752311            0.0       0.000000            0.0            0.0   \n",
      "346005            0.0       0.000000            0.0            0.0   \n",
      "175060            0.0       0.000000            0.0            0.0   \n",
      "194471            0.0       0.000000            0.0            0.0   \n",
      "16968             0.0       0.000000            0.0            0.0   \n",
      "221877            0.0       0.000000            0.0            0.0   \n",
      "750553            0.0       0.000000            0.0            0.0   \n",
      "103124            0.0       0.000000            0.0            0.0   \n",
      "611644            0.0       0.000000            0.0            0.0   \n",
      "88294             0.0       0.000000            0.0            0.0   \n",
      "262327            0.0       0.000000            0.0            0.0   \n",
      "742732            0.0       0.000000            0.0            0.0   \n",
      "661855            0.0       0.000000            0.0            0.0   \n",
      "253918            0.0       0.000000            0.0            0.0   \n",
      "285338            0.0       0.000000            0.0            0.0   \n",
      "484133            0.0       0.000000            0.0            0.0   \n",
      "298125            0.0       0.000000            0.0            0.0   \n",
      "143478            0.0       0.000000            0.0            0.0   \n",
      "449990            0.0       0.000000            0.0            0.0   \n",
      "650465            0.0       0.000000            0.0            0.0   \n",
      "148158            0.0       0.000000            0.0            0.0   \n",
      "585083            0.0       0.000000            0.0            0.0   \n",
      "661892            0.0       0.000000            0.0            0.0   \n",
      "685296            0.0       0.000000            0.0            0.0   \n",
      "...               ...            ...            ...            ...   \n",
      "662335            0.0       0.000000            0.0            0.0   \n",
      "62222             0.0       0.000000            0.0            0.0   \n",
      "569253            0.0       0.730463            0.0            0.0   \n",
      "685999            0.0       0.000000            0.0            0.0   \n",
      "465029            0.0       0.000000            0.0            0.0   \n",
      "193627            0.0       0.000000            0.0            0.0   \n",
      "689311            0.0       0.000000            0.0            0.0   \n",
      "46736             0.0       0.000000            0.0            0.0   \n",
      "157520            0.0       0.000000            0.0            0.0   \n",
      "154861            0.0       0.000000            0.0            0.0   \n",
      "653106            0.0       0.000000            0.0            0.0   \n",
      "249956            0.0       0.000000            0.0            0.0   \n",
      "139750            0.0       0.000000            0.0            0.0   \n",
      "312047            0.0       0.000000            0.0            0.0   \n",
      "102621            0.0       0.000000            0.0            0.0   \n",
      "183377            0.0       0.000000            0.0            0.0   \n",
      "614893            0.0       0.000000            0.0            0.0   \n",
      "82179             0.0       0.000000            0.0            0.0   \n",
      "563208            0.0       0.000000            0.0            0.0   \n",
      "119484            0.0       0.000000            0.0            0.0   \n",
      "462623            0.0       0.000000            0.0            0.0   \n",
      "236079            0.0       0.000000            0.0            0.0   \n",
      "395731            0.0       0.000000            0.0            0.0   \n",
      "427531            0.0       0.000000            0.0            0.0   \n",
      "263854            0.0       0.000000            0.0            0.0   \n",
      "5127              0.0       0.000000            0.0            0.0   \n",
      "331637            0.0       0.000000            0.0            0.0   \n",
      "11293             0.0       0.730463            0.0            0.0   \n",
      "638747            0.0       0.000000            0.0            0.0   \n",
      "291880            0.0       0.000000            0.0            0.0   \n",
      "\n",
      "        addr_state_WY  initial_list_status_f  initial_list_status_w  \n",
      "321150            0.0               0.000000               0.730463  \n",
      "705691            0.0               0.730463               0.000000  \n",
      "377068            0.0               0.730463               0.000000  \n",
      "85052             0.0               0.730463               0.000000  \n",
      "386388            0.0               0.000000               0.730463  \n",
      "744945            0.0               0.000000               0.730463  \n",
      "752311            0.0               0.000000               0.730463  \n",
      "346005            0.0               0.000000               0.730463  \n",
      "175060            0.0               0.730463               0.000000  \n",
      "194471            0.0               0.730463               0.000000  \n",
      "16968             0.0               0.000000               0.730463  \n",
      "221877            0.0               0.000000               0.730463  \n",
      "750553            0.0               0.000000               0.730463  \n",
      "103124            0.0               0.730463               0.000000  \n",
      "611644            0.0               0.000000               0.730463  \n",
      "88294             0.0               0.000000               0.730463  \n",
      "262327            0.0               0.000000               0.730463  \n",
      "742732            0.0               0.000000               0.730463  \n",
      "661855            0.0               0.000000               0.730463  \n",
      "253918            0.0               0.000000               0.730463  \n",
      "285338            0.0               0.000000               0.730463  \n",
      "484133            0.0               0.730463               0.000000  \n",
      "298125            0.0               0.730463               0.000000  \n",
      "143478            0.0               0.000000               0.730463  \n",
      "449990            0.0               0.000000               0.730463  \n",
      "650465            0.0               0.730463               0.000000  \n",
      "148158            0.0               0.000000               0.730463  \n",
      "585083            0.0               0.000000               0.730463  \n",
      "661892            0.0               0.000000               0.730463  \n",
      "685296            0.0               0.000000               0.730463  \n",
      "...               ...                    ...                    ...  \n",
      "662335            0.0               0.000000               0.730463  \n",
      "62222             0.0               0.730463               0.000000  \n",
      "569253            0.0               0.730463               0.000000  \n",
      "685999            0.0               0.000000               0.730463  \n",
      "465029            0.0               0.730463               0.000000  \n",
      "193627            0.0               0.730463               0.000000  \n",
      "689311            0.0               0.000000               0.730463  \n",
      "46736             0.0               0.000000               0.730463  \n",
      "157520            0.0               0.730463               0.000000  \n",
      "154861            0.0               0.730463               0.000000  \n",
      "653106            0.0               0.000000               0.730463  \n",
      "249956            0.0               0.730463               0.000000  \n",
      "139750            0.0               0.730463               0.000000  \n",
      "312047            0.0               0.730463               0.000000  \n",
      "102621            0.0               0.000000               0.730463  \n",
      "183377            0.0               0.730463               0.000000  \n",
      "614893            0.0               0.730463               0.000000  \n",
      "82179             0.0               0.000000               0.730463  \n",
      "563208            0.0               0.000000               0.730463  \n",
      "119484            0.0               0.730463               0.000000  \n",
      "462623            0.0               0.730463               0.000000  \n",
      "236079            0.0               0.000000               0.730463  \n",
      "395731            0.0               0.730463               0.000000  \n",
      "427531            0.0               0.730463               0.000000  \n",
      "263854            0.0               0.730463               0.000000  \n",
      "5127              0.0               0.000000               0.730463  \n",
      "331637            0.0               0.730463               0.000000  \n",
      "11293             0.0               0.000000               0.730463  \n",
      "638747            0.0               0.000000               0.730463  \n",
      "291880            0.0               0.000000               0.730463  \n",
      "\n",
      "[769790 rows x 207 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After scaling\n",
      "[[ 0.78963152  0.79124781  0.78974543 ... -0.04767921 -1.01308394\n",
      "   1.01308394]\n",
      " [-0.79103917 -0.78996489 -0.77558193 ... -0.04767921  0.98708504\n",
      "  -0.98708504]\n",
      " [ 1.35125264  1.35306151  1.34591498 ... -0.04767921  0.98708504\n",
      "  -0.98708504]\n",
      " ...\n",
      " [ 0.78963152  0.79124781  0.78974543 ... -0.04767921 -1.01308394\n",
      "   1.01308394]\n",
      " [ 1.73965728  1.74159933  1.73054943 ... -0.04767921 -1.01308394\n",
      "   1.01308394]\n",
      " [-0.14090731 -0.1396101  -0.1317608  ... -0.04767921 -1.01308394\n",
      "   1.01308394]]\n",
      "XGBoost\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier trained on 615832 samples.\n",
      "{'train_time': 273.8983132839203, 'pred_time': 3.3885505199432373, 'acc_train': 0.848625923953286, 'acc_test': 0.8481793735953962, 'f_train': 0.877928251001055, 'f_test': 0.8775348027423189}\n",
      "Decision Tree\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "DecisionTreeClassifier trained on 615832 samples.\n",
      "{'train_time': 15.598974227905273, 'pred_time': 0.399153470993042, 'acc_train': 0.8347195338988556, 'acc_test': 0.8338183140856598, 'f_train': 0.8735138626721308, 'f_test': 0.8728762797972536}\n",
      "Random Forest\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "RandomForestClassifier trained on 615832 samples.\n",
      "{'train_time': 1.7503464221954346, 'pred_time': 1.2341256141662598, 'acc_train': 0.8074556047753283, 'acc_test': 0.8079021551332182, 'f_train': 0.83979517561563, 'f_test': 0.8401815688685045}\n",
      "Neural Net\n",
      "MLPClassifier(activation='relu', alpha=1, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "MLPClassifier trained on 615832 samples.\n",
      "{'train_time': 318.35587453842163, 'pred_time': 8.327288389205933, 'acc_train': 0.8305040985203757, 'acc_test': 0.8304667506722613, 'f_train': 0.8643392849313124, 'f_test': 0.8642948830278135}\n",
      "AdaBoost\n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "AdaBoostClassifier trained on 615832 samples.\n",
      "{'train_time': 182.47441506385803, 'pred_time': 7.789899826049805, 'acc_train': 0.8319898933475364, 'acc_test': 0.830836981514439, 'f_train': 0.8676524880554248, 'f_test': 0.866917350579005}\n",
      "Naive Bayes\n",
      "GaussianNB(priors=None)\n",
      "GaussianNB trained on 615832 samples.\n",
      "{'train_time': 2.236755609512329, 'pred_time': 3.0015370845794678, 'acc_train': 0.5656851219163668, 'acc_test': 0.566375245196742, 'f_train': 0.7848704851690742, 'f_test': 0.7856500916884483}\n",
      "QDA\n",
      "QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
      "               store_covariance=False, store_covariances=None, tol=0.0001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/home/anilraj/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticDiscriminantAnalysis trained on 615832 samples.\n",
      "{'train_time': 17.516059637069702, 'pred_time': 6.333901405334473, 'acc_train': 0.5694393925616077, 'acc_test': 0.5698632094467322, 'f_train': 0.7710336971607157, 'f_test': 0.7717670230603875}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data after scaling\")\n",
    "print(\"=============\")\n",
    "print(features)\n",
    "features =  StandardScaler().fit_transform(features)\n",
    "print(\"After scaling\")\n",
    "print(features)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(name)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "    result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"More fine tuning\")\\n    \\n# TODO: Import \\'GridSearchCV\\', \\'make_scorer\\', and any other necessary libraries\\nfrom sklearn.metrics import make_scorer\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# TODO: Initialize the classifier\\nclf = MLPClassifier()\\n\\n## Note the features is already scaled\\nX_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\\n\\n# TODO: Create the parameters list you wish to tune\\nparameters = {\\n    \\'hidden_layer_sizes\\' : [(100,), (50, 50), (100,50,3), (10, 50, 100), (10, 50, 100, 50, 10)],\\n    # \\'activation\\' : [\\'identity\\', \\'logistic\\', \\'tanh\\', \\'relu\\'],\\n    # \\'solver\\' : [\\'lbfgs\\', \\'sgd\\', \\'adam\\'],\\n    # \\'alpha\\' : [0.0001, 0.001, 0.01, 0.1, 0.00001, 1],\\n    # \\'learning_rate\\' : [\\'constant\\', \\'invscaling\\', \\'adaptive\\'],\\n    # \\'learning_rate_init\\' : [0.001, 0.01, 0.1, 0.0001],\\n    # \\'max_iter\\' : [200, 100, 50, 400],\\n    # \\'warm_start\\' : [False, True],\\n    # \\'momentum\\' : [0.9, 0.5, 0.8, 0.1],\\n    ### ------\\n    # nesterovs_momentum : boolean, default True\\n    # early_stopping : bool, default False\\n    # validation_fraction : float, optional, default 0.1\\n    # beta_1 : float, optional, default 0.9\\n    # beta_2 : float, optional, default 0.999\\n    # epsilon : float, optional, default 1e-8\\n    # n_iter_no_change : int, optional, default 10\\n    # \\'power_t\\' : double, optional, default 0.5\\n    # \\'batch_size\\' : int, optional, default ‘auto’\\n    # \\'shuffle\\' : bool, optional, default True\\n    # random_state : int, RandomState instance or None, optional, default None\\n    # tol : float, optional, default 1e-4\\n    # verbose : bool, optional, default False\\n}\\n\\n# TODO: Make an fbeta_score scoring object\\nscorer = make_scorer(fbeta_score, beta=0.5)\\n\\n# TODO: Perform grid search on the classifier using \\'scorer\\' as the scoring method\\ngrid_obj = GridSearchCV(clf, parameters, scoring=scorer)\\n\\n# TODO: Fit the grid search object to the training data and find the optimal parameters\\ngrid_fit = grid_obj.fit(X_train, y_train)\\n\\n# Get the estimator\\nbest_clf = grid_fit.best_estimator_\\n\\n# Make predictions using the unoptimized and model\\npredictions = (clf.fit(X_train, y_train)).predict(X_test)\\nbest_predictions = best_clf.predict(X_test)\\n\\n# Report the before-and-afterscores\\nprint(\"Unoptimized model\\n------\")\\nprint(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\\nprint(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\\nprint(\"\\nOptimized Model\\n------\")\\nprint(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\\nprint(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"More fine tuning\")\n",
    "    \n",
    "# TODO: Import 'GridSearchCV', 'make_scorer', and any other necessary libraries\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TODO: Initialize the classifier\n",
    "clf = MLPClassifier()\n",
    "\n",
    "## Note the features is already scaled\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, loan_status, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune\n",
    "parameters = {\n",
    "    'hidden_layer_sizes' : [(100,), (50, 50), (100,50,3), (10, 50, 100), (10, 50, 100, 50, 10)],\n",
    "    # 'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    # 'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "    # 'alpha' : [0.0001, 0.001, 0.01, 0.1, 0.00001, 1],\n",
    "    # 'learning_rate' : ['constant', 'invscaling', 'adaptive'],\n",
    "    # 'learning_rate_init' : [0.001, 0.01, 0.1, 0.0001],\n",
    "    # 'max_iter' : [200, 100, 50, 400],\n",
    "    # 'warm_start' : [False, True],\n",
    "    # 'momentum' : [0.9, 0.5, 0.8, 0.1],\n",
    "    ### ------\n",
    "    # nesterovs_momentum : boolean, default True\n",
    "    # early_stopping : bool, default False\n",
    "    # validation_fraction : float, optional, default 0.1\n",
    "    # beta_1 : float, optional, default 0.9\n",
    "    # beta_2 : float, optional, default 0.999\n",
    "    # epsilon : float, optional, default 1e-8\n",
    "    # n_iter_no_change : int, optional, default 10\n",
    "    # 'power_t' : double, optional, default 0.5\n",
    "    # 'batch_size' : int, optional, default ‘auto’\n",
    "    # 'shuffle' : bool, optional, default True\n",
    "    # random_state : int, RandomState instance or None, optional, default None\n",
    "    # tol : float, optional, default 1e-4\n",
    "    # verbose : bool, optional, default False\n",
    "}\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object\n",
    "scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grid_fit.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
