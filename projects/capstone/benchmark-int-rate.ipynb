{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan data\n",
    "df = pd.read_pickle('data_cleaned.pkl')\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Remove loan_status as it is one of the items we will predict\n",
    "df.drop('loan_status', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id float64\n",
      "member_id float64\n",
      "loan_amnt int64\n",
      "funded_amnt int64\n",
      "funded_amnt_inv float64\n",
      "term int64\n",
      "int_rate float64\n",
      "installment float64\n",
      "grade object\n",
      "sub_grade object\n",
      "emp_length object\n",
      "home_ownership object\n",
      "annual_inc float64\n",
      "verification_status object\n",
      "pymnt_plan object\n",
      "purpose object\n",
      "zip_code int64\n",
      "addr_state object\n",
      "dti float64\n",
      "delinq_2yrs int64\n",
      "inq_last_6mths int64\n",
      "mths_since_last_delinq int64\n",
      "mths_since_last_record int64\n",
      "open_acc int64\n",
      "pub_rec int64\n",
      "revol_bal int64\n",
      "revol_util float64\n",
      "total_acc int64\n",
      "initial_list_status object\n",
      "out_prncp float64\n",
      "out_prncp_inv float64\n",
      "total_pymnt float64\n",
      "total_pymnt_inv float64\n",
      "total_rec_prncp float64\n",
      "total_rec_int float64\n",
      "total_rec_late_fee float64\n",
      "recoveries float64\n",
      "collection_recovery_fee float64\n",
      "last_pymnt_amnt float64\n",
      "collections_12_mths_ex_med int64\n",
      "mths_since_last_major_derog int64\n",
      "application_type object\n",
      "acc_now_delinq int64\n",
      "tot_coll_amt int64\n",
      "tot_cur_bal int64\n",
      "open_acc_6m int64\n",
      "open_act_il int64\n",
      "open_il_12m int64\n",
      "open_il_24m int64\n",
      "mths_since_rcnt_il float64\n",
      "total_bal_il float64\n",
      "il_util float64\n",
      "open_rv_12m float64\n",
      "open_rv_24m float64\n",
      "max_bal_bc int64\n",
      "all_util int64\n",
      "total_rev_hi_lim int64\n",
      "inq_fi int64\n",
      "total_cu_tl int64\n",
      "inq_last_12m int64\n",
      "acc_open_past_24mths int64\n",
      "avg_cur_bal int64\n",
      "bc_open_to_buy int64\n",
      "bc_util float64\n",
      "chargeoff_within_12_mths int64\n",
      "delinq_amnt int64\n",
      "mo_sin_old_il_acct float64\n",
      "mo_sin_old_rev_tl_op float64\n",
      "mo_sin_rcnt_rev_tl_op float64\n",
      "mo_sin_rcnt_tl int64\n",
      "mort_acc int64\n",
      "mths_since_recent_bc int64\n",
      "mths_since_recent_bc_dlq int64\n",
      "mths_since_recent_inq int64\n",
      "mths_since_recent_revol_delinq int64\n",
      "num_accts_ever_120_pd int64\n",
      "num_actv_bc_tl int64\n",
      "num_actv_rev_tl int64\n",
      "num_bc_sats int64\n",
      "num_bc_tl int64\n",
      "num_il_tl int64\n",
      "num_op_rev_tl int64\n",
      "num_rev_accts int64\n",
      "num_rev_tl_bal_gt_0 int64\n",
      "num_sats int64\n",
      "num_tl_120dpd_2m int64\n",
      "num_tl_30dpd int64\n",
      "num_tl_90g_dpd_24m int64\n",
      "num_tl_op_past_12m int64\n",
      "pct_tl_nvr_dlq float64\n",
      "percent_bc_gt_75 float64\n",
      "pub_rec_bankruptcies int64\n",
      "tax_liens int64\n",
      "tot_hi_cred_lim int64\n",
      "total_bal_ex_mort int64\n",
      "total_bc_limit int64\n",
      "total_il_high_credit_limit int64\n",
      "revol_bal_joint float64\n",
      "sec_app_inq_last_6mths int64\n",
      "sec_app_mort_acc int64\n",
      "sec_app_open_acc int64\n",
      "sec_app_revol_util int64\n",
      "sec_app_open_act_il int64\n",
      "sec_app_num_rev_accts int64\n",
      "sec_app_chargeoff_within_12_mths int64\n",
      "sec_app_collections_12_mths_ex_med int64\n",
      "sec_app_mths_since_last_major_derog int64\n",
      "hardship_type object\n",
      "hardship_reason object\n",
      "hardship_status object\n",
      "deferral_term int64\n",
      "hardship_amount float64\n",
      "hardship_length float64\n",
      "orig_projected_additional_accrued_interest float64\n",
      "debt_settlement_flag object\n",
      "settlement_status object\n",
      "settlement_amount float64\n",
      "settlement_percentage float64\n",
      "settlement_term int64\n",
      "issue_d_month int64\n",
      "issue_d_year int64\n",
      "earliest_cr_line_month int64\n",
      "earliest_cr_line_year int64\n",
      "last_pymnt_d_month int64\n",
      "last_pymnt_d_year int64\n",
      "last_credit_pull_d_month int64\n",
      "last_credit_pull_d_year int64\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the type of all the columns\n",
    "for y in df.columns:\n",
    "    print(y, df[y].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features from data-cleanup.ipynb\n",
    "cat_features = ['grade', 'sub_grade', 'emp_length', 'home_ownership', 'verification_status', \n",
    "                'purpose', 'addr_state', 'initial_list_status', 'application_type']\n",
    "\n",
    "for y in cat_features:\n",
    "    print(y)\n",
    "    df = df.join(pd.get_dummies(df[y], prefix=y))\n",
    "    df.drop(y, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data in features and target label\n",
    "int_rate = df['int_rate']\n",
    "features = df.drop('int_rate', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the features and int_rate data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, int_rate, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # TODO: Fit the learner to the training data using slicing with 'sample_size'\n",
    "    start = time() # Get start time\n",
    "    learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
    "    end = time() # Get end time\n",
    "    \n",
    "    # TODO: Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "        \n",
    "    # TODO: Get the predictions on the test set,\n",
    "    #       then get predictions on the first 300 training samples\n",
    "    start = time() # Get start time\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train[:300])\n",
    "    end = time() # Get end time\n",
    "       \n",
    "    # TODO: Calculate the total prediction time\n",
    "    results['pred_time'] = end - start\n",
    "            \n",
    "    # TODO: Compute accuracy on the first 300 training samples\n",
    "    results['rmsd_train'] = math.sqrt(mean_squared_error(y_train, learner.predict(X_train)))\n",
    "        \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['rmsd_test'] = math.sqrt(mean_squared_error(y_test, learner.predict(X_test)))\n",
    "    \n",
    "    # TODO: Compute accuracy on test set\n",
    "    results['score_train'] = learner.score(X_train, y_train)\n",
    "    results['score_test'] = learner.score(X_test, y_test)\n",
    "    \n",
    "    # Success\n",
    "    print(\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
    "    \n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "    join_df = pd.concat([y_test, pd.Series(learner.predict(X_test))], axis=1)\n",
    "    print(join_df)\n",
    "        \n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "result = train_predict(clf, len(y_train), X_train, y_train, X_test, y_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
